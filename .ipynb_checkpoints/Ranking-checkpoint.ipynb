{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, AutoConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 885 ms, sys: 432 ms, total: 1.32 s\n",
      "Wall time: 1.31 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>conclusion</th>\n",
       "      <th>relevance</th>\n",
       "      <th>relevance_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>d267a5af-2019-04-18T18:07:23Z-00009-000</td>\n",
       "      <td>Should Marijuana Be a Medical Option?</td>\n",
       "      <td>Marijuana is a major concern to the United Sta...</td>\n",
       "      <td>Medical Marijuana</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>7839a8e-2019-04-18T13:02:10Z-00000-000</td>\n",
       "      <td>Is Sexual Orientation Determined at Birth?</td>\n",
       "      <td>Why did you accept my debate if you agreed wit...</td>\n",
       "      <td>Sexual Orientation is a choice.</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>e100392e-2019-04-18T19:19:21Z-00000-000</td>\n",
       "      <td>Do Standardized Tests Improve Education?</td>\n",
       "      <td>You don't it, you have to provide PROOF you di...</td>\n",
       "      <td>Cannabis Sativa Enhances my Life</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>5339b784-2019-04-18T15:45:56Z-00005-000</td>\n",
       "      <td>Should the Federal Minimum Wage Be Increased?</td>\n",
       "      <td>I accept this challenge and negate the resolut...</td>\n",
       "      <td>Resolved: Minimum wages in the United States s...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>61bcba6c-2019-04-18T15:04:19Z-00004-000</td>\n",
       "      <td>Should Animals Be Used for Scientific or Comme...</td>\n",
       "      <td>Well, first of all, thanks for accepting.-----...</td>\n",
       "      <td>Animal Testing</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>36f68365-2019-04-18T15:05:04Z-00000-000</td>\n",
       "      <td>Do Electronic Voting Machines Improve the Voti...</td>\n",
       "      <td>As you can see, my opponent has failed to back...</td>\n",
       "      <td>Earth's orbit around the Sun</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>2c05e9fb-2019-04-15T20:23:05Z-00005-000</td>\n",
       "      <td>Do Electronic Voting Machines Improve the Voti...</td>\n",
       "      <td>Remote electronic voting can be conducted very...</td>\n",
       "      <td>allow the use of electronic and internet votin...</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>b760077b-2019-04-18T13:01:46Z-00003-000</td>\n",
       "      <td>Do Standardized Tests Improve Education?</td>\n",
       "      <td>Challenge accepted, Standardized tests should ...</td>\n",
       "      <td>Standardized Tests</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>b9c0e12b-2019-04-18T13:51:22Z-00005-000</td>\n",
       "      <td>Is Sexual Orientation Determined at Birth?</td>\n",
       "      <td>Lol well that was a waste of a round. But I gu...</td>\n",
       "      <td>there is nothing wrong with zoosexuality/beast...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>2baaf2c1-2019-04-18T18:57:49Z-00000-000</td>\n",
       "      <td>Do Electronic Voting Machines Improve the Voti...</td>\n",
       "      <td>As expected, a cowardly forfeit. Vote Con</td>\n",
       "      <td>Electronics have a positive affect on our live...</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1411 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           id  \\\n",
       "353   d267a5af-2019-04-18T18:07:23Z-00009-000   \n",
       "864    7839a8e-2019-04-18T13:02:10Z-00000-000   \n",
       "1312  e100392e-2019-04-18T19:19:21Z-00000-000   \n",
       "192   5339b784-2019-04-18T15:45:56Z-00005-000   \n",
       "782   61bcba6c-2019-04-18T15:04:19Z-00004-000   \n",
       "...                                       ...   \n",
       "1095  36f68365-2019-04-18T15:05:04Z-00000-000   \n",
       "1130  2c05e9fb-2019-04-15T20:23:05Z-00005-000   \n",
       "1294  b760077b-2019-04-18T13:01:46Z-00003-000   \n",
       "860   b9c0e12b-2019-04-18T13:51:22Z-00005-000   \n",
       "1126  2baaf2c1-2019-04-18T18:57:49Z-00000-000   \n",
       "\n",
       "                                                  query  \\\n",
       "353               Should Marijuana Be a Medical Option?   \n",
       "864          Is Sexual Orientation Determined at Birth?   \n",
       "1312           Do Standardized Tests Improve Education?   \n",
       "192       Should the Federal Minimum Wage Be Increased?   \n",
       "782   Should Animals Be Used for Scientific or Comme...   \n",
       "...                                                 ...   \n",
       "1095  Do Electronic Voting Machines Improve the Voti...   \n",
       "1130  Do Electronic Voting Machines Improve the Voti...   \n",
       "1294           Do Standardized Tests Improve Education?   \n",
       "860          Is Sexual Orientation Determined at Birth?   \n",
       "1126  Do Electronic Voting Machines Improve the Voti...   \n",
       "\n",
       "                                                   text  \\\n",
       "353   Marijuana is a major concern to the United Sta...   \n",
       "864   Why did you accept my debate if you agreed wit...   \n",
       "1312  You don't it, you have to provide PROOF you di...   \n",
       "192   I accept this challenge and negate the resolut...   \n",
       "782   Well, first of all, thanks for accepting.-----...   \n",
       "...                                                 ...   \n",
       "1095  As you can see, my opponent has failed to back...   \n",
       "1130  Remote electronic voting can be conducted very...   \n",
       "1294  Challenge accepted, Standardized tests should ...   \n",
       "860   Lol well that was a waste of a round. But I gu...   \n",
       "1126          As expected, a cowardly forfeit. Vote Con   \n",
       "\n",
       "                                             conclusion  relevance  \\\n",
       "353                                   Medical Marijuana          3   \n",
       "864                     Sexual Orientation is a choice.         -2   \n",
       "1312                   Cannabis Sativa Enhances my Life         -2   \n",
       "192   Resolved: Minimum wages in the United States s...          2   \n",
       "782                                      Animal Testing          3   \n",
       "...                                                 ...        ...   \n",
       "1095                       Earth's orbit around the Sun         -2   \n",
       "1130  allow the use of electronic and internet votin...         -2   \n",
       "1294                                 Standardized Tests          3   \n",
       "860   there is nothing wrong with zoosexuality/beast...          3   \n",
       "1126  Electronics have a positive affect on our live...         -2   \n",
       "\n",
       "      relevance_binary  \n",
       "353                  1  \n",
       "864                  0  \n",
       "1312                 0  \n",
       "192                  1  \n",
       "782                  1  \n",
       "...                ...  \n",
       "1095                 0  \n",
       "1130                 0  \n",
       "1294                 1  \n",
       "860                  1  \n",
       "1126                 0  \n",
       "\n",
       "[1411 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "judgments = pd.read_csv('Data/tira-qrels', delim_whitespace=True, names=['topic','iteration','id','relevance'])\n",
    "arguments = pd.read_pickle('Data/dataset.pkl')\n",
    "\n",
    "tree = ET.parse('Data/topics-automatic-runs-task-1.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "topics = []\n",
    "for child in root:\n",
    "    d = {'topic':int(child[0].text), 'query':child[1].text}\n",
    "    topics.append(d)\n",
    "topics = pd.DataFrame(topics)\n",
    "\n",
    "relevance = judgments.merge(topics)\n",
    "relevance['relevance_binary'] = (relevance['relevance'] != -2).astype(int)\n",
    "relevance = relevance.merge(arguments[['id', 'text', 'conclusion']])\n",
    "relevance = relevance[['id', 'query', 'text', 'conclusion', 'relevance','relevance_binary']]\n",
    "relevance = relevance.sample(frac=1, random_state=42)\n",
    "relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_valid = train_test_split(relevance, shuffle=False, random_state=42, train_size=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_for_encoding(df, batch_size=128):\n",
    "    df = df.copy()\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(dict(df[['query','text','conclusion']]))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e202f5de674e479ca595b5ddbc8b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=546.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da47d70cdc9421ca961bb4ec67df779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_TO_USE = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_TO_USE, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b0413511d748939de8b9cbda596ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1.64 s, sys: 18.1 ms, total: 1.66 s\n",
      "Wall time: 548 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>id</th>\n",
       "      <th>old_index</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>binary_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 2323, 16204, 2022, 1037, 2966, 5724, 102...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>d267a5af-2019-04-18T18:07:23Z-00009-000</td>\n",
       "      <td>353</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 2003, 4424, 10296, 4340, 2012, 4182, 102...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>7839a8e-2019-04-18T13:02:10Z-00000-000</td>\n",
       "      <td>864</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 2079, 16367, 5852, 5335, 2495, 1029, 102...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>e100392e-2019-04-18T19:19:21Z-00000-000</td>\n",
       "      <td>1312</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_ids  \\\n",
       "0  [101, 2323, 16204, 2022, 1037, 2966, 5724, 102...   \n",
       "1  [101, 2003, 4424, 10296, 4340, 2012, 4182, 102...   \n",
       "2  [101, 2079, 16367, 5852, 5335, 2495, 1029, 102...   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                        id  old_index  relevance_score  \\\n",
       "0  d267a5af-2019-04-18T18:07:23Z-00009-000        353                3   \n",
       "1   7839a8e-2019-04-18T13:02:10Z-00000-000        864               -2   \n",
       "2  e100392e-2019-04-18T19:19:21Z-00000-000       1312               -2   \n",
       "\n",
       "   binary_score  \n",
       "0             1  \n",
       "1             0  \n",
       "2             0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tokenized = []\n",
    "for chunk in tqdm_notebook(np.array_split(relevance, 1), total=1):\n",
    "    tokenized_chunk = tokenizer.batch_encode_plus(list(zip(list(chunk['query'].values), list(chunk['text'].values))), max_length=tokenizer.max_len, pad_to_max_length=True, return_overflowing_tokens=True)\n",
    "    tokenized_chunk.pop('token_type_ids')\n",
    "\n",
    "    overflow_index = tokenized_chunk.pop('overflow_to_sample_mapping')\n",
    "\n",
    "    # Repeating indices are included as lists of the corresponding index eg: [0,1, [2,2,2,2], [3,3]...]\n",
    "    overflow_index = np.hstack(overflow_index)\n",
    "    text_ids = chunk['id'].values\n",
    "    text_ids = text_ids[overflow_index]\n",
    "    \n",
    "    old_index = chunk.index.to_series().values\n",
    "    old_index = old_index[overflow_index]\n",
    "    \n",
    "    relevance_score = chunk['relevance'].values\n",
    "    relevance_score = relevance_score[overflow_index]\n",
    "    \n",
    "    binary_score = chunk['relevance_binary'].values\n",
    "    binary_score = binary_score[overflow_index]\n",
    "\n",
    "    df = pd.DataFrame(tokenized_chunk)\n",
    "    df[['input_ids', 'attention_mask']] = df[['input_ids', 'attention_mask']].applymap(np.array)\n",
    "    df['id'] = text_ids\n",
    "    df['old_index'] = old_index\n",
    "    df['relevance_score'] = relevance_score\n",
    "    df['binary_score'] = binary_score\n",
    "    tokenized.append(df)\n",
    "tokenized = pd.concat(tokenized)\n",
    "tokenized.reset_index(inplace=True, drop=True)\n",
    "tokenized[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(MODEL_TO_USE)\n",
    "config.num_labels=2\n",
    "seq = TFAutoModelForSequenceClassification.from_pretrained(MODEL_TO_USE, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = np.stack(tokenized['input_ids'])\n",
    "# m = np.stack(tokenized['attention_mask'])\n",
    "\n",
    "# dataset = tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(i), tf.data.Dataset.from_tensor_slices(m)))\n",
    "# dataset = dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(dict(tokenized))\n",
    "dataset = dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for thing in dataset.take(1):\n",
    "    bla = thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: ping: not found\r\n"
     ]
    }
   ],
   "source": [
    "!ping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[0.09643522, 0.06895541],\n",
       "        [0.10445672, 0.08956073]], dtype=float32)>,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq(inputs=bla['input_ids'], attention_mask=bla['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With TF-Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.2 s, sys: 2.64 s, total: 21.9 s\n",
      "Wall time: 20 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "module = hub.load('https://tfhub.dev/google/universal-sentence-encoder-qa/3')\n",
    "query_embedder = module.signatures['question_encoder']\n",
    "arg_embedder = module.signatures['response_encoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10cfa7b698c84e3487c2c206cb0b59f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=45.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = make_dataset_for_encoding(relevance, batch_size=32)\n",
    "\n",
    "query_encodings = []\n",
    "arg_encodings = []\n",
    "dot_ps = []\n",
    "for batch in tqdm_notebook(dataset, total=tf.data.experimental.cardinality(dataset).numpy()):\n",
    "    query_encoding = query_embedder(batch['query'])\n",
    "    query_encoding = query_encoding['outputs'].numpy()\n",
    "    \n",
    "    arg_encoding = arg_embedder(input=batch['text'], context=batch['conclusion'])\n",
    "    arg_encoding = arg_encoding['outputs'].numpy()\n",
    "    \n",
    "    #Use einstein notation to perform row-by-row dot-product\n",
    "    dot_p = np.einsum('ij,ij->i',query_encoding, arg_encoding)\n",
    "    \n",
    "    query_encodings.append(query_encoding)\n",
    "    arg_encodings.append(arg_encoding)\n",
    "    dot_ps.append(dot_p)\n",
    "query_encodings = np.vstack(query_encodings)\n",
    "arg_encodings = np.vstack(arg_encodings)\n",
    "encodings = np.hstack([query_encodings, arg_encodings])\n",
    "\n",
    "#Add a column dimension to dot_ps to be able to vstack it\n",
    "dot_ps = np.vstack([item[:, np.newaxis] for item in dot_ps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1411, 1024)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForQuestionAnswering, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be6b36641664e638184e72e2d99d34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=363423424.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qa_model = TFAutoModelForQuestionAnswering.from_pretrained(MODEL_TO_USE)\n",
    "seq_model = TFAutoModelForSequenceClassification.from_pretrained(MODEL_TO_USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<transformers.modeling_tf_distilbert.TFDistilBertMainLayer at 0x7f5e1f2aeeb8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f5e1e2008d0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7f5e1e200c50>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<transformers.modeling_tf_distilbert.TFDistilBertMainLayer at 0x7f5e1e2313c8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f5e1f0fa0b8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f5e1f0fa2b0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7f5e1f0fa438>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,m in dataset.take(1):\n",
    "    thing = seq_model(i, attention_mask=m, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 2), dtype=float32, numpy=\n",
       " array([[ 0.02370459,  0.04156683],\n",
       "        [ 0.00032923, -0.02047816],\n",
       "        [ 0.03233599,  0.00640122],\n",
       "        [ 0.01530294,  0.00575107],\n",
       "        [ 0.00542534,  0.01057596],\n",
       "        [ 0.00386707,  0.0109483 ],\n",
       "        [-0.02191666, -0.01352489],\n",
       "        [ 0.05955591,  0.03452582],\n",
       "        [-0.02115268,  0.05518474],\n",
       "        [ 0.04437988,  0.03044362],\n",
       "        [ 0.01202991, -0.00052051],\n",
       "        [-0.00044268,  0.01128567],\n",
       "        [ 0.00499162,  0.03732803],\n",
       "        [ 0.03562927, -0.01012373],\n",
       "        [-0.01354843,  0.01092469],\n",
       "        [ 0.05125595,  0.00094387],\n",
       "        [ 0.03309708, -0.0178038 ],\n",
       "        [ 0.02648746,  0.01509987],\n",
       "        [ 0.05976138, -0.00176021],\n",
       "        [ 0.05338664,  0.03857746],\n",
       "        [ 0.00203231, -0.00394597],\n",
       "        [-0.01573052, -0.01564515],\n",
       "        [-0.0220802 ,  0.04258042],\n",
       "        [ 0.01276951, -0.00522505],\n",
       "        [ 0.03225153,  0.03452024],\n",
       "        [ 0.05629495,  0.03115635],\n",
       "        [ 0.07306077,  0.01959048],\n",
       "        [ 0.01971092,  0.05757003],\n",
       "        [ 0.02035066,  0.05795369],\n",
       "        [ 0.02967301,  0.07562146],\n",
       "        [ 0.01593224,  0.03164162],\n",
       "        [ 0.01321858,  0.03749076]], dtype=float32)>,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
