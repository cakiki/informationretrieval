{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from pplm_utils import *\n",
    "from transformers import AutoConfig, AutoModelWithLMHead, AutoTokenizer, BertTokenizer, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Should birth control pills be available over the counter?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using PPLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc51e1cea69f4be796a30013d49ff005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=224.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786eb074424549f186df697bc32bf8c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7987745b664f40458fb3412e8bf9df5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8789475f527745e1b2bc3447d1ec9bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "LM_MODEL_TO_USE = \"gpt2\"\n",
    "config = AutoConfig.from_pretrained(LM_MODEL_TO_USE)\n",
    "config.output_hidden_states = True\n",
    "tokenizer = AutoTokenizer.from_pretrained(LM_MODEL_TO_USE)\n",
    "lm = AutoModelWithLMHead.from_pretrained(LM_MODEL_TO_USE, config=config)\n",
    "lm.eval()    \n",
    "for param in lm.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_cond_text = tokenizer.encode(tokenizer.bos_token + query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 50s, sys: 15.6 s, total: 21min 6s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "unpert_gen_tok_text, pert_gen_tok_texts, grad_norms, loss_per_iter = full_text_generation(model=lm, tokenizer=tokenizer, context=tokenized_cond_text, bag_of_words='arg_bow', length=100, stepsize=0.04, temperature=1.5, \n",
    "                                                                                          top_k=10, num_iterations=4, grad_length=10000, horizon_length=1, gm_scale=0.85, kl_scale=0.03, repetition_penalty=1.5, gamma=1.8,\n",
    "                                                                                          no_cuda=True, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The answer is no. The FDA has not yet determined whether or how many women will need to take them, but it's expected to begin taking more in 2015 and 2016 than before that date (the agency says there are about 1 million people who have taken a pill since 2000). And while some doctors say they're concerned with unintended pregnancies because of their side effects — such as nausea after using an oral contraceptive for years without any problems—there aren't enough studies on this topic at present; most\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(unpert_gen_tok_text[0][len(tokenized_cond_text):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The American Academy of Pediatrics (AAP) has issued a statement on this issue. The AAP's position is that \"the use and availability\" or lack thereof of contraceptives should not constitute an emergency contraceptive, but rather as part to prevent pregnancy.\" This means it would have been better for women who were pregnant if they could get their pill without having unprotected sex with someone else in order make sure there was no risk associated from using them at all:\n",
      "\n",
      "  http://www-aapnewsletter\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(pert_gen_tok_texts[0][0][len(tokenized_cond_text):]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Transformer decoders with an Language Model head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_MODEL_TO_USE = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(LM_MODEL_TO_USE)\n",
    "lm = AutoModelWithLMHead.from_pretrained(LM_MODEL_TO_USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_return_sequences = 5\n",
    "query = \"I am trying to think of good arguments. Can you help me? What do you think?\"+query \n",
    "input_context_pro = [\n",
    "    \"-\"+query+\"\\n- Yes because\",\n",
    "    query+\"The answer is yes.\"\n",
    "]\n",
    "input_context_con = [\n",
    "    \"-\"+query+\"\\n- No because\",\n",
    "    query+\"The answer is no.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hallucinated:  they are safe and effective. However, there is no scientific evidence to support their use as an alternative method of contraception for women who don't want or need them (e:g., those with premenstrual syndrome). There has been some debate about whether such a pill would have any effect on pregnancy outcomes in this population; however research suggests that it may reduce risk factors associated at least partially by inhibiting ovulation during\n",
      "\n",
      "\n",
      "Hallucinated:  According to a new study published in The American Journal of Obstetrics and Gynecology, more than one-third (35%) women who have had an abortion are still using them at some point during pregnancy because they don't want to miss out on their chance for health insurance coverage if it's not covered by Medicaid or other government programs such as Social Security Disability Insurance.\"If you're pregnant with your first child,\" says\n",
      "\n",
      "\n",
      "Hallucinated:  there is no evidence that they are safe or effective in preventing pregnancy. However, some studies have shown a link between use of these drugs and increased risk for breast cancer among women who take them at least once per week during their first trimester (1⇓–3). It should also not come as too much surprise to learn from this study how little research has been done on hormonal contraception since it was approved by US\n",
      "\n",
      "\n",
      "Hallucinated:  According to a new study published in The American Journal of Obstetrics and Gynecology, more than half (48 percent) women who have had an abortion at some point during pregnancy don't know they are pregnant until after their last menstrual period—a time when there's little or nothing left for them before ovulation begins.\"This means that if you're planning on having your first child within six months from conception,\" says\n",
      "\n",
      "CPU times: user 6min 42s, sys: 2.98 s, total: 6min 45s\n",
      "Wall time: 34.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hallucinated_greedy = []\n",
    "\n",
    "for j, input_context in enumerate(chain(*[input_context_pro, input_context_con])):\n",
    "    input_ids = torch.tensor(tokenizer.encode(input_context)).unsqueeze(0)  \n",
    "    L = len(input_ids[0])\n",
    "    outputs = lm.generate(max_length=100, input_ids=input_ids, do_sample=False, num_beams=10, top_k=100 , top_p=0.4, num_return_sequences=1, temperature=1.6, repetition_penalty=20)\n",
    "    for i in range(1):\n",
    "        print('')\n",
    "        print(f'Greedilty hallucinated for query {j}: {tokenizer.decode(outputs[i][L:], skip_special_tokens=True)}')\n",
    "        print('')\n",
    "        hallucinated_greedy.append(tokenizer.decode(outputs[i][L:], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_return_sequences = 5\n",
    "input_context_pro = [\n",
    "    \"-\"+query+\"\\n- Yes because\",\n",
    "    query+\"The answer is yes.\"\n",
    "]\n",
    "input_context_con = [\n",
    "    \"-\"+query+\"\\n- No because\",\n",
    "    query+\"The answer is no.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Hallucinated 1 for query 1:  they're an option, I have been in a relationship for years and still feel that way about them but this doesn't mean anything without some kind (but\n",
      " \n",
      " \n",
      "Hallucinated 2 for query 1:  they are very easy, if not impossible... You will have plenty at home and in your office so we don't need any problems with women going out into\n",
      " \n",
      " \n",
      "Hallucinated 3 for query 1:  it can cause infertility, and I've had some doctors say no but they'd prefer for a small dose on its own anyway so that we could keep an\n",
      " \n",
      " \n",
      "Hallucinated 4 for query 1:  they are so popular and I want my children with no side effects at all! They work great in pregnancy, it helps your baby's brain cells become stronger\n",
      " \n",
      " \n",
      "Hallucinated 5 for query 1:  they work so well for my breasts that I just can't go anywhere without one on and off every day - this is why people have tried them (they\n",
      " \n",
      " \n",
      "Hallucinated 1 for query 2:  The only way I can get a contraceptive in that amount and not have one thrown at my door would definitely take up space, so there are no reasons for\n",
      " \n",
      " \n",
      "Hallucinated 2 for query 2:  Birth Control can make your body better, reduce side effects and increase sex drive in women who want it more than those without.\"\n",
      "\n",
      "\n",
      "\"You're talking\n",
      " \n",
      " \n",
      "Hallucinated 3 for query 2:  The pill that we are discussing here could easily make your life more manageable with some form, and not require prescription medications for pregnancy or childbirth.\"This can work\n",
      " \n",
      " \n",
      "Hallucinated 4 for query 2:  The reason we have been discussing these options for a long time was that they didn't provide women with enough information on their own health or safety when choosing whether\n",
      " \n",
      " \n",
      "Hallucinated 5 for query 2: \n",
      "It depends on your age, health condition and level:On Monday night at a Republican rally in Cleveland for his party's 2016 nominee Hillary Clinton he\n",
      " \n",
      " \n",
      "Hallucinated 1 for query 3:  they can cause hormonal problems that would not work on women who are using them as well, or for those with low libido (like men) and want\n",
      " \n",
      " \n",
      "Hallucinated 2 for query 3:  there's a lack on women who don't need them, but I'll take your argument seriously when my time comes and let ya know that is not true\n",
      " \n",
      " \n",
      "Hallucinated 3 for query 3:  I don't know what's better than not being told that if my husband is having unprotected sex with a non condom, it won (that we have an\n",
      " \n",
      " \n",
      "Hallucinated 4 for query 3:  it can cause a lot, and even if there are many things I want (and what is wrong with my baby) in moderation...but as long As\n",
      " \n",
      " \n",
      "Hallucinated 5 for query 3:  it is a medication used for treating some kind or other health condition, and not as prescribed in general medical practices like chiropractic services where there's no\n",
      " \n",
      " \n",
      "Hallucinated 1 for query 4:  As long as women are being offered contraceptive methods in general and not just those they have already given their consent, I can't support a change because there's\n",
      " \n",
      " \n",
      "Hallucinated 2 for query 4:  Birth Control pill use should never have a higher than 6% chance that your baby's going in with diabetes or cancer.\"\n",
      "If I was on this list\n",
      " \n",
      " \n",
      "Hallucinated 3 for query 4:  No, because in a healthy environment people don't become infected with this disease if their family member isn\"s right and he knows they have health problems,\"\n",
      " \n",
      " \n",
      "Hallucinated 4 for query 4:  But we need more evidence and a public debate about what constitutes safe use, whether they should or shouldn't exist,\" he said in his blog post.\"There\n",
      " \n",
      " \n",
      "Hallucinated 5 for query 4:  But there's another argument I've heard that could explain why women get sick or die before they start menstruating because their bodies are in a better state for\n",
      " \n",
      "CPU times: user 10min 41s, sys: 6.94 s, total: 10min 48s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hallucinated_sampling = []\n",
    "\n",
    "for j, input_context in enumerate(chain(*[input_context_pro, input_context_con])):\n",
    "    input_ids = torch.tensor(tokenizer.encode(input_context)).unsqueeze(0)  # encode input context\n",
    "    L = len(input_ids[0])\n",
    "    outputs = lm.generate(max_length=65, input_ids=input_ids, do_sample=True, num_beams=10, top_k=100 , top_p=0.4, num_return_sequences=num_return_sequences, temperature=1.6, repetition_penalty=20)\n",
    "    for i in range(num_return_sequences): \n",
    "        print(\" \")\n",
    "        print(f'Hallucinated {i+1} for query {j+1}: {tokenizer.decode(outputs[i][L:], skip_special_tokens=True)}')\n",
    "        print(\" \")\n",
    "        hallucinated_sampling.append(tokenizer.decode(outputs[i][L:], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   12,    40,   716,  2111,   284,   892,   286,   922,  7159,    13,\n",
       "          1680,   345,  1037,   502,    30,  1867,   466,   345,   892,    30,\n",
       "            40,   716,  2111,   284,   892,   286,   922,  7159,    13,  1680,\n",
       "           345,  1037,   502,    30,  1867,   466,   345,   892,    30,    40,\n",
       "           716,  2111,   284,   892,   286,   922,  7159,    13,  1680,   345,\n",
       "          1037,   502,    30,  1680,   345,   892,   286,   922,  7159,    30,\n",
       "         10358,  4082,  1630, 19521,   307,  1695,   625,   262,  3753,    30,\n",
       "           198,    12,  3363,   780]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.generate(input_ids=input_ids, do_sample=True, top_k=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Transformer encoders with a Masked Language Model head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve a list of stopwords by computing the union of the respective stop word lists of Scikit-learn, Spacy and NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as SKLEARN_STOPWORDS\n",
    "SKLEARN_STOPWORDS = set(SKLEARN_STOPWORDS)\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as SPACY_STOPWORDS\n",
    "\n",
    "import nltk\n",
    "from ipywidgets import Output\n",
    "out = Output()\n",
    "with out:\n",
    "    nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "NLTK_STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "STOP_WORDS = set.union(*[SKLEARN_STOPWORDS, SPACY_STOPWORDS, NLTK_STOPWORDS])\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2859ed33a9f4e32b7a851b2fe9ca464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb4bd3b589640d7a96640a3fe753f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=362.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f271f76792ca4565bec405abf5515aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1344997306.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Should churches be taxed?\"\n",
    "query = \"I can't think of any arguments, can you help me? \"+ query\n",
    "\n",
    "input_context_pro = [\n",
    "    '-'+query+'\\n-Yes, because of [MASK] and the benefits of [MASK] [MASK].',\n",
    "    '-'+query+'\\n-Absolutely, I think [MASK] is good!.',\n",
    "    \"-\"+query+\"\\n-Yes, [MASK] is associated with [MASK] during [MASK].\"\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "input_context_con = [\n",
    "    '-'+query+'\\n-No, because of [MASK] and the risk of [MASK] [MASK].',\n",
    "    '-'+query+'\\n-Absolutely not, I think [MASK] is bad!.',\n",
    "    \"-\"+query+\"\\n-No, [MASK] is associated with [MASK] during [MASK].\"\n",
    "]\n",
    "\n",
    "input_context_neutral = [\n",
    "    query+' What about [MASK] or [MASK]?',\n",
    "    query+\" Don't forget about [MASK]!\"\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.6 s, sys: 890 ms, total: 36.5 s\n",
      "Wall time: 2.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hallucinations = []\n",
    "for input_context in chain(*[input_context_pro, input_context_con, input_context_neutral]):\n",
    "    inp_tens = torch.tensor(tokenizer.encode(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(input_context)))).unsqueeze(0)\n",
    "    mask_indices = np.nonzero(inp_tens.squeeze()==103).squeeze()\n",
    "    preds = model(inp_tens)[0].squeeze()\n",
    "    mask_indices = [mask_indices.tolist()] if type(mask_indices.tolist())!=list else mask_indices.tolist()\n",
    "    top_words = []\n",
    "    for i in mask_indices:\n",
    "        top_words.append(torch.topk(preds[i], k=5))\n",
    "    words = []\n",
    "    for mask_topk in top_words:\n",
    "        for token in mask_topk.indices.tolist():\n",
    "            words.append(tokenizer.decode(token, clean_up_tokenization_spaces=True))\n",
    "        #Interestingly, BERT was returning the ##carriage subword, obviously part of \"miscarriage\" in the \"pregnancy\" context. Further investigation needed to see how to return the full of word. Filtering out subwords for now.\n",
    "        #Filter out subwords\n",
    "        words = [word.replace(\" \",\"\") for word in words if not word.startswith(\"#\")]\n",
    "        words = [word for word in words if not word.endswith(\"#\")]\n",
    "        #Filter out punctuation\n",
    "        words = [word for word in words if not word in punctuation]\n",
    "    words = set(words)\n",
    "    words = list(words.difference(STOP_WORDS))\n",
    "    hallucinations.extend(words)\n",
    "hallucinations = set(hallucinations)\n",
    "hallucinations = list(hallucinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['religion',\n",
       " 'poverty',\n",
       " 'attendance',\n",
       " 'public',\n",
       " 'economics',\n",
       " 'land',\n",
       " 'money',\n",
       " 'prayer',\n",
       " 'death',\n",
       " 'church',\n",
       " 'consumption',\n",
       " 'easter',\n",
       " 'good',\n",
       " 'free',\n",
       " 'tax',\n",
       " 'lent',\n",
       " 'churches',\n",
       " 'property',\n",
       " 'costs',\n",
       " 'mass',\n",
       " 'education',\n",
       " 'exposure',\n",
       " 'financial',\n",
       " 'christmas',\n",
       " 'schools',\n",
       " 'festivals',\n",
       " 'work',\n",
       " 'women',\n",
       " 'taxes',\n",
       " 'religious',\n",
       " 'unemployment',\n",
       " 'bankruptcy',\n",
       " 'legal',\n",
       " 'services']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['religion',\n",
       " 'poverty',\n",
       " 'faith',\n",
       " 'land',\n",
       " 'money',\n",
       " 'prayer',\n",
       " 'death',\n",
       " 'cost',\n",
       " 'church',\n",
       " 'conversion',\n",
       " 'worship',\n",
       " 'free',\n",
       " 'tax',\n",
       " 'lent',\n",
       " 'legal',\n",
       " 'collapse',\n",
       " 'churches',\n",
       " 'property',\n",
       " 'costs',\n",
       " 'mass',\n",
       " 'wartime',\n",
       " 'housing',\n",
       " 'living',\n",
       " 'education',\n",
       " 'financial',\n",
       " 'christmas',\n",
       " 'schools',\n",
       " 'tourism',\n",
       " 'festivals',\n",
       " 'taxes',\n",
       " 'religious',\n",
       " 'attendance',\n",
       " 'corruption',\n",
       " 'services']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Should the Federal Minimum Wage Be Increased?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inflation', 'labor', 'taxes', 'immigration', 'congress']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"-\"+query+\"\\n-Yes, it's not too late because of [MASK] [MASK]\"]\n",
    "hallucinations = []\n",
    "for input_context in chain(*[test]):\n",
    "    inp_tens = torch.tensor(tokenizer.encode(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(input_context)))).unsqueeze(0)\n",
    "    mask_indices = np.nonzero(inp_tens.squeeze()==103).squeeze()\n",
    "    preds = model(inp_tens)[0].squeeze()\n",
    "    mask_indices = [mask_indices.tolist()] if type(mask_indices.tolist())!=list else mask_indices.tolist()\n",
    "    top_words = []\n",
    "    for i in mask_indices:\n",
    "        top_words.append(torch.topk(preds[i], k=10))\n",
    "    words = []\n",
    "    for mask_topk in top_words:\n",
    "        for token in mask_topk.indices.tolist():\n",
    "            words.append(tokenizer.decode(token, clean_up_tokenization_spaces=True))\n",
    "        #Interestingly, BERT was returning the ##carriage subword, obviously part of \"miscarriage\" in the \"pregnancy\" context. Further investigation needed to see how to return the full of word. Filtering out subwords for now.\n",
    "        #Filter out subwords\n",
    "        words = [word.replace(\" \",\"\") for word in words if not word.startswith(\"#\")]\n",
    "        words = [word for word in words if not word.endswith(\"#\")]\n",
    "        #Filter out punctuation\n",
    "        words = [word for word in words if not word in [*punctuation, \"...\"]]\n",
    "    words = set(words)\n",
    "    words = list(words.difference(STOP_WORDS))\n",
    "    hallucinations.extend(words)\n",
    "hallucinations = set(hallucinations)\n",
    "hallucinations = list(hallucinations)\n",
    "hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wars',\n",
       " 'pollution',\n",
       " 'death',\n",
       " 'consumption',\n",
       " 'climate',\n",
       " 'risk',\n",
       " 'water',\n",
       " 'development',\n",
       " 'warming',\n",
       " 'growth',\n",
       " 'summer',\n",
       " 'energy',\n",
       " 'emissions',\n",
       " 'migration',\n",
       " 'winter',\n",
       " 'construction',\n",
       " 'health',\n",
       " 'deaths',\n",
       " 'drought',\n",
       " 'mortality',\n",
       " 'pregnancy',\n",
       " 'wartime']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abortion',\n",
       " 'drugs',\n",
       " 'condoms',\n",
       " 'alcohol',\n",
       " 'pills',\n",
       " 'babies',\n",
       " 'children',\n",
       " 'men',\n",
       " 'women',\n",
       " 'money',\n",
       " 'kids',\n",
       " 'sex',\n",
       " 'insurance']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_context = \"-\"+query+\"\\n-But what about [MASK]?\"\n",
    "inp_tens = torch.tensor(tokenizer.encode(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(input_context)))).unsqueeze(0)\n",
    "mask_indices = np.nonzero(inp_tens.squeeze()==103).squeeze()\n",
    "preds = model(inp_tens)[0].squeeze()\n",
    "mask_indices = [mask_indices.tolist()] if type(mask_indices.tolist())!=list else mask_indices.tolist()\n",
    "top_words = []\n",
    "for i in mask_indices:\n",
    "    top_words.append(torch.topk(preds[i], k=20))\n",
    "words = []\n",
    "tokens = []\n",
    "for mask_topk in top_words:\n",
    "    for token in mask_topk.indices.tolist():\n",
    "        tokens.append(token)\n",
    "        words.append(tokenizer.decode(token, clean_up_tokenization_spaces=True))\n",
    "    words = [word.replace(\" \",\"\") for word in words if not word.startswith(\"#\")]\n",
    "words = set(words)\n",
    "words = list(words.difference(STOP_WORDS))\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doctor',\n",
       " 'condoms',\n",
       " 'pills',\n",
       " 'prescription',\n",
       " 'pill',\n",
       " 'medication',\n",
       " 'baby',\n",
       " 'stuff',\n",
       " 'condom',\n",
       " 'sex',\n",
       " 'medicine']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_context = \"-\"+query+\"\\n-Don't forget about [MASK] [MASK].\"\n",
    "inp_tens = torch.tensor(tokenizer.encode(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(input_context)))).unsqueeze(0)\n",
    "mask_indices = np.nonzero(inp_tens.squeeze()==103).squeeze()\n",
    "preds = model(inp_tens)[0].squeeze()\n",
    "mask_indices = [mask_indices.tolist()] if type(mask_indices.tolist())!=list else mask_indices.tolist()\n",
    "top_words = []\n",
    "for i in mask_indices:\n",
    "    top_words.append(torch.topk(preds[i], k=10))\n",
    "words = []\n",
    "tokens = []\n",
    "for mask_topk in top_words:\n",
    "    for token in mask_topk.indices.tolist():\n",
    "        tokens.append(token)\n",
    "        words.append(tokenizer.decode(token, clean_up_tokenization_spaces=True))\n",
    "    words = [word.replace(\" \",\"\") for word in words if not word.startswith(\"#\")]\n",
    "words = set(words)\n",
    "words = list(words.difference(STOP_WORDS))\n",
    "words =[word for word in words if len(word)>1]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abortion', 'drugs', 'condoms', 'pills', 'babies', 'prostitution', 'sex']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_context = query+\"I don't believe in [MASK].\"\n",
    "inp_tens = torch.tensor(tokenizer.encode(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(input_context)))).unsqueeze(0)\n",
    "mask_indices = np.nonzero(inp_tens.squeeze()==103).squeeze()\n",
    "preds = model(inp_tens)[0].squeeze()\n",
    "mask_indices = [mask_indices.tolist()] if type(mask_indices.tolist())!=list else mask_indices.tolist()\n",
    "top_words = []\n",
    "for i in mask_indices:\n",
    "    top_words.append(torch.topk(preds[i], k=10))\n",
    "words = []\n",
    "tokens = []\n",
    "for mask_topk in top_words:\n",
    "    for token in mask_topk.indices.tolist():\n",
    "        tokens.append(token)\n",
    "        words.append(tokenizer.decode(token, clean_up_tokenization_spaces=True))\n",
    "    words = [word.replace(\" \",\"\") for word in words if not word.startswith(\"#\")]\n",
    "words = set(words)\n",
    "words = list(words.difference(STOP_WORDS))\n",
    "words =[word for word in words if len(word)>1]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string.pu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
