{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from pplm_utils import *\n",
    "from transformers import AutoConfig, AutoModelWithLMHead, AutoTokenizer, BertTokenizer, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Should birth control pills be available over the counter?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using PPLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argumentation Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accept', 'according', 'accordingly', 'affirm', 'agree', 'argue', 'argument', 'argumentation', 'assert', 'assumption', 'attack', 'attest', 'backing', 'basis', 'because', 'belief', 'believe', 'bias', 'biased', 'challenge', 'cite', 'claim', 'clear', 'con', 'concede', 'conclude', 'conclusion', 'concur', 'consequence', 'consequently', 'considering', 'context', 'controversial', 'convince', 'corroborate', 'convincing', 'corroboration', 'credibility', 'credible', 'criteria', 'criterion', 'debatable', 'debate', 'deduce', 'definition', 'determine', 'disagree', 'disprove', 'ergo', 'evidence', 'example', 'facts', 'fallacy', 'fallible', 'faulty', 'general', 'hence', 'hypothetical', 'imply', 'inconsistent', 'infer', 'irrelevant', 'justify', 'knowledge', 'logical', 'naturally', 'objectively ', 'opinion', 'perspective', 'persuade', 'persuasive', 'point', 'position', 'precisely', 'premise', 'pro', 'probable', 'proof', 'prove', 'rational', 'reason', 'rebuttal', 'reiterate', 'relevant', 'rhetoric', 'rhetorical', 'right', 'rumors', 'sure', 'surely', 'skeptical', 'skepticsm', 'sources', 'specific', 'stance', 'statistically', 'statistics', 'study', 'subjective ', 'subjectively', 'suppose', 'testimonial', 'theory', 'therefore', 'thesis', 'think', 'thought', 'thus', 'trustworthy', 'unconvinced', 'undermine', 'unsubstantiated', 'valid', 'warrant', 'whereas', 'wrong']\n"
     ]
    }
   ],
   "source": [
    "with open('arg_bow') as f:\n",
    "    bow = f.read().splitlines()\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c805524cc361425a9536b2c4c1e94652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=224.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc518c48f9040bf8df22edc56b7743a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e567e90d5cc5460c981bd0ab30cf0d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06bcd8a97cbb4e7ea5c096f70b75f553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "LM_MODEL_TO_USE = \"gpt2\"\n",
    "config = AutoConfig.from_pretrained(LM_MODEL_TO_USE)\n",
    "config.output_hidden_states = True\n",
    "tokenizer = AutoTokenizer.from_pretrained(LM_MODEL_TO_USE)\n",
    "lm = AutoModelWithLMHead.from_pretrained(LM_MODEL_TO_USE, config=config)\n",
    "lm.eval()    \n",
    "for param in lm.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "query= \"Should Performance Enhancing Drugs Be Accepted in Sports?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", I believe that because it is a medical necessity. Because of this reason why we have to make sure people who are not able to afford them know about these products and they can't buy from us or even if there's no problem with their health care provider for some reasons like so many other things in life but also due to fear as well which means more money being spent on drugs than any kind since all those costs would go towards making up what was lost by having women get abortions instead just cause when men don´t want children then maybe something else will happen where one side has an advantage while another doesn` t see how much difference between two sides at least until after abortion comes out now right before everyone realizes otherwise i mean really let me say here first thing most probably my opinion based off research shows only 2% chance (because its true) 1/2 = 0 meaning 3 times less likely compared wtf im thinking bc thats pretty obvious becuase u dont understand whats wrong btw your saying \"if\" yes every woman should feel bad she doesnt need contraception unless her husband wants sex he needs his wife too lol ok okay yeah yea man thanks dude thank god hes talking good enough haha sorry guys please stop trying hard telling others tell him shit anyway lets start asking questions honestly ask yourself question: Why does someone choose pregnancy insurance? Is anyone going crazy believing such nonsense?? If somebody says 'I am pregnant',then guess again imagine whether person believes same way. But wait till later :P<|endoftext|>The following article originally appeared under permission given through our affiliate links below! We're excitedly hoping readers find ways around using Google Analytics data without worrying either; however…we've been looking into getting rid simply via email marketing campaigns—and seeing results come back very quickly once users click onto certain ads within seconds rather knowing exactly WHY each time...so far….but unfortunately today marks day three – especially considering recent trends regarding social media analytics including Facebook Messenger integration — wherein marketers were forced downplaying concerns raised during last week′s conference call among members concerned primarily related specifically concerning privacy rights issues associated solelywith Twitter accounts belongingto advertisers.\"Because,\" said Mark Zuckerberg himself,\"the fact remains [that] millions upon thousands of Americans use Social Media platforms …[which], according Toowoomba County Sheriff John Kollman told The Daily Beast had led several law enforcement agencies across America […] In order to protect against potential criminal activity involving personal information collected pursuant thereto\", Mr Klein added.\"We thought perhaps better\n",
      "CPU times: user 11h 6min 35s, sys: 6min 40s, total: 11h 13min 16s\n",
      "Wall time: 53min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_cond_text = tokenizer.encode(\"- What do you think? \" + query + \"\\n- Yes\")\n",
    "unpert_gen_tok_text, pert_gen_tok_texts, grad_norms, loss_per_iter = full_text_generation(model=lm, tokenizer=tokenizer, context=tokenized_cond_text, bag_of_words='arg_bow',\n",
    "                                                                                          length=500, stepsize=0.03, temperature=1.1, \n",
    "                                                                                          top_k=15, num_iterations=15, num_samples=2, grad_length=1000, horizon_length=5,\n",
    "                                                                                          gm_scale=0.9, kl_scale=0.7, repetition_penalty=2, gamma=1.5,\n",
    "                                                                                          no_cuda=True, device=\"cpu\")\n",
    "print(tokenizer.decode(pert_gen_tok_texts[0][0][len(tokenized_cond_text):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". I don't know if it's because of the fact that they're not as popular, but maybe due to their popularity and so on… Maybe there is a reason why people are more interested when athletes say \"because\" or something like this:\n",
      "CPU times: user 36min 24s, sys: 35.8 s, total: 37min\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenized_cond_text = tokenizer.encode(\"- What do you think? \" + query + \"\\n- No\")\n",
    "unpert_gen_tok_text, pert_gen_tok_texts, grad_norms, loss_per_iter = full_text_generation(model=lm, tokenizer=tokenizer, context=tokenized_cond_text, bag_of_words='arg_bow',\n",
    "                                                                                          length=50, stepsize=0.03, temperature=1.1, \n",
    "                                                                                          top_k=5, num_iterations=15, num_samples=2, grad_length=1000, horizon_length=5,\n",
    "                                                                                          gm_scale=0.9, kl_scale=0.7, repetition_penalty=2, gamma=1.5,\n",
    "                                                                                          no_cuda=True, device=\"cpu\")\n",
    "print(tokenizer.decode(pert_gen_tok_texts[0][0][len(tokenized_cond_text):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". I'm not really a fan of it, but if they're going to accept this because there's no evidence that the drugs are harmful then why should we be accepting them for sports reasons as well when all athletes who have been tested on performance enhancing\n",
      "CPU times: user 36min 44s, sys: 37 s, total: 37min 21s\n",
      "Wall time: 3min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenized_cond_text = tokenizer.encode(\"- What do you think? \" + query + \"\\n- Not sure\")\n",
    "unpert_gen_tok_text, pert_gen_tok_texts, grad_norms, loss_per_iter = full_text_generation(model=lm, tokenizer=tokenizer, context=tokenized_cond_text, bag_of_words='arg_bow',\n",
    "                                                                                          length=50, stepsize=0.03, temperature=1.1, \n",
    "                                                                                          top_k=5, num_iterations=15, num_samples=2, grad_length=1000, horizon_length=5,\n",
    "                                                                                          gm_scale=0.9, kl_scale=0.7, repetition_penalty=2, gamma=1.5,\n",
    "                                                                                          no_cuda=True, device=\"cpu\")\n",
    "print(tokenizer.decode(pert_gen_tok_texts[0][0][len(tokenized_cond_text):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". But it's a good idea because if they're not accepted then there is no reason to believe that the drugs are safe and effective, so why should we accept them when people who have been wrong about these things for years now can be right again\n",
      "CPU times: user 37min 22s, sys: 39.6 s, total: 38min 1s\n",
      "Wall time: 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenized_cond_text = tokenizer.encode(\"- What do you think? \" + query + \"\\n- I don't know\")\n",
    "unpert_gen_tok_text, pert_gen_tok_texts, grad_norms, loss_per_iter = full_text_generation(model=lm, tokenizer=tokenizer, context=tokenized_cond_text, bag_of_words='arg_bow',\n",
    "                                                                                          length=50, stepsize=0.03, temperature=1.1, \n",
    "                                                                                          top_k=5, num_iterations=15, num_samples=2, grad_length=1000, horizon_length=5,\n",
    "                                                                                          gm_scale=0.9, kl_scale=0.7, repetition_penalty=2, gamma=1.5,\n",
    "                                                                                          no_cuda=True, device=\"cpu\")\n",
    "print(tokenizer.decode(pert_gen_tok_texts[0][0][len(tokenized_cond_text):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". But it's a good idea to have them, and if they're not accepted then we'll see what happens with the sport of sports medicine.\"<|endoftext|>The UESPWiki – Your source for The Elder Scrolls since 1995\n",
      "\n",
      " (click here)\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(unpert_gen_tok_text[0][len(tokenized_cond_text):]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Transformer decoders with a Language Model head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_MODEL_TO_USE = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(LM_MODEL_TO_USE)\n",
    "lm = AutoModelWithLMHead.from_pretrained(LM_MODEL_TO_USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What do you think?\"+query \n",
    "input_context_pro = [\n",
    "    \"- \"+query+\"\\n- Yes because\",\n",
    "    query+\"The answer is yes.\"\n",
    "]\n",
    "input_context_con = [\n",
    "    \"- \"+query+\"\\n- No because\",\n",
    "    query+\"The answer is no.\"\n",
    "]\n",
    "\n",
    "input_context_neutral = [\n",
    "    \"- \" + query + \"\\n- I don't know\",\n",
    "    \"- \" + query + \"\\n- Not sure\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Greedily hallucinated for query 0:\n",
      "  they are safe and effective. They can be used to treat a wide range of health conditions, including diabetes mellitus (DM), hypertension/hypercholesterolemia / type 2 diabetics (HDIs) etc., as well the most common types of cardiovascular disease like heart attack or stroke [1]. There is no evidence that performance enhancing\n",
      "\n",
      "\n",
      "Greedily hallucinated for query 1:\n",
      "  They should be accepted as a part of the sport, and they shouldn't have to compete against other athletes who are competing at higher levels than them.\"\n",
      "\"There's no question that performance enhancing drugs (PEDs) can help people improve their athletic ability,\" he said during an interview with ESPN FC on Wednesday night after his team won 2\n",
      "\n",
      "\n",
      "Greedily hallucinated for query 2:\n",
      "  I don't believe it should be accepted as a medical condition.I'm not saying that performance enhancing drugs are bad for your health, but if they're given to athletes who need them the most then there's no reason why this shouldn'a never been considered medically acceptable by sports medicine or any other professional bodybuilder/athletic group (\n",
      "\n",
      "\n",
      "Greedily hallucinated for query 3:\n",
      "  In fact, it's not even close to being accepted by the scientific community as a safe and effective treatment for chronic fatigue syndrome (CFS) or any other type of muscle wasting disease that can be caused by exercise-induced hypertrophy.[1]\n",
      "[2][3]: http://www... [4](http:...)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Greedily hallucinated for query 4:\n",
      "  if they should be accepted or not, but it's something that needs to happen. If there is a problem with performance enhancing drugs then we need more research on this topic and better understanding of how these substances work so people can make informed decisions about their use based upon what works best for them at the time. It would also help us\n",
      "\n",
      "\n",
      "Greedily hallucinated for query 5:\n",
      "  if this is a good idea or not, but I don't see any reason why it should be accepted as such.I would like to hear your thoughts on the topic of performance enhancing drugs and how they can help athletes improve their athletic ability by helping them get better at running faster than ever before!Please let me know what questions/comments are\n",
      "\n",
      "CPU times: user 8min 5s, sys: 3.11 s, total: 8min 8s\n",
      "Wall time: 41.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hallucinated_greedy = []\n",
    "\n",
    "for j, input_context in enumerate(chain(*[input_context_pro, input_context_con, input_context_neutral])):\n",
    "    input_ids = torch.tensor(tokenizer.encode(input_context)).unsqueeze(0)  \n",
    "    L = len(input_ids[0])\n",
    "    outputs = lm.generate(max_length=100, input_ids=input_ids, do_sample=False, num_beams=10, top_k=100 , top_p=0.4, num_return_sequences=1, temperature=1.6, repetition_penalty=20)\n",
    "    for i in range(1):, \n",
    "        print('')\n",
    "        print(f'Greedily hallucinated for query {j}:\\n {tokenizer.decode(outputs[i][L:], skip_special_tokens=True)}')\n",
    "        print('')\n",
    "        hallucinated_greedy.append(tokenizer.decode(outputs[i][L:], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_return_sequences = 3\n",
    "input_context_pro = [\n",
    "    \"-\"+query+\"\\n- Yes because\",\n",
    "    query+\"The answer is yes.\"\n",
    "]\n",
    "input_context_con = [\n",
    "    \"-\"+query+\"\\n- No because\",\n",
    "    query+\"The answer is no.\"\n",
    "]\n",
    "\n",
    "input_context_neutral = [\n",
    "    \"- \" + query + \"\\n- I don't know\",\n",
    "    \"- \" + query + \"\\n- Not sure\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Hallucinated 1 for query 1:  they help keep your body from becoming overly stressed or over stimulated and prevent excessive sore muscles. I personally feel that the use of these substances has helped with my physical condition since its inception but unfortunately some people are still not convinced by it, which is why this page needs to be updated so more accurate information can become available on a daily basis\n",
      "\n",
      " \"\n",
      " \n",
      " \n",
      "Hallucinated 2 for query 1:  they help the brain to recognize patterns and understand what's going on within it, which is really beneficial. -No Because these drugs may not work if given daily as part of an ongoing program or practice regimen that might reduce risk from chronic disease. There are some reports showing a significant improvement for those who take them, although I've heard anecdotal evidence\n",
      " \n",
      " \n",
      "Hallucinated 3 for query 1:  it will prevent injury or brain damage and make the sport safer for athletes. -No, we won't tolerate drugs used by doping agents such as DDT's that have been linked to many cancers due both of them having a long history from exposure but still causing serious adverse side effects including liver cancer (as seen with Parkinson), renal failure which can\n",
      " \n",
      " \n",
      "Hallucinated 1 for query 2:  I've heard that the NFL has been trying to legalize drugs for decades, and it's now a national sport (which we're not talking about here), but what does this all mean on its own terms as well if people are allowed by professional sports leagues—the league must get off their backs at least once or twice before any of them could\n",
      " \n",
      " \n",
      "Hallucinated 2 for query 2:  Athletes can achieve a level that the athletes would have achieved with drugs they were never aware of before, if we take them into consideration for performance enhancing medicine.\"Dr John Gaddis: \"Athletics need to understand how their body and its natural response system works as it responds after injuries or even post injury problems like depression which affects\n",
      " \n",
      " \n",
      "Hallucinated 3 for query 2:  But there are also issues that need to be addressed, so the current state of science doesn't really address them yet (if ever) but it's important for athletes and coaches alike because this information has been gathered from a lot more than just one single source which should help us all get on with our training process over time.\"\n",
      "1/5\n",
      " \n",
      " \n",
      "Hallucinated 1 for query 3:  it doesn't matter. You just need to listen carefully and see how they work out for yourself, not the sport or your teammates who want a piece of advice from them!\n",
      "\n",
      "In this photo provided by CBS News reporter Scott Adams shows President Donald Trump during an appearance on \"60 Minutes\" with anchor Chris Wallace Thursday June 29th at Lincoln\n",
      " \n",
      " \n",
      "Hallucinated 2 for query 3:  of medical and scientific issues but this is a very difficult question that needs answers.We've known for years, over the course about 10 months or more as I have worked with various teams to create what we call \"A New World.\" We started off at Seattle University where our philosophy was simple - if it isn't already there on an actual\n",
      " \n",
      " \n",
      "Hallucinated 3 for query 3:  they are not proven to improve performance or health but it's an easy option and is something we need more information about. We will consider these substances if necessary as research can be made into a safer drug based on its potential for treating diseases related, among others such conditions like cancer, cardiovascular disease.We have developed protocols that allow the FDA (Food\n",
      " \n",
      " \n",
      "Hallucinated 1 for query 4:  However it should be done by those who are most concerned about their athletes' performance, as a last resort when taking these drugs or others such that they may have an adverse reaction and require additional training for optimal athletic results.\"I don't want people to go into what I'm going through with the steroids,\" said Mr Deaton after his meeting at\n",
      " \n",
      " \n",
      "Hallucinated 2 for query 4:  A small number of scientists, and athletes themselves, have argued that the scientific community needs to take an active role with sport doping as it becomes a new frontier for drug testing across society.\"This means more work being done on how we can improve performance enhancement,\" says Professor Jens Høgg-Kauf at Uppsala University where he\n",
      " \n",
      " \n",
      "Hallucinated 3 for query 4:  In order to ensure a competitive environment and high level of performance, these drugs need not be administered through injection by physicians who have had experience treating sports injuries with their own medications.\"\n",
      "\n",
      "\n",
      "This study confirms the results from our earlier studies that showed higher rates for lower extremity injury compared those treated via ACE inhibitors (see also here) on steroids as\n",
      " \n",
      " \n",
      "Hallucinated 1 for query 5: , maybe it would be nice to have a better answer if we could get some information about the side effects that people are getting from performance enhancing drugs. But again this is just conjecture on my part and nothing official for sure as of right now at least so far...\n",
      "\n",
      "\"You're not going out there trying hard enough because they won\n",
      " \n",
      " \n",
      "Hallucinated 2 for query 5:  what the issue is. Is it a problem with my own body, or just for sport performance purposes - would anyone please be open to this idea?! The answer should definitely have been yes!The National Security Agency's controversial collection of personal data on U..s foreign visitors will soon go up again and we've already seen similar stories\n",
      " \n",
      " \n",
      "Hallucinated 3 for query 5: . Do your studies and medical tests on athletes change any of that, because we've had a lot more evidence now than ever before regarding performance enhancement drugs (like this?)? Should the sport take it up with those scientists who have proven them to be effective for years so they're not trying something else anymore as well. Are these some\n",
      " \n",
      " \n",
      "Hallucinated 1 for query 6:  what to say.\n",
      "\n",
      " - Posted by: Anonymous on February 13rd, 2017 | Comments (3 ) Reply Quote Quick Question Submit Answer As long as they are used consistently with no side effects and good quality packaging the athletes have excellent athletic performance...they should be taken care of well or at least considered seriously if their sportsmanship comes from them..\n",
      " \n",
      " \n",
      "Hallucinated 2 for query 6:  what your question is about performance enhancing drugs. I don't know whether they should be accepted, and that would probably affect their ability to compete professionally with athletes from other countries who aren\" (Gee)By Dr William Pritchett & Robert Dyson | November 23rd 2015 11:46AM EST By Prof Stephen Silliman\n",
      " \n",
      " \n",
      "Hallucinated 3 for query 6: . But this one would make me want to try it myself..I'm a guy that loves watching sports, so the first thing I did after seeing Drs is just take some painkillers like Vicodin and ibuprofen before playing games or anything else but my knees ached really badly from all those injuries which are causing them very\n",
      " \n",
      "CPU times: user 21min 20s, sys: 16.4 s, total: 21min 36s\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hallucinated_sampling = []\n",
    "\n",
    "for j, input_context in enumerate(chain(*[input_context_pro, input_context_con, input_context_neutral])):\n",
    "    input_ids = torch.tensor(tokenizer.encode(input_context)).unsqueeze(0)  # encode input context\n",
    "    L = len(input_ids[0])\n",
    "    outputs = lm.generate(max_length=100, input_ids=input_ids, do_sample=True, num_beams=10, top_k=100 , top_p=0.4, num_return_sequences=num_return_sequences, temperature=1.6, repetition_penalty=20)\n",
    "    for i in range(num_return_sequences): \n",
    "        print(\" \")\n",
    "        print(f'Hallucinated {i+1} for query {j+1}: {tokenizer.decode(outputs[i][L:], skip_special_tokens=True)}')\n",
    "        print(\" \")\n",
    "        hallucinated_sampling.append(tokenizer.decode(outputs[i][L:], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Transformer encoders with a Masked Language Model head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve a list of stopwords by computing the union of the respective stop word lists of Scikit-learn, Spacy and NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as SKLEARN_STOPWORDS\n",
    "SKLEARN_STOPWORDS = set(SKLEARN_STOPWORDS)\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as SPACY_STOPWORDS\n",
    "\n",
    "import nltk\n",
    "from ipywidgets import Output\n",
    "out = Output()\n",
    "with out:\n",
    "    nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "NLTK_STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "STOP_WORDS = set.union(*[SKLEARN_STOPWORDS, SPACY_STOPWORDS, NLTK_STOPWORDS])\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2859ed33a9f4e32b7a851b2fe9ca464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb4bd3b589640d7a96640a3fe753f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=362.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f271f76792ca4565bec405abf5515aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1344997306.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Should churches be taxed?\"\n",
    "query = \"I can't think of any arguments, can you help me? \"+ query\n",
    "\n",
    "input_context_pro = [\n",
    "    '-'+query+'\\n-Yes, because of [MASK] and the benefits of [MASK] [MASK].',\n",
    "    '-'+query+'\\n-Absolutely, I think [MASK] is good!.',\n",
    "    \"-\"+query+\"\\n-Yes, [MASK] is associated with [MASK] during [MASK].\"\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "input_context_con = [\n",
    "    '-'+query+'\\n-No, because of [MASK] and the risk of [MASK] [MASK].',\n",
    "    '-'+query+'\\n-Absolutely not, I think [MASK] is bad!.',\n",
    "    \"-\"+query+\"\\n-No, [MASK] is associated with [MASK] during [MASK].\"\n",
    "]\n",
    "\n",
    "input_context_neutral = [\n",
    "    query+' What about [MASK] or [MASK]?',\n",
    "    query+\" Don't forget about [MASK]!\"\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.6 s, sys: 890 ms, total: 36.5 s\n",
      "Wall time: 2.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hallucinations = []\n",
    "for input_context in chain(*[input_context_pro, input_context_con, input_context_neutral]):\n",
    "    inp_tens = torch.tensor(tokenizer.encode(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(input_context)))).unsqueeze(0)\n",
    "    mask_indices = np.nonzero(inp_tens.squeeze()==103).squeeze()\n",
    "    preds = model(inp_tens)[0].squeeze()\n",
    "    mask_indices = [mask_indices.tolist()] if type(mask_indices.tolist())!=list else mask_indices.tolist()\n",
    "    top_words = []\n",
    "    for i in mask_indices:\n",
    "        top_words.append(torch.topk(preds[i], k=5))\n",
    "    words = []\n",
    "    for mask_topk in top_words:\n",
    "        for token in mask_topk.indices.tolist():\n",
    "            words.append(tokenizer.decode(token, clean_up_tokenization_spaces=True))\n",
    "        #Interestingly, BERT was returning the ##carriage subword, obviously part of \"miscarriage\" in the \"pregnancy\" context. Further investigation needed to see how to return the full of word. Filtering out subwords for now.\n",
    "        #Filter out subwords\n",
    "        words = [word.replace(\" \",\"\") for word in words if not word.startswith(\"#\")]\n",
    "        words = [word for word in words if not word.endswith(\"#\")]\n",
    "        #Filter out punctuation\n",
    "        words = [word for word in words if not word in punctuation]\n",
    "    words = set(words)\n",
    "    words = list(words.difference(STOP_WORDS))\n",
    "    hallucinations.extend(words)\n",
    "hallucinations = set(hallucinations)\n",
    "hallucinations = list(hallucinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['religion',\n",
       " 'poverty',\n",
       " 'attendance',\n",
       " 'public',\n",
       " 'economics',\n",
       " 'land',\n",
       " 'money',\n",
       " 'prayer',\n",
       " 'death',\n",
       " 'church',\n",
       " 'consumption',\n",
       " 'easter',\n",
       " 'good',\n",
       " 'free',\n",
       " 'tax',\n",
       " 'lent',\n",
       " 'churches',\n",
       " 'property',\n",
       " 'costs',\n",
       " 'mass',\n",
       " 'education',\n",
       " 'exposure',\n",
       " 'financial',\n",
       " 'christmas',\n",
       " 'schools',\n",
       " 'festivals',\n",
       " 'work',\n",
       " 'women',\n",
       " 'taxes',\n",
       " 'religious',\n",
       " 'unemployment',\n",
       " 'bankruptcy',\n",
       " 'legal',\n",
       " 'services']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['religion',\n",
       " 'poverty',\n",
       " 'faith',\n",
       " 'land',\n",
       " 'money',\n",
       " 'prayer',\n",
       " 'death',\n",
       " 'cost',\n",
       " 'church',\n",
       " 'conversion',\n",
       " 'worship',\n",
       " 'free',\n",
       " 'tax',\n",
       " 'lent',\n",
       " 'legal',\n",
       " 'collapse',\n",
       " 'churches',\n",
       " 'property',\n",
       " 'costs',\n",
       " 'mass',\n",
       " 'wartime',\n",
       " 'housing',\n",
       " 'living',\n",
       " 'education',\n",
       " 'financial',\n",
       " 'christmas',\n",
       " 'schools',\n",
       " 'tourism',\n",
       " 'festivals',\n",
       " 'taxes',\n",
       " 'religious',\n",
       " 'attendance',\n",
       " 'corruption',\n",
       " 'services']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Should the Federal Minimum Wage Be Increased?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inflation', 'labor', 'taxes', 'immigration', 'congress']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"-\"+query+\"\\n-Yes, it's not too late because of [MASK] [MASK]\"]\n",
    "hallucinations = []\n",
    "for input_context in chain(*[test]):\n",
    "    inp_tens = torch.tensor(tokenizer.encode(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(input_context)))).unsqueeze(0)\n",
    "    mask_indices = np.nonzero(inp_tens.squeeze()==103).squeeze()\n",
    "    preds = model(inp_tens)[0].squeeze()\n",
    "    mask_indices = [mask_indices.tolist()] if type(mask_indices.tolist())!=list else mask_indices.tolist()\n",
    "    top_words = []\n",
    "    for i in mask_indices:\n",
    "        top_words.append(torch.topk(preds[i], k=10))\n",
    "    words = []\n",
    "    for mask_topk in top_words:\n",
    "        for token in mask_topk.indices.tolist():\n",
    "            words.append(tokenizer.decode(token, clean_up_tokenization_spaces=True))\n",
    "        #Interestingly, BERT was returning the ##carriage subword, obviously part of \"miscarriage\" in the \"pregnancy\" context. Further investigation needed to see how to return the full of word. Filtering out subwords for now.\n",
    "        #Filter out subwords\n",
    "        words = [word.replace(\" \",\"\") for word in words if not word.startswith(\"#\")]\n",
    "        words = [word for word in words if not word.endswith(\"#\")]\n",
    "        #Filter out punctuation\n",
    "        words = [word for word in words if not word in [*punctuation, \"...\"]]\n",
    "    words = set(words)\n",
    "    words = list(words.difference(STOP_WORDS))\n",
    "    hallucinations.extend(words)\n",
    "hallucinations = set(hallucinations)\n",
    "hallucinations = list(hallucinations)\n",
    "hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wars',\n",
       " 'pollution',\n",
       " 'death',\n",
       " 'consumption',\n",
       " 'climate',\n",
       " 'risk',\n",
       " 'water',\n",
       " 'development',\n",
       " 'warming',\n",
       " 'growth',\n",
       " 'summer',\n",
       " 'energy',\n",
       " 'emissions',\n",
       " 'migration',\n",
       " 'winter',\n",
       " 'construction',\n",
       " 'health',\n",
       " 'deaths',\n",
       " 'drought',\n",
       " 'mortality',\n",
       " 'pregnancy',\n",
       " 'wartime']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abortion',\n",
       " 'drugs',\n",
       " 'condoms',\n",
       " 'alcohol',\n",
       " 'pills',\n",
       " 'babies',\n",
       " 'children',\n",
       " 'men',\n",
       " 'women',\n",
       " 'money',\n",
       " 'kids',\n",
       " 'sex',\n",
       " 'insurance']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_context = \"-\"+query+\"\\n-But what about [MASK]?\"\n",
    "inp_tens = torch.tensor(tokenizer.encode(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(input_context)))).unsqueeze(0)\n",
    "mask_indices = np.nonzero(inp_tens.squeeze()==103).squeeze()\n",
    "preds = model(inp_tens)[0].squeeze()\n",
    "mask_indices = [mask_indices.tolist()] if type(mask_indices.tolist())!=list else mask_indices.tolist()\n",
    "top_words = []\n",
    "for i in mask_indices:\n",
    "    top_words.append(torch.topk(preds[i], k=20))\n",
    "words = []\n",
    "tokens = []\n",
    "for mask_topk in top_words:\n",
    "    for token in mask_topk.indices.tolist():\n",
    "        tokens.append(token)\n",
    "        words.append(tokenizer.decode(token, clean_up_tokenization_spaces=True))\n",
    "    words = [word.replace(\" \",\"\") for word in words if not word.startswith(\"#\")]\n",
    "words = set(words)\n",
    "words = list(words.difference(STOP_WORDS))\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doctor',\n",
       " 'condoms',\n",
       " 'pills',\n",
       " 'prescription',\n",
       " 'pill',\n",
       " 'medication',\n",
       " 'baby',\n",
       " 'stuff',\n",
       " 'condom',\n",
       " 'sex',\n",
       " 'medicine']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_context = \"-\"+query+\"\\n-Don't forget about [MASK] [MASK].\"\n",
    "inp_tens = torch.tensor(tokenizer.encode(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(input_context)))).unsqueeze(0)\n",
    "mask_indices = np.nonzero(inp_tens.squeeze()==103).squeeze()\n",
    "preds = model(inp_tens)[0].squeeze()\n",
    "mask_indices = [mask_indices.tolist()] if type(mask_indices.tolist())!=list else mask_indices.tolist()\n",
    "top_words = []\n",
    "for i in mask_indices:\n",
    "    top_words.append(torch.topk(preds[i], k=10))\n",
    "words = []\n",
    "tokens = []\n",
    "for mask_topk in top_words:\n",
    "    for token in mask_topk.indices.tolist():\n",
    "        tokens.append(token)\n",
    "        words.append(tokenizer.decode(token, clean_up_tokenization_spaces=True))\n",
    "    words = [word.replace(\" \",\"\") for word in words if not word.startswith(\"#\")]\n",
    "words = set(words)\n",
    "words = list(words.difference(STOP_WORDS))\n",
    "words =[word for word in words if len(word)>1]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abortion', 'drugs', 'condoms', 'pills', 'babies', 'prostitution', 'sex']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_context = query+\"I don't believe in [MASK].\"\n",
    "inp_tens = torch.tensor(tokenizer.encode(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(input_context)))).unsqueeze(0)\n",
    "mask_indices = np.nonzero(inp_tens.squeeze()==103).squeeze()\n",
    "preds = model(inp_tens)[0].squeeze()\n",
    "mask_indices = [mask_indices.tolist()] if type(mask_indices.tolist())!=list else mask_indices.tolist()\n",
    "top_words = []\n",
    "for i in mask_indices:\n",
    "    top_words.append(torch.topk(preds[i], k=10))\n",
    "words = []\n",
    "tokens = []\n",
    "for mask_topk in top_words:\n",
    "    for token in mask_topk.indices.tolist():\n",
    "        tokens.append(token)\n",
    "        words.append(tokenizer.decode(token, clean_up_tokenization_spaces=True))\n",
    "    words = [word.replace(\" \",\"\") for word in words if not word.startswith(\"#\")]\n",
    "words = set(words)\n",
    "words = list(words.difference(STOP_WORDS))\n",
    "words =[word for word in words if len(word)>1]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string.pu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
