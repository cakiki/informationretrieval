{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, AutoConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search, Q\n",
    "\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Should Teachers Get Tenure?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Is Vaping with E-Cigarettes Safe?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Should Insider Trading Be Allowed?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Should Corporal Punishment Be Used in Schools?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Should Social Security Be Privatized?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic                                           query\n",
       "0      1                     Should Teachers Get Tenure?\n",
       "1      2               Is Vaping with E-Cigarettes Safe?\n",
       "2      3              Should Insider Trading Be Allowed?\n",
       "3      4  Should Corporal Punishment Be Used in Schools?\n",
       "4      5           Should Social Security Be Privatized?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>conclusion</th>\n",
       "      <th>relevance</th>\n",
       "      <th>relevance_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>353</td>\n",
       "      <td>d267a5af-2019-04-18T18:07:23Z-00009-000</td>\n",
       "      <td>Should Marijuana Be a Medical Option?</td>\n",
       "      <td>Marijuana is a major concern to the United Sta...</td>\n",
       "      <td>Medical Marijuana</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>864</td>\n",
       "      <td>7839a8e-2019-04-18T13:02:10Z-00000-000</td>\n",
       "      <td>Is Sexual Orientation Determined at Birth?</td>\n",
       "      <td>Why did you accept my debate if you agreed wit...</td>\n",
       "      <td>Sexual Orientation is a choice.</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1312</td>\n",
       "      <td>e100392e-2019-04-18T19:19:21Z-00000-000</td>\n",
       "      <td>Do Standardized Tests Improve Education?</td>\n",
       "      <td>You don't it, you have to provide PROOF you di...</td>\n",
       "      <td>Cannabis Sativa Enhances my Life</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192</td>\n",
       "      <td>5339b784-2019-04-18T15:45:56Z-00005-000</td>\n",
       "      <td>Should the Federal Minimum Wage Be Increased?</td>\n",
       "      <td>I accept this challenge and negate the resolut...</td>\n",
       "      <td>Resolved: Minimum wages in the United States s...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>782</td>\n",
       "      <td>61bcba6c-2019-04-18T15:04:19Z-00004-000</td>\n",
       "      <td>Should Animals Be Used for Scientific or Comme...</td>\n",
       "      <td>Well, first of all, thanks for accepting.-----...</td>\n",
       "      <td>Animal Testing</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                       id  \\\n",
       "0    353  d267a5af-2019-04-18T18:07:23Z-00009-000   \n",
       "1    864   7839a8e-2019-04-18T13:02:10Z-00000-000   \n",
       "2   1312  e100392e-2019-04-18T19:19:21Z-00000-000   \n",
       "3    192  5339b784-2019-04-18T15:45:56Z-00005-000   \n",
       "4    782  61bcba6c-2019-04-18T15:04:19Z-00004-000   \n",
       "\n",
       "                                               query  \\\n",
       "0              Should Marijuana Be a Medical Option?   \n",
       "1         Is Sexual Orientation Determined at Birth?   \n",
       "2           Do Standardized Tests Improve Education?   \n",
       "3      Should the Federal Minimum Wage Be Increased?   \n",
       "4  Should Animals Be Used for Scientific or Comme...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Marijuana is a major concern to the United Sta...   \n",
       "1  Why did you accept my debate if you agreed wit...   \n",
       "2  You don't it, you have to provide PROOF you di...   \n",
       "3  I accept this challenge and negate the resolut...   \n",
       "4  Well, first of all, thanks for accepting.-----...   \n",
       "\n",
       "                                          conclusion  relevance  \\\n",
       "0                                  Medical Marijuana          3   \n",
       "1                    Sexual Orientation is a choice.         -2   \n",
       "2                   Cannabis Sativa Enhances my Life         -2   \n",
       "3  Resolved: Minimum wages in the United States s...          2   \n",
       "4                                     Animal Testing          3   \n",
       "\n",
       "   relevance_binary  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 1  \n",
       "4                 1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 896 ms, sys: 381 ms, total: 1.28 s\n",
      "Wall time: 1.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "judgments = pd.read_csv('Data/tira-qrels', delim_whitespace=True, names=['topic','iteration','id','relevance'])\n",
    "arguments = pd.read_pickle('Data/dataset.pkl')\n",
    "\n",
    "tree = ET.parse('Data/topics-automatic-runs-task-1.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "topics = []\n",
    "for child in root:\n",
    "    d = {'topic':int(child[0].text), 'query':child[1].text}\n",
    "    topics.append(d)\n",
    "topics = pd.DataFrame(topics)\n",
    "\n",
    "relevance = judgments.merge(topics)\n",
    "relevance['relevance_binary'] = (relevance['relevance'] != -2).astype(int)\n",
    "relevance = relevance.merge(arguments[['id', 'text', 'conclusion']])\n",
    "relevance = relevance[['id', 'query', 'text', 'conclusion', 'relevance','relevance_binary']]\n",
    "relevance = relevance.sample(frac=1, random_state=42)\n",
    "relevance.reset_index(inplace=True)\n",
    "display(topics[:5])\n",
    "display(relevance[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_for_encoding(df, batch_size=128):\n",
    "    df = df.copy()\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(dict(df[['query','text','conclusion']]))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cabb66c6b574af089ee94d7f96dcb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=546.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2b581f2fb34c6c94b9518bbbd2cc18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_TO_USE = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_TO_USE, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddaad2f967a84b2f9980711c18c5a65f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 2.4 s, sys: 452 ms, total: 2.85 s\n",
      "Wall time: 693 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>id</th>\n",
       "      <th>old_index</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>binary_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 2323, 16204, 2022, 1037, 2966, 5724, 102...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>d267a5af-2019-04-18T18:07:23Z-00009-000</td>\n",
       "      <td>353</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 2003, 4424, 10296, 4340, 2012, 4182, 102...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>7839a8e-2019-04-18T13:02:10Z-00000-000</td>\n",
       "      <td>864</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 2079, 16367, 5852, 5335, 2495, 1029, 102...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>e100392e-2019-04-18T19:19:21Z-00000-000</td>\n",
       "      <td>1312</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_ids  \\\n",
       "0  [101, 2323, 16204, 2022, 1037, 2966, 5724, 102...   \n",
       "1  [101, 2003, 4424, 10296, 4340, 2012, 4182, 102...   \n",
       "2  [101, 2079, 16367, 5852, 5335, 2495, 1029, 102...   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                        id  old_index  relevance_score  \\\n",
       "0  d267a5af-2019-04-18T18:07:23Z-00009-000        353                3   \n",
       "1   7839a8e-2019-04-18T13:02:10Z-00000-000        864               -2   \n",
       "2  e100392e-2019-04-18T19:19:21Z-00000-000       1312               -2   \n",
       "\n",
       "   binary_score  \n",
       "0             1  \n",
       "1             0  \n",
       "2             0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tokenized = []\n",
    "for chunk in tqdm_notebook(np.array_split(relevance, 1), total=1):\n",
    "    tokenized_chunk = tokenizer.batch_encode_plus(list(zip(list(chunk['query'].values), list(chunk['text'].values))), max_length=tokenizer.max_len, pad_to_max_length=True, return_overflowing_tokens=True)\n",
    "    tokenized_chunk.pop('token_type_ids')\n",
    "\n",
    "    overflow_index = tokenized_chunk.pop('overflow_to_sample_mapping')\n",
    "\n",
    "    # Repeating indices are included as lists of the corresponding index eg: [0,1, [2,2,2,2], [3,3]...]\n",
    "    overflow_index = np.hstack(overflow_index)\n",
    "    text_ids = chunk['id'].values\n",
    "    text_ids = text_ids[overflow_index]\n",
    "    \n",
    "    old_index = chunk.index.to_series().values\n",
    "    old_index = old_index[overflow_index]\n",
    "    \n",
    "    relevance_score = chunk['relevance'].values\n",
    "    relevance_score = relevance_score[overflow_index]\n",
    "    \n",
    "    binary_score = chunk['relevance_binary'].values\n",
    "    binary_score = binary_score[overflow_index]\n",
    "\n",
    "    df = pd.DataFrame(tokenized_chunk)\n",
    "    df[['input_ids', 'attention_mask']] = df[['input_ids', 'attention_mask']].applymap(np.array)\n",
    "    df['id'] = text_ids\n",
    "    df['old_index'] = old_index\n",
    "    df['relevance_score'] = relevance_score\n",
    "    df['binary_score'] = binary_score\n",
    "    tokenized.append(df)\n",
    "tokenized = pd.concat(tokenized)\n",
    "tokenized.reset_index(inplace=True, drop=True)\n",
    "tokenized[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train, tokenized_valid = train_test_split(tokenized, shuffle=False, random_state=42, train_size=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a1180443c146dfa0584252dd7eb026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=363423424.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(MODEL_TO_USE)\n",
    "config.num_labels=2\n",
    "seq_model = TFAutoModelForSequenceClassification.from_pretrained(MODEL_TO_USE, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_train = np.stack(tokenized_train['input_ids'])\n",
    "m_train = np.stack(tokenized_train['attention_mask'])\n",
    "relevance_train = np.stack(tokenized_train['relevance_score'].values)\n",
    "binary_train = np.stack(tokenized_train['binary_score'].values)\n",
    "\n",
    "i_valid = np.stack(tokenized_valid['input_ids'])\n",
    "m_valid = np.stack(tokenized_valid['attention_mask'])\n",
    "relevance_valid = np.stack(tokenized_valid['relevance_score'].values)\n",
    "binary_valid = np.stack(tokenized_valid['binary_score'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1218, 512)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a multiple input - multiple output keras neural network using the functional API, with a huggingface sequence classifier with two outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "input_ids = keras.layers.Input(shape=[512], name=\"input_ids\", dtype=tf.int64)\n",
    "input_masks = keras.layers.Input(shape=[512], name=\"masks\", dtype=tf.int64)\n",
    "seq_model = TFAutoModelForSequenceClassification.from_pretrained(MODEL_TO_USE, config=config)\n",
    "two_outputs = seq_model(input_ids, attention_mask=input_masks, training=True)[0]\n",
    "output_relevance = keras.layers.Lambda(lambda x: x[:,0], name=\"relevance_regressor\")(two_outputs)\n",
    "output_binary = keras.layers.Lambda(lambda x: x[:,1])(two_outputs)\n",
    "output_binary = keras.layers.Activation('sigmoid', name=\"binary_relevance_classifier\")(output_binary)\n",
    "model = keras.Model(inputs=[input_ids, input_masks], outputs=[output_relevance, output_binary])\n",
    "\n",
    "\n",
    "model.compile(loss=[\"mse\", keras.losses.BinaryCrossentropy(from_logits=True)], loss_weights=[0.85, 0.15], optimizer=\"Adam\")\n",
    "callback_list = [keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1218 samples, validate on 216 samples\n",
      "Epoch 1/50\n",
      "1218/1218 [==============================] - 28s 23ms/sample - loss: 3.7713 - relevance_regressor_loss: 4.2686 - binary_relevance_classifier_loss: 0.5349 - val_loss: 3.4723 - val_relevance_regressor_loss: 4.0271 - val_binary_relevance_classifier_loss: 0.5060\n",
      "Epoch 2/50\n",
      "1218/1218 [==============================] - 27s 22ms/sample - loss: 3.4578 - relevance_regressor_loss: 3.9168 - binary_relevance_classifier_loss: 0.5227 - val_loss: 3.2226 - val_relevance_regressor_loss: 3.7355 - val_binary_relevance_classifier_loss: 0.5077\n",
      "Epoch 3/50\n",
      "1218/1218 [==============================] - 27s 22ms/sample - loss: 3.4161 - relevance_regressor_loss: 3.8552 - binary_relevance_classifier_loss: 0.5195 - val_loss: 3.2008 - val_relevance_regressor_loss: 3.7097 - val_binary_relevance_classifier_loss: 0.5066\n",
      "Epoch 4/50\n",
      "1218/1218 [==============================] - 27s 23ms/sample - loss: 3.3217 - relevance_regressor_loss: 3.7637 - binary_relevance_classifier_loss: 0.5186 - val_loss: 3.1607 - val_relevance_regressor_loss: 3.6580 - val_binary_relevance_classifier_loss: 0.5059\n",
      "Epoch 5/50\n",
      "1218/1218 [==============================] - 28s 23ms/sample - loss: 3.3563 - relevance_regressor_loss: 3.7702 - binary_relevance_classifier_loss: 0.5183 - val_loss: 3.1814 - val_relevance_regressor_loss: 3.6798 - val_binary_relevance_classifier_loss: 0.5060\n",
      "Epoch 6/50\n",
      "1218/1218 [==============================] - 28s 23ms/sample - loss: 3.3355 - relevance_regressor_loss: 3.7906 - binary_relevance_classifier_loss: 0.5181 - val_loss: 3.2179 - val_relevance_regressor_loss: 3.7221 - val_binary_relevance_classifier_loss: 0.5059\n",
      "Epoch 7/50\n",
      "1218/1218 [==============================] - 28s 23ms/sample - loss: 3.3287 - relevance_regressor_loss: 3.7700 - binary_relevance_classifier_loss: 0.5180 - val_loss: 3.1853 - val_relevance_regressor_loss: 3.6866 - val_binary_relevance_classifier_loss: 0.5057\n",
      "Epoch 8/50\n",
      "1218/1218 [==============================] - 28s 23ms/sample - loss: 3.3388 - relevance_regressor_loss: 3.9307 - binary_relevance_classifier_loss: 0.5299 - val_loss: 3.1683 - val_relevance_regressor_loss: 3.6659 - val_binary_relevance_classifier_loss: 0.5057\n",
      "Epoch 9/50\n",
      "1218/1218 [==============================] - 28s 23ms/sample - loss: 3.3439 - relevance_regressor_loss: 3.8909 - binary_relevance_classifier_loss: 0.5299 - val_loss: 3.2066 - val_relevance_regressor_loss: 3.7120 - val_binary_relevance_classifier_loss: 0.5056\n",
      "Epoch 10/50\n",
      "1218/1218 [==============================] - 28s 23ms/sample - loss: 3.3401 - relevance_regressor_loss: 3.8924 - binary_relevance_classifier_loss: 0.5299 - val_loss: 3.1806 - val_relevance_regressor_loss: 3.6864 - val_binary_relevance_classifier_loss: 0.5056\n",
      "Epoch 11/50\n",
      "1218/1218 [==============================] - 28s 23ms/sample - loss: 3.3337 - relevance_regressor_loss: 3.7488 - binary_relevance_classifier_loss: 0.5179 - val_loss: 3.1850 - val_relevance_regressor_loss: 3.6899 - val_binary_relevance_classifier_loss: 0.5056\n",
      "Epoch 12/50\n",
      "1218/1218 [==============================] - 28s 23ms/sample - loss: 3.3176 - relevance_regressor_loss: 3.9096 - binary_relevance_classifier_loss: 0.5298 - val_loss: 3.1914 - val_relevance_regressor_loss: 3.6930 - val_binary_relevance_classifier_loss: 0.5056\n",
      "Epoch 13/50\n",
      "1218/1218 [==============================] - 28s 23ms/sample - loss: 3.3000 - relevance_regressor_loss: 3.8785 - binary_relevance_classifier_loss: 0.5298 - val_loss: 3.1760 - val_relevance_regressor_loss: 3.6756 - val_binary_relevance_classifier_loss: 0.5056\n",
      "Epoch 14/50\n",
      "1218/1218 [==============================] - 28s 23ms/sample - loss: 3.3334 - relevance_regressor_loss: 3.7687 - binary_relevance_classifier_loss: 0.5178 - val_loss: 3.1938 - val_relevance_regressor_loss: 3.6963 - val_binary_relevance_classifier_loss: 0.5054\n",
      "Epoch 15/50\n",
      "1218/1218 [==============================] - 28s 23ms/sample - loss: 3.3230 - relevance_regressor_loss: 3.8875 - binary_relevance_classifier_loss: 0.5297 - val_loss: 3.1959 - val_relevance_regressor_loss: 3.7003 - val_binary_relevance_classifier_loss: 0.5056\n",
      "Epoch 16/50\n",
      "1218/1218 [==============================] - 29s 23ms/sample - loss: 3.3259 - relevance_regressor_loss: 3.9043 - binary_relevance_classifier_loss: 0.5298 - val_loss: 3.1686 - val_relevance_regressor_loss: 3.6714 - val_binary_relevance_classifier_loss: 0.5055\n",
      "Epoch 17/50\n",
      "1218/1218 [==============================] - 29s 23ms/sample - loss: 3.3199 - relevance_regressor_loss: 3.7762 - binary_relevance_classifier_loss: 0.5178 - val_loss: 3.1960 - val_relevance_regressor_loss: 3.6966 - val_binary_relevance_classifier_loss: 0.5055\n",
      "Epoch 18/50\n",
      "1218/1218 [==============================] - 29s 23ms/sample - loss: 3.3097 - relevance_regressor_loss: 3.8883 - binary_relevance_classifier_loss: 0.5298 - val_loss: 3.1906 - val_relevance_regressor_loss: 3.6923 - val_binary_relevance_classifier_loss: 0.5055\n",
      "Epoch 19/50\n",
      "1218/1218 [==============================] - 29s 23ms/sample - loss: 3.3172 - relevance_regressor_loss: 3.7537 - binary_relevance_classifier_loss: 0.5178 - val_loss: 3.1994 - val_relevance_regressor_loss: 3.7065 - val_binary_relevance_classifier_loss: 0.5055\n",
      "Epoch 20/50\n",
      "1218/1218 [==============================] - 29s 24ms/sample - loss: 3.3134 - relevance_regressor_loss: 3.7689 - binary_relevance_classifier_loss: 0.5178 - val_loss: 3.1796 - val_relevance_regressor_loss: 3.6773 - val_binary_relevance_classifier_loss: 0.5055\n",
      "Epoch 21/50\n",
      "1218/1218 [==============================] - 29s 24ms/sample - loss: 3.3373 - relevance_regressor_loss: 3.9092 - binary_relevance_classifier_loss: 0.5298 - val_loss: 3.1627 - val_relevance_regressor_loss: 3.6592 - val_binary_relevance_classifier_loss: 0.5055\n",
      "Epoch 22/50\n",
      "1218/1218 [==============================] - 29s 24ms/sample - loss: 3.3348 - relevance_regressor_loss: 3.7896 - binary_relevance_classifier_loss: 0.5179 - val_loss: 3.1648 - val_relevance_regressor_loss: 3.6733 - val_binary_relevance_classifier_loss: 0.5055\n",
      "Epoch 23/50\n",
      "1218/1218 [==============================] - 29s 24ms/sample - loss: 3.3112 - relevance_regressor_loss: 3.7726 - binary_relevance_classifier_loss: 0.5178 - val_loss: 3.1725 - val_relevance_regressor_loss: 3.6720 - val_binary_relevance_classifier_loss: 0.5055\n",
      "Epoch 24/50\n",
      "1218/1218 [==============================] - 29s 24ms/sample - loss: 3.3231 - relevance_regressor_loss: 3.7506 - binary_relevance_classifier_loss: 0.5178 - val_loss: 3.1878 - val_relevance_regressor_loss: 3.6918 - val_binary_relevance_classifier_loss: 0.5056\n",
      "Epoch 25/50\n",
      "1218/1218 [==============================] - 29s 24ms/sample - loss: 3.3252 - relevance_regressor_loss: 3.8609 - binary_relevance_classifier_loss: 0.5298 - val_loss: 3.1738 - val_relevance_regressor_loss: 3.6711 - val_binary_relevance_classifier_loss: 0.5055\n",
      "Epoch 26/50\n",
      " 704/1218 [================>.............] - ETA: 11s - loss: 3.3612 - relevance_regressor_loss: 3.8612 - binary_relevance_classifier_loss: 0.5277WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,relevance_regressor_loss,binary_relevance_classifier_loss,lr\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-7474cda156e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrelevance_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrelevance_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit([i_train, m_train], [relevance_train, binary_train], batch_size=32, epochs=50, validation_data=([i_valid, m_valid],[relevance_valid, binary_valid]), callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.5302646, 1.6240828, 1.5198188], dtype=float32),\n",
       " array([0.99761826, 0.99823296, 0.9982457 ], dtype=float32)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([i_train[:3], m_train[:3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With TF-Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-qa/3'.\n",
      "INFO:absl:Downloading https://tfhub.dev/google/universal-sentence-encoder-qa/3: 170.04MB\n",
      "INFO:absl:Downloading https://tfhub.dev/google/universal-sentence-encoder-qa/3: 340.04MB\n",
      "INFO:absl:Downloading https://tfhub.dev/google/universal-sentence-encoder-qa/3: 510.04MB\n",
      "INFO:absl:Downloaded https://tfhub.dev/google/universal-sentence-encoder-qa/3, Total size: 588.94MB\n",
      "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-qa/3'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.2 s, sys: 5.8 s, total: 37 s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "keras.backend.clear_session()\n",
    "\n",
    "module = hub.load('https://tfhub.dev/google/universal-sentence-encoder-qa/3')\n",
    "query_embedder = module.signatures['question_encoder']\n",
    "arg_embedder = module.signatures['response_encoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d271961c71594d7185a38cdb91a01c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=45.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = make_dataset_for_encoding(relevance, batch_size=32)\n",
    "\n",
    "query_encodings = []\n",
    "arg_encodings = []\n",
    "dot_ps = []\n",
    "for batch in tqdm_notebook(dataset, total=tf.data.experimental.cardinality(dataset).numpy()):\n",
    "    query_encoding = query_embedder(batch['query'])\n",
    "    query_encoding = query_encoding['outputs'].numpy()\n",
    "    \n",
    "    arg_encoding = arg_embedder(input=batch['text'], context=batch['conclusion'])\n",
    "    arg_encoding = arg_encoding['outputs'].numpy()\n",
    "    \n",
    "    #Use einstein notation to perform row-by-row dot-product\n",
    "    dot_p = np.einsum('ij,ij->i',query_encoding, arg_encoding)\n",
    "    \n",
    "    query_encodings.append(query_encoding)\n",
    "    arg_encodings.append(arg_encoding)\n",
    "    dot_ps.append(dot_p)\n",
    "query_encodings = np.vstack(query_encodings)\n",
    "arg_encodings = np.vstack(arg_encodings)\n",
    "encodings = np.hstack([query_encodings, arg_encodings])\n",
    "\n",
    "#Add a column dimension to dot_ps to be able to vstack it\n",
    "dot_ps = np.vstack([item[:, np.newaxis] for item in dot_ps])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a *Wide and Deep* network to predict relevance from a query and an argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wide network will use the elasticsearch LMDirichlet scores and the dot-product of the query embedding and argument embedding returned by the Universal Sentence Encoder for question-answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch()\n",
    "es.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>conclusion</th>\n",
       "      <th>relevance</th>\n",
       "      <th>relevance_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>353</td>\n",
       "      <td>d267a5af-2019-04-18T18:07:23Z-00009-000</td>\n",
       "      <td>Should Marijuana Be a Medical Option?</td>\n",
       "      <td>Marijuana is a major concern to the United Sta...</td>\n",
       "      <td>Medical Marijuana</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>864</td>\n",
       "      <td>7839a8e-2019-04-18T13:02:10Z-00000-000</td>\n",
       "      <td>Is Sexual Orientation Determined at Birth?</td>\n",
       "      <td>Why did you accept my debate if you agreed wit...</td>\n",
       "      <td>Sexual Orientation is a choice.</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1312</td>\n",
       "      <td>e100392e-2019-04-18T19:19:21Z-00000-000</td>\n",
       "      <td>Do Standardized Tests Improve Education?</td>\n",
       "      <td>You don't it, you have to provide PROOF you di...</td>\n",
       "      <td>Cannabis Sativa Enhances my Life</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192</td>\n",
       "      <td>5339b784-2019-04-18T15:45:56Z-00005-000</td>\n",
       "      <td>Should the Federal Minimum Wage Be Increased?</td>\n",
       "      <td>I accept this challenge and negate the resolut...</td>\n",
       "      <td>Resolved: Minimum wages in the United States s...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>782</td>\n",
       "      <td>61bcba6c-2019-04-18T15:04:19Z-00004-000</td>\n",
       "      <td>Should Animals Be Used for Scientific or Comme...</td>\n",
       "      <td>Well, first of all, thanks for accepting.-----...</td>\n",
       "      <td>Animal Testing</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>1095</td>\n",
       "      <td>36f68365-2019-04-18T15:05:04Z-00000-000</td>\n",
       "      <td>Do Electronic Voting Machines Improve the Voti...</td>\n",
       "      <td>As you can see, my opponent has failed to back...</td>\n",
       "      <td>Earth's orbit around the Sun</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>1130</td>\n",
       "      <td>2c05e9fb-2019-04-15T20:23:05Z-00005-000</td>\n",
       "      <td>Do Electronic Voting Machines Improve the Voti...</td>\n",
       "      <td>Remote electronic voting can be conducted very...</td>\n",
       "      <td>allow the use of electronic and internet votin...</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>1294</td>\n",
       "      <td>b760077b-2019-04-18T13:01:46Z-00003-000</td>\n",
       "      <td>Do Standardized Tests Improve Education?</td>\n",
       "      <td>Challenge accepted, Standardized tests should ...</td>\n",
       "      <td>Standardized Tests</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>860</td>\n",
       "      <td>b9c0e12b-2019-04-18T13:51:22Z-00005-000</td>\n",
       "      <td>Is Sexual Orientation Determined at Birth?</td>\n",
       "      <td>Lol well that was a waste of a round. But I gu...</td>\n",
       "      <td>there is nothing wrong with zoosexuality/beast...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>1126</td>\n",
       "      <td>2baaf2c1-2019-04-18T18:57:49Z-00000-000</td>\n",
       "      <td>Do Electronic Voting Machines Improve the Voti...</td>\n",
       "      <td>As expected, a cowardly forfeit. Vote Con</td>\n",
       "      <td>Electronics have a positive affect on our live...</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1411 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                       id  \\\n",
       "0       353  d267a5af-2019-04-18T18:07:23Z-00009-000   \n",
       "1       864   7839a8e-2019-04-18T13:02:10Z-00000-000   \n",
       "2      1312  e100392e-2019-04-18T19:19:21Z-00000-000   \n",
       "3       192  5339b784-2019-04-18T15:45:56Z-00005-000   \n",
       "4       782  61bcba6c-2019-04-18T15:04:19Z-00004-000   \n",
       "...     ...                                      ...   \n",
       "1406   1095  36f68365-2019-04-18T15:05:04Z-00000-000   \n",
       "1407   1130  2c05e9fb-2019-04-15T20:23:05Z-00005-000   \n",
       "1408   1294  b760077b-2019-04-18T13:01:46Z-00003-000   \n",
       "1409    860  b9c0e12b-2019-04-18T13:51:22Z-00005-000   \n",
       "1410   1126  2baaf2c1-2019-04-18T18:57:49Z-00000-000   \n",
       "\n",
       "                                                  query  \\\n",
       "0                 Should Marijuana Be a Medical Option?   \n",
       "1            Is Sexual Orientation Determined at Birth?   \n",
       "2              Do Standardized Tests Improve Education?   \n",
       "3         Should the Federal Minimum Wage Be Increased?   \n",
       "4     Should Animals Be Used for Scientific or Comme...   \n",
       "...                                                 ...   \n",
       "1406  Do Electronic Voting Machines Improve the Voti...   \n",
       "1407  Do Electronic Voting Machines Improve the Voti...   \n",
       "1408           Do Standardized Tests Improve Education?   \n",
       "1409         Is Sexual Orientation Determined at Birth?   \n",
       "1410  Do Electronic Voting Machines Improve the Voti...   \n",
       "\n",
       "                                                   text  \\\n",
       "0     Marijuana is a major concern to the United Sta...   \n",
       "1     Why did you accept my debate if you agreed wit...   \n",
       "2     You don't it, you have to provide PROOF you di...   \n",
       "3     I accept this challenge and negate the resolut...   \n",
       "4     Well, first of all, thanks for accepting.-----...   \n",
       "...                                                 ...   \n",
       "1406  As you can see, my opponent has failed to back...   \n",
       "1407  Remote electronic voting can be conducted very...   \n",
       "1408  Challenge accepted, Standardized tests should ...   \n",
       "1409  Lol well that was a waste of a round. But I gu...   \n",
       "1410          As expected, a cowardly forfeit. Vote Con   \n",
       "\n",
       "                                             conclusion  relevance  \\\n",
       "0                                     Medical Marijuana          3   \n",
       "1                       Sexual Orientation is a choice.         -2   \n",
       "2                      Cannabis Sativa Enhances my Life         -2   \n",
       "3     Resolved: Minimum wages in the United States s...          2   \n",
       "4                                        Animal Testing          3   \n",
       "...                                                 ...        ...   \n",
       "1406                       Earth's orbit around the Sun         -2   \n",
       "1407  allow the use of electronic and internet votin...         -2   \n",
       "1408                                 Standardized Tests          3   \n",
       "1409  there is nothing wrong with zoosexuality/beast...          3   \n",
       "1410  Electronics have a positive affect on our live...         -2   \n",
       "\n",
       "      relevance_binary  \n",
       "0                    1  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    1  \n",
       "4                    1  \n",
       "...                ...  \n",
       "1406                 0  \n",
       "1407                 0  \n",
       "1408                 1  \n",
       "1409                 1  \n",
       "1410                 0  \n",
       "\n",
       "[1411 rows x 7 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1411, 1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevance.text.str.len().values[:, np.newaxis].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Dirichlet scores for every query-argument in the judgments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.26 s, sys: 105 ms, total: 3.36 s\n",
      "Wall time: 6.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dirichlet_scores = np.zeros(dot_ps.shape)\n",
    "for i, row in relevance.iterrows():\n",
    "    s = Search(using=es, index='arg_index')\n",
    "    s.query = Q(\"match\", text=row['query']) & Q(\"term\", _id=row['id'])\n",
    "    response = s.execute()\n",
    "    if not response.hits.total.value == 0:\n",
    "        dirichlet_scores[i,0] = response[0].meta.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(dirichlet_scores == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((relevance.relevance == -2).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create network with the tf.keras functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_i = np.hstack([dot_ps, dirichlet_scores, relevance.text.str.len().values[:, np.newaxis]])\n",
    "deep_i = encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = relevance[[\"relevance\", \"relevance_binary\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  1],\n",
       "       [-2,  0],\n",
       "       [-2,  0],\n",
       "       ...,\n",
       "       [ 3,  1],\n",
       "       [ 3,  1],\n",
       "       [-2,  0]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From Aurelien Geron's HOML https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch11.html\n",
    "RegularizedDense = partial(keras.layers.Dense, activation=\"elu\", kernel_initializer=\"he_normal\", kernel_regularizer=keras.regularizers.l2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "input_wide = keras.layers.Input(shape=[3], name=\"wide\")\n",
    "input_deep = keras.layers.Input(shape=[1024], name=\"deep\")\n",
    "\n",
    "norm_input_deep = keras.layers.BatchNormalization()(input_deep)\n",
    "\n",
    "hidden1 = RegularizedDense(1024)(norm_input_deep)\n",
    "hidden1 = keras.layers.BatchNormalization()(hidden1)\n",
    "\n",
    "hidden2 = RegularizedDense(512)(hidden1)\n",
    "hidden2 = keras.layers.BatchNormalization()(hidden2)\n",
    "\n",
    "hidden3 = RegularizedDense(64)(hidden2)\n",
    "hidden3 = keras.layers.BatchNormalization()(hidden3)\n",
    "\n",
    "hidden4 = RegularizedDense(2)(hidden3)\n",
    "\n",
    "concat = keras.layers.concatenate([input_wide, hidden4])\n",
    "\n",
    "mix = RegularizedDense(8)(concat)\n",
    "\n",
    "output_reg = keras.layers.Dense(1, name=\"output_reg\")(mix)\n",
    "output_class = keras.layers.Dense(1, activation=\"sigmoid\", name=\"output_class\")(mix)\n",
    "output_aux = keras.layers.Dense(1, activation=\"sigmoid\", name=\"output_aux\")(hidden4)\n",
    "\n",
    "wide_and_deep = keras.Model(inputs=[input_wide, input_deep], outputs=[output_reg, output_class, output_aux])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wide_and_deep.compile(loss=[\"mse\", keras.losses.BinaryCrossentropy(from_logits=True), keras.losses.BinaryCrossentropy(from_logits=True)], loss_weights=[0.7, 0.15, 0.15], optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1411 samples\n",
      "Epoch 1/500\n",
      "1411/1411 [==============================] - 0s 202us/sample - loss: 3.9726 - output_reg_loss: 4.5035 - output_class_loss: 0.5137 - output_aux_loss: 0.4357\n",
      "Epoch 2/500\n",
      "1411/1411 [==============================] - 0s 227us/sample - loss: 2.4136 - output_reg_loss: 2.9519 - output_class_loss: 0.5137 - output_aux_loss: 0.4366\n",
      "Epoch 3/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 3.7988 - output_reg_loss: 4.0215 - output_class_loss: 0.5275 - output_aux_loss: 0.4404\n",
      "Epoch 4/500\n",
      "1411/1411 [==============================] - 0s 232us/sample - loss: 3.6287 - output_reg_loss: 4.0855 - output_class_loss: 0.5137 - output_aux_loss: 0.4323\n",
      "Epoch 5/500\n",
      "1411/1411 [==============================] - 0s 240us/sample - loss: 3.3014 - output_reg_loss: 3.4667 - output_class_loss: 0.5275 - output_aux_loss: 0.4431\n",
      "Epoch 6/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 4.0438 - output_reg_loss: 4.8254 - output_class_loss: 0.5275 - output_aux_loss: 0.4501\n",
      "Epoch 7/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 2.9917 - output_reg_loss: 2.9980 - output_class_loss: 0.5137 - output_aux_loss: 0.4338\n",
      "Epoch 8/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 1.4394 - output_reg_loss: 0.9859 - output_class_loss: 0.5275 - output_aux_loss: 0.4357\n",
      "Epoch 9/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 1.2648 - output_reg_loss: 0.8833 - output_class_loss: 0.5137 - output_aux_loss: 0.4198\n",
      "Epoch 10/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 1.2313 - output_reg_loss: 0.7144 - output_class_loss: 0.5275 - output_aux_loss: 0.4225\n",
      "Epoch 11/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 1.2482 - output_reg_loss: 0.8381 - output_class_loss: 0.5137 - output_aux_loss: 0.4245\n",
      "Epoch 12/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 1.1927 - output_reg_loss: 1.0548 - output_class_loss: 0.5137 - output_aux_loss: 0.4231\n",
      "Epoch 13/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 1.1405 - output_reg_loss: 0.8545 - output_class_loss: 0.5137 - output_aux_loss: 0.4199\n",
      "Epoch 14/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 1.0982 - output_reg_loss: 0.6819 - output_class_loss: 0.5137 - output_aux_loss: 0.4192\n",
      "Epoch 15/500\n",
      "1411/1411 [==============================] - 0s 223us/sample - loss: 1.1616 - output_reg_loss: 0.7175 - output_class_loss: 0.5275 - output_aux_loss: 0.4254\n",
      "Epoch 16/500\n",
      "1411/1411 [==============================] - 0s 205us/sample - loss: 1.1173 - output_reg_loss: 0.6712 - output_class_loss: 0.5275 - output_aux_loss: 0.4240\n",
      "Epoch 17/500\n",
      "1411/1411 [==============================] - 0s 219us/sample - loss: 1.0735 - output_reg_loss: 0.7703 - output_class_loss: 0.5413 - output_aux_loss: 0.4391\n",
      "Epoch 18/500\n",
      "1411/1411 [==============================] - 0s 199us/sample - loss: 1.0829 - output_reg_loss: 0.7294 - output_class_loss: 0.5137 - output_aux_loss: 0.4170\n",
      "Epoch 19/500\n",
      "1411/1411 [==============================] - 0s 220us/sample - loss: 1.0654 - output_reg_loss: 0.7389 - output_class_loss: 0.5137 - output_aux_loss: 0.4217\n",
      "Epoch 20/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 1.0284 - output_reg_loss: 0.8149 - output_class_loss: 0.5137 - output_aux_loss: 0.4200\n",
      "Epoch 21/500\n",
      "1411/1411 [==============================] - 0s 223us/sample - loss: 1.0225 - output_reg_loss: 0.7381 - output_class_loss: 0.5137 - output_aux_loss: 0.4219\n",
      "Epoch 22/500\n",
      "1411/1411 [==============================] - 0s 228us/sample - loss: 1.0177 - output_reg_loss: 0.9386 - output_class_loss: 0.5137 - output_aux_loss: 0.4178\n",
      "Epoch 23/500\n",
      "1411/1411 [==============================] - 0s 227us/sample - loss: 1.0226 - output_reg_loss: 0.6765 - output_class_loss: 0.5137 - output_aux_loss: 0.4186\n",
      "Epoch 24/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.9968 - output_reg_loss: 0.8739 - output_class_loss: 0.5137 - output_aux_loss: 0.4174\n",
      "Epoch 25/500\n",
      "1411/1411 [==============================] - 0s 229us/sample - loss: 0.9532 - output_reg_loss: 0.6876 - output_class_loss: 0.5275 - output_aux_loss: 0.4345\n",
      "Epoch 26/500\n",
      "1411/1411 [==============================] - 0s 232us/sample - loss: 0.9737 - output_reg_loss: 0.5474 - output_class_loss: 0.5275 - output_aux_loss: 0.4219\n",
      "Epoch 27/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.9818 - output_reg_loss: 0.5625 - output_class_loss: 0.5275 - output_aux_loss: 0.4197\n",
      "Epoch 28/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.9590 - output_reg_loss: 0.7263 - output_class_loss: 0.5275 - output_aux_loss: 0.4329\n",
      "Epoch 29/500\n",
      "1411/1411 [==============================] - 0s 222us/sample - loss: 0.9354 - output_reg_loss: 0.5141 - output_class_loss: 0.5275 - output_aux_loss: 0.4192\n",
      "Epoch 30/500\n",
      "1411/1411 [==============================] - 0s 206us/sample - loss: 0.9310 - output_reg_loss: 0.7221 - output_class_loss: 0.5137 - output_aux_loss: 0.4179\n",
      "Epoch 31/500\n",
      "1411/1411 [==============================] - 0s 215us/sample - loss: 0.9364 - output_reg_loss: 0.5777 - output_class_loss: 0.5137 - output_aux_loss: 0.4126\n",
      "Epoch 32/500\n",
      "1411/1411 [==============================] - 0s 219us/sample - loss: 0.9769 - output_reg_loss: 0.9514 - output_class_loss: 0.5275 - output_aux_loss: 0.4342\n",
      "Epoch 33/500\n",
      "1411/1411 [==============================] - 0s 204us/sample - loss: 0.9106 - output_reg_loss: 0.8812 - output_class_loss: 0.5137 - output_aux_loss: 0.4179\n",
      "Epoch 34/500\n",
      "1411/1411 [==============================] - 0s 220us/sample - loss: 0.9420 - output_reg_loss: 0.5201 - output_class_loss: 0.5137 - output_aux_loss: 0.4180\n",
      "Epoch 35/500\n",
      "1411/1411 [==============================] - 0s 229us/sample - loss: 0.9408 - output_reg_loss: 0.6405 - output_class_loss: 0.5137 - output_aux_loss: 0.4163\n",
      "Epoch 36/500\n",
      "1411/1411 [==============================] - 0s 227us/sample - loss: 0.9310 - output_reg_loss: 0.6731 - output_class_loss: 0.5137 - output_aux_loss: 0.4169\n",
      "Epoch 37/500\n",
      "1411/1411 [==============================] - 0s 231us/sample - loss: 0.9313 - output_reg_loss: 0.8268 - output_class_loss: 0.5413 - output_aux_loss: 0.4333\n",
      "Epoch 38/500\n",
      "1411/1411 [==============================] - 0s 231us/sample - loss: 0.9091 - output_reg_loss: 0.6026 - output_class_loss: 0.5137 - output_aux_loss: 0.4133\n",
      "Epoch 39/500\n",
      "1411/1411 [==============================] - 0s 209us/sample - loss: 0.8833 - output_reg_loss: 0.4330 - output_class_loss: 0.5275 - output_aux_loss: 0.4168\n",
      "Epoch 40/500\n",
      "1411/1411 [==============================] - 0s 206us/sample - loss: 0.8974 - output_reg_loss: 0.7798 - output_class_loss: 0.5137 - output_aux_loss: 0.4160\n",
      "Epoch 41/500\n",
      "1411/1411 [==============================] - 0s 226us/sample - loss: 0.8853 - output_reg_loss: 0.6422 - output_class_loss: 0.5137 - output_aux_loss: 0.4167\n",
      "Epoch 42/500\n",
      "1411/1411 [==============================] - 0s 232us/sample - loss: 0.9068 - output_reg_loss: 0.5351 - output_class_loss: 0.5275 - output_aux_loss: 0.4160\n",
      "Epoch 43/500\n",
      "1411/1411 [==============================] - 0s 217us/sample - loss: 0.8609 - output_reg_loss: 0.7149 - output_class_loss: 0.5137 - output_aux_loss: 0.4158\n",
      "Epoch 44/500\n",
      "1411/1411 [==============================] - 0s 214us/sample - loss: 0.8869 - output_reg_loss: 0.6634 - output_class_loss: 0.5137 - output_aux_loss: 0.4180\n",
      "Epoch 45/500\n",
      "1411/1411 [==============================] - 0s 218us/sample - loss: 0.8415 - output_reg_loss: 0.5746 - output_class_loss: 0.5137 - output_aux_loss: 0.4167\n",
      "Epoch 46/500\n",
      "1411/1411 [==============================] - 0s 203us/sample - loss: 0.8483 - output_reg_loss: 0.6095 - output_class_loss: 0.5275 - output_aux_loss: 0.4159\n",
      "Epoch 47/500\n",
      "1411/1411 [==============================] - 0s 205us/sample - loss: 0.8417 - output_reg_loss: 0.5965 - output_class_loss: 0.5137 - output_aux_loss: 0.4154\n",
      "Epoch 48/500\n",
      "1411/1411 [==============================] - 0s 213us/sample - loss: 0.8483 - output_reg_loss: 0.4263 - output_class_loss: 0.5275 - output_aux_loss: 0.4153\n",
      "Epoch 49/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1411/1411 [==============================] - 0s 223us/sample - loss: 0.8434 - output_reg_loss: 0.4130 - output_class_loss: 0.5275 - output_aux_loss: 0.4137\n",
      "Epoch 50/500\n",
      "1411/1411 [==============================] - 0s 231us/sample - loss: 0.8527 - output_reg_loss: 0.6506 - output_class_loss: 0.5137 - output_aux_loss: 0.4128\n",
      "Epoch 51/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 1.0387 - output_reg_loss: 0.9990 - output_class_loss: 0.5413 - output_aux_loss: 0.4310\n",
      "Epoch 52/500\n",
      "1411/1411 [==============================] - 0s 222us/sample - loss: 0.7948 - output_reg_loss: 0.3670 - output_class_loss: 0.5275 - output_aux_loss: 0.4181\n",
      "Epoch 53/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7650 - output_reg_loss: 0.5073 - output_class_loss: 0.5137 - output_aux_loss: 0.4135\n",
      "Epoch 54/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7564 - output_reg_loss: 0.3193 - output_class_loss: 0.5275 - output_aux_loss: 0.4125\n",
      "Epoch 55/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7509 - output_reg_loss: 0.3923 - output_class_loss: 0.5137 - output_aux_loss: 0.4081\n",
      "Epoch 56/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7789 - output_reg_loss: 0.6422 - output_class_loss: 0.5137 - output_aux_loss: 0.4143\n",
      "Epoch 57/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7654 - output_reg_loss: 0.3275 - output_class_loss: 0.5275 - output_aux_loss: 0.4143\n",
      "Epoch 58/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7472 - output_reg_loss: 0.5327 - output_class_loss: 0.5137 - output_aux_loss: 0.4093\n",
      "Epoch 59/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7502 - output_reg_loss: 0.3538 - output_class_loss: 0.5275 - output_aux_loss: 0.4125\n",
      "Epoch 60/500\n",
      "1411/1411 [==============================] - 0s 240us/sample - loss: 0.7696 - output_reg_loss: 0.5975 - output_class_loss: 0.5137 - output_aux_loss: 0.4133\n",
      "Epoch 61/500\n",
      "1411/1411 [==============================] - 0s 255us/sample - loss: 0.7519 - output_reg_loss: 0.5066 - output_class_loss: 0.5137 - output_aux_loss: 0.4129\n",
      "Epoch 62/500\n",
      "1411/1411 [==============================] - 0s 251us/sample - loss: 0.7527 - output_reg_loss: 0.3876 - output_class_loss: 0.5137 - output_aux_loss: 0.4093\n",
      "Epoch 63/500\n",
      "1411/1411 [==============================] - 0s 249us/sample - loss: 0.7354 - output_reg_loss: 0.3605 - output_class_loss: 0.5137 - output_aux_loss: 0.4083\n",
      "Epoch 64/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7514 - output_reg_loss: 0.4432 - output_class_loss: 0.5137 - output_aux_loss: 0.4141\n",
      "Epoch 65/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7409 - output_reg_loss: 0.6622 - output_class_loss: 0.5275 - output_aux_loss: 0.4267\n",
      "Epoch 66/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7246 - output_reg_loss: 0.3788 - output_class_loss: 0.5137 - output_aux_loss: 0.4080\n",
      "Epoch 67/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7585 - output_reg_loss: 0.3689 - output_class_loss: 0.5275 - output_aux_loss: 0.4134\n",
      "Epoch 68/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7466 - output_reg_loss: 0.5291 - output_class_loss: 0.5137 - output_aux_loss: 0.4130\n",
      "Epoch 69/500\n",
      "1411/1411 [==============================] - 0s 244us/sample - loss: 0.7264 - output_reg_loss: 0.3041 - output_class_loss: 0.5275 - output_aux_loss: 0.4118\n",
      "Epoch 70/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7368 - output_reg_loss: 0.6295 - output_class_loss: 0.5137 - output_aux_loss: 0.4137\n",
      "Epoch 71/500\n",
      "1411/1411 [==============================] - 0s 246us/sample - loss: 0.7592 - output_reg_loss: 0.3818 - output_class_loss: 0.5137 - output_aux_loss: 0.4136\n",
      "Epoch 72/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7406 - output_reg_loss: 0.5019 - output_class_loss: 0.5137 - output_aux_loss: 0.4136\n",
      "Epoch 73/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7259 - output_reg_loss: 0.2628 - output_class_loss: 0.5275 - output_aux_loss: 0.4137\n",
      "Epoch 74/500\n",
      "1411/1411 [==============================] - 0s 241us/sample - loss: 0.7246 - output_reg_loss: 0.6119 - output_class_loss: 0.5137 - output_aux_loss: 0.4118\n",
      "Epoch 75/500\n",
      "1411/1411 [==============================] - 0s 242us/sample - loss: 0.7425 - output_reg_loss: 0.4807 - output_class_loss: 0.5137 - output_aux_loss: 0.4107\n",
      "Epoch 76/500\n",
      "1411/1411 [==============================] - 0s 242us/sample - loss: 0.7308 - output_reg_loss: 0.5105 - output_class_loss: 0.5137 - output_aux_loss: 0.4136\n",
      "Epoch 77/500\n",
      "1411/1411 [==============================] - 0s 241us/sample - loss: 0.7242 - output_reg_loss: 0.2907 - output_class_loss: 0.5275 - output_aux_loss: 0.4135\n",
      "Epoch 78/500\n",
      "1411/1411 [==============================] - 0s 246us/sample - loss: 0.7139 - output_reg_loss: 0.3658 - output_class_loss: 0.5137 - output_aux_loss: 0.4076\n",
      "Epoch 79/500\n",
      "1411/1411 [==============================] - 0s 240us/sample - loss: 0.7235 - output_reg_loss: 0.4342 - output_class_loss: 0.5137 - output_aux_loss: 0.4116\n",
      "Epoch 80/500\n",
      "1411/1411 [==============================] - 0s 240us/sample - loss: 0.7239 - output_reg_loss: 0.4413 - output_class_loss: 0.5413 - output_aux_loss: 0.4279\n",
      "Epoch 81/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7383 - output_reg_loss: 0.3883 - output_class_loss: 0.5137 - output_aux_loss: 0.4138\n",
      "Epoch 82/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7432 - output_reg_loss: 0.5648 - output_class_loss: 0.5137 - output_aux_loss: 0.4188\n",
      "Epoch 83/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7189 - output_reg_loss: 0.3242 - output_class_loss: 0.5137 - output_aux_loss: 0.4074\n",
      "Epoch 84/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7219 - output_reg_loss: 0.3952 - output_class_loss: 0.5275 - output_aux_loss: 0.4198\n",
      "Epoch 85/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7347 - output_reg_loss: 0.5309 - output_class_loss: 0.5137 - output_aux_loss: 0.4111\n",
      "Epoch 86/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7085 - output_reg_loss: 0.3095 - output_class_loss: 0.5137 - output_aux_loss: 0.4082\n",
      "Epoch 87/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7232 - output_reg_loss: 0.2536 - output_class_loss: 0.5275 - output_aux_loss: 0.4129\n",
      "Epoch 88/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7144 - output_reg_loss: 0.4589 - output_class_loss: 0.5137 - output_aux_loss: 0.4090\n",
      "Epoch 89/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7384 - output_reg_loss: 0.4720 - output_class_loss: 0.5137 - output_aux_loss: 0.4113\n",
      "Epoch 90/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7122 - output_reg_loss: 0.2366 - output_class_loss: 0.5275 - output_aux_loss: 0.4135\n",
      "Epoch 91/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7075 - output_reg_loss: 0.2784 - output_class_loss: 0.5275 - output_aux_loss: 0.4184\n",
      "Epoch 92/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7248 - output_reg_loss: 0.5681 - output_class_loss: 0.5137 - output_aux_loss: 0.4095\n",
      "Epoch 93/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7190 - output_reg_loss: 0.2536 - output_class_loss: 0.5275 - output_aux_loss: 0.4125\n",
      "Epoch 94/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7434 - output_reg_loss: 0.4537 - output_class_loss: 0.5137 - output_aux_loss: 0.4126\n",
      "Epoch 95/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7362 - output_reg_loss: 0.3578 - output_class_loss: 0.5137 - output_aux_loss: 0.4100\n",
      "Epoch 96/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7388 - output_reg_loss: 0.4638 - output_class_loss: 0.5413 - output_aux_loss: 0.4336\n",
      "Epoch 97/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7290 - output_reg_loss: 0.2776 - output_class_loss: 0.5275 - output_aux_loss: 0.4122\n",
      "Epoch 98/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7023 - output_reg_loss: 0.2381 - output_class_loss: 0.5275 - output_aux_loss: 0.4127\n",
      "Epoch 99/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7243 - output_reg_loss: 0.4723 - output_class_loss: 0.5137 - output_aux_loss: 0.4126\n",
      "Epoch 100/500\n",
      "1411/1411 [==============================] - 0s 232us/sample - loss: 0.7544 - output_reg_loss: 0.4751 - output_class_loss: 0.5137 - output_aux_loss: 0.4141\n",
      "Epoch 101/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7344 - output_reg_loss: 0.5872 - output_class_loss: 0.5137 - output_aux_loss: 0.4128\n",
      "Epoch 102/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7271 - output_reg_loss: 0.2706 - output_class_loss: 0.5137 - output_aux_loss: 0.4146\n",
      "Epoch 103/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7593 - output_reg_loss: 0.6219 - output_class_loss: 0.5137 - output_aux_loss: 0.4156\n",
      "Epoch 104/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7115 - output_reg_loss: 0.4701 - output_class_loss: 0.5137 - output_aux_loss: 0.4097\n",
      "Epoch 105/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7409 - output_reg_loss: 0.5103 - output_class_loss: 0.5413 - output_aux_loss: 0.4276\n",
      "Epoch 106/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7321 - output_reg_loss: 0.2727 - output_class_loss: 0.5275 - output_aux_loss: 0.4135\n",
      "Epoch 107/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7531 - output_reg_loss: 0.5352 - output_class_loss: 0.5137 - output_aux_loss: 0.4145\n",
      "Epoch 108/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7290 - output_reg_loss: 0.5028 - output_class_loss: 0.5413 - output_aux_loss: 0.4269\n",
      "Epoch 109/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7137 - output_reg_loss: 0.2869 - output_class_loss: 0.5137 - output_aux_loss: 0.4130\n",
      "Epoch 110/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7128 - output_reg_loss: 0.4586 - output_class_loss: 0.5137 - output_aux_loss: 0.4117\n",
      "Epoch 111/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7397 - output_reg_loss: 0.5030 - output_class_loss: 0.5137 - output_aux_loss: 0.4133\n",
      "Epoch 112/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7336 - output_reg_loss: 0.2666 - output_class_loss: 0.5275 - output_aux_loss: 0.4136\n",
      "Epoch 113/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7058 - output_reg_loss: 0.4372 - output_class_loss: 0.5137 - output_aux_loss: 0.4110\n",
      "Epoch 114/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7315 - output_reg_loss: 0.2757 - output_class_loss: 0.5275 - output_aux_loss: 0.4148\n",
      "Epoch 115/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7045 - output_reg_loss: 0.4368 - output_class_loss: 0.5413 - output_aux_loss: 0.4301\n",
      "Epoch 116/500\n",
      "1411/1411 [==============================] - 0s 230us/sample - loss: 0.7142 - output_reg_loss: 0.3326 - output_class_loss: 0.5275 - output_aux_loss: 0.4190\n",
      "Epoch 117/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7219 - output_reg_loss: 0.4276 - output_class_loss: 0.5137 - output_aux_loss: 0.4118\n",
      "Epoch 118/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7225 - output_reg_loss: 0.4838 - output_class_loss: 0.5413 - output_aux_loss: 0.4264\n",
      "Epoch 119/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7156 - output_reg_loss: 0.3941 - output_class_loss: 0.5137 - output_aux_loss: 0.4121\n",
      "Epoch 120/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7287 - output_reg_loss: 0.4417 - output_class_loss: 0.5137 - output_aux_loss: 0.4116\n",
      "Epoch 121/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7220 - output_reg_loss: 0.3793 - output_class_loss: 0.5137 - output_aux_loss: 0.4120\n",
      "Epoch 122/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7128 - output_reg_loss: 0.2914 - output_class_loss: 0.5275 - output_aux_loss: 0.4118\n",
      "Epoch 123/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7257 - output_reg_loss: 0.2946 - output_class_loss: 0.5275 - output_aux_loss: 0.4138\n",
      "Epoch 124/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7585 - output_reg_loss: 0.4181 - output_class_loss: 0.5275 - output_aux_loss: 0.4239\n",
      "Epoch 125/500\n",
      "1411/1411 [==============================] - 0s 232us/sample - loss: 0.7178 - output_reg_loss: 0.3014 - output_class_loss: 0.5275 - output_aux_loss: 0.4137\n",
      "Epoch 126/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7215 - output_reg_loss: 0.2545 - output_class_loss: 0.5275 - output_aux_loss: 0.4127\n",
      "Epoch 127/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7209 - output_reg_loss: 0.2502 - output_class_loss: 0.5275 - output_aux_loss: 0.4130\n",
      "Epoch 128/500\n",
      "1411/1411 [==============================] - 0s 225us/sample - loss: 0.7273 - output_reg_loss: 0.5016 - output_class_loss: 0.5137 - output_aux_loss: 0.4118\n",
      "Epoch 129/500\n",
      "1411/1411 [==============================] - 0s 229us/sample - loss: 0.7273 - output_reg_loss: 0.2865 - output_class_loss: 0.5275 - output_aux_loss: 0.4129\n",
      "Epoch 130/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7337 - output_reg_loss: 0.3312 - output_class_loss: 0.5137 - output_aux_loss: 0.4087\n",
      "Epoch 131/500\n",
      "1411/1411 [==============================] - 0s 231us/sample - loss: 0.7590 - output_reg_loss: 0.3172 - output_class_loss: 0.5137 - output_aux_loss: 0.4154\n",
      "Epoch 132/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7187 - output_reg_loss: 0.2517 - output_class_loss: 0.5137 - output_aux_loss: 0.4121\n",
      "Epoch 133/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7358 - output_reg_loss: 0.4807 - output_class_loss: 0.5137 - output_aux_loss: 0.4129\n",
      "Epoch 134/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7138 - output_reg_loss: 0.3209 - output_class_loss: 0.5137 - output_aux_loss: 0.4114\n",
      "Epoch 135/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7457 - output_reg_loss: 0.5003 - output_class_loss: 0.5137 - output_aux_loss: 0.4116\n",
      "Epoch 136/500\n",
      "1411/1411 [==============================] - 0s 232us/sample - loss: 0.7343 - output_reg_loss: 0.4651 - output_class_loss: 0.5137 - output_aux_loss: 0.4121\n",
      "Epoch 137/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7125 - output_reg_loss: 0.3632 - output_class_loss: 0.5137 - output_aux_loss: 0.4079\n",
      "Epoch 138/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7283 - output_reg_loss: 0.4531 - output_class_loss: 0.5137 - output_aux_loss: 0.4120\n",
      "Epoch 139/500\n",
      "1411/1411 [==============================] - 0s 229us/sample - loss: 0.7486 - output_reg_loss: 0.7365 - output_class_loss: 0.5413 - output_aux_loss: 0.4299\n",
      "Epoch 140/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7154 - output_reg_loss: 0.2664 - output_class_loss: 0.5137 - output_aux_loss: 0.4091\n",
      "Epoch 141/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7217 - output_reg_loss: 0.4614 - output_class_loss: 0.5137 - output_aux_loss: 0.4122\n",
      "Epoch 142/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7249 - output_reg_loss: 0.2551 - output_class_loss: 0.5275 - output_aux_loss: 0.4126\n",
      "Epoch 143/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7406 - output_reg_loss: 0.6711 - output_class_loss: 0.5275 - output_aux_loss: 0.4255\n",
      "Epoch 144/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7084 - output_reg_loss: 0.3184 - output_class_loss: 0.5137 - output_aux_loss: 0.4069\n",
      "Epoch 145/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7193 - output_reg_loss: 0.4652 - output_class_loss: 0.5137 - output_aux_loss: 0.4114\n",
      "Epoch 146/500\n",
      "1411/1411 [==============================] - 0s 240us/sample - loss: 0.7239 - output_reg_loss: 0.3769 - output_class_loss: 0.5275 - output_aux_loss: 0.4201\n",
      "Epoch 147/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7228 - output_reg_loss: 0.4087 - output_class_loss: 0.5413 - output_aux_loss: 0.4289\n",
      "Epoch 148/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7663 - output_reg_loss: 0.5177 - output_class_loss: 0.5137 - output_aux_loss: 0.4142\n",
      "Epoch 149/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7335 - output_reg_loss: 0.8815 - output_class_loss: 0.5551 - output_aux_loss: 0.4405\n",
      "Epoch 150/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7302 - output_reg_loss: 0.4420 - output_class_loss: 0.5137 - output_aux_loss: 0.4120\n",
      "Epoch 151/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7352 - output_reg_loss: 0.2919 - output_class_loss: 0.5275 - output_aux_loss: 0.4150\n",
      "Epoch 152/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7484 - output_reg_loss: 0.3717 - output_class_loss: 0.5275 - output_aux_loss: 0.4140\n",
      "Epoch 153/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7298 - output_reg_loss: 0.3213 - output_class_loss: 0.5137 - output_aux_loss: 0.4106\n",
      "Epoch 154/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7409 - output_reg_loss: 0.3082 - output_class_loss: 0.5275 - output_aux_loss: 0.4190\n",
      "Epoch 155/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7205 - output_reg_loss: 0.3419 - output_class_loss: 0.5137 - output_aux_loss: 0.4115\n",
      "Epoch 156/500\n",
      "1411/1411 [==============================] - 0s 241us/sample - loss: 0.7326 - output_reg_loss: 0.2648 - output_class_loss: 0.5275 - output_aux_loss: 0.4145\n",
      "Epoch 157/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7018 - output_reg_loss: 0.2232 - output_class_loss: 0.5275 - output_aux_loss: 0.4124\n",
      "Epoch 158/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7141 - output_reg_loss: 0.2427 - output_class_loss: 0.5275 - output_aux_loss: 0.4135\n",
      "Epoch 159/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7129 - output_reg_loss: 0.5773 - output_class_loss: 0.5413 - output_aux_loss: 0.4262\n",
      "Epoch 160/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7310 - output_reg_loss: 0.6476 - output_class_loss: 0.5413 - output_aux_loss: 0.4254\n",
      "Epoch 161/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7244 - output_reg_loss: 0.2626 - output_class_loss: 0.5275 - output_aux_loss: 0.4129\n",
      "Epoch 162/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7150 - output_reg_loss: 0.3508 - output_class_loss: 0.5137 - output_aux_loss: 0.4080\n",
      "Epoch 163/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7201 - output_reg_loss: 0.2839 - output_class_loss: 0.5137 - output_aux_loss: 0.4119\n",
      "Epoch 164/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7363 - output_reg_loss: 0.2724 - output_class_loss: 0.5275 - output_aux_loss: 0.4128\n",
      "Epoch 165/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7438 - output_reg_loss: 0.5913 - output_class_loss: 0.5137 - output_aux_loss: 0.4125\n",
      "Epoch 166/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7373 - output_reg_loss: 0.5740 - output_class_loss: 0.5137 - output_aux_loss: 0.4127\n",
      "Epoch 167/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7590 - output_reg_loss: 0.5535 - output_class_loss: 0.5137 - output_aux_loss: 0.4129\n",
      "Epoch 168/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7185 - output_reg_loss: 0.2653 - output_class_loss: 0.5275 - output_aux_loss: 0.4126\n",
      "Epoch 169/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7443 - output_reg_loss: 0.6949 - output_class_loss: 0.5413 - output_aux_loss: 0.4288\n",
      "Epoch 170/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7306 - output_reg_loss: 0.3029 - output_class_loss: 0.5137 - output_aux_loss: 0.4084\n",
      "Epoch 171/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7333 - output_reg_loss: 0.3556 - output_class_loss: 0.5275 - output_aux_loss: 0.4123\n",
      "Epoch 172/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7429 - output_reg_loss: 0.5321 - output_class_loss: 0.5413 - output_aux_loss: 0.4283\n",
      "Epoch 173/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7270 - output_reg_loss: 0.2695 - output_class_loss: 0.5275 - output_aux_loss: 0.4133\n",
      "Epoch 174/500\n",
      "1411/1411 [==============================] - 0s 208us/sample - loss: 0.7160 - output_reg_loss: 0.4097 - output_class_loss: 0.5137 - output_aux_loss: 0.4124\n",
      "Epoch 175/500\n",
      "1411/1411 [==============================] - 0s 224us/sample - loss: 0.7051 - output_reg_loss: 0.2275 - output_class_loss: 0.5275 - output_aux_loss: 0.4127\n",
      "Epoch 176/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.6973 - output_reg_loss: 0.2183 - output_class_loss: 0.5275 - output_aux_loss: 0.4130\n",
      "Epoch 177/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7374 - output_reg_loss: 0.4604 - output_class_loss: 0.5137 - output_aux_loss: 0.4127\n",
      "Epoch 178/500\n",
      "1411/1411 [==============================] - 0s 232us/sample - loss: 0.7329 - output_reg_loss: 0.3684 - output_class_loss: 0.5137 - output_aux_loss: 0.4135\n",
      "Epoch 179/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7157 - output_reg_loss: 0.2588 - output_class_loss: 0.5137 - output_aux_loss: 0.4129\n",
      "Epoch 180/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7260 - output_reg_loss: 0.3024 - output_class_loss: 0.5137 - output_aux_loss: 0.4081\n",
      "Epoch 181/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7213 - output_reg_loss: 0.3441 - output_class_loss: 0.5137 - output_aux_loss: 0.4112\n",
      "Epoch 182/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7337 - output_reg_loss: 0.4464 - output_class_loss: 0.5137 - output_aux_loss: 0.4124\n",
      "Epoch 183/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7353 - output_reg_loss: 0.3875 - output_class_loss: 0.5413 - output_aux_loss: 0.4327\n",
      "Epoch 184/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7035 - output_reg_loss: 0.2489 - output_class_loss: 0.5275 - output_aux_loss: 0.4109\n",
      "Epoch 185/500\n",
      "1411/1411 [==============================] - 0s 232us/sample - loss: 0.7075 - output_reg_loss: 0.2324 - output_class_loss: 0.5275 - output_aux_loss: 0.4117\n",
      "Epoch 186/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7435 - output_reg_loss: 0.6139 - output_class_loss: 0.5137 - output_aux_loss: 0.4156\n",
      "Epoch 187/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7190 - output_reg_loss: 0.4042 - output_class_loss: 0.5137 - output_aux_loss: 0.4118\n",
      "Epoch 188/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7310 - output_reg_loss: 0.5375 - output_class_loss: 0.5137 - output_aux_loss: 0.4134\n",
      "Epoch 189/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7415 - output_reg_loss: 0.4653 - output_class_loss: 0.5137 - output_aux_loss: 0.4131\n",
      "Epoch 190/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7229 - output_reg_loss: 0.3835 - output_class_loss: 0.5137 - output_aux_loss: 0.4135\n",
      "Epoch 191/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7284 - output_reg_loss: 0.2731 - output_class_loss: 0.5275 - output_aux_loss: 0.4146\n",
      "Epoch 192/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7523 - output_reg_loss: 0.5488 - output_class_loss: 0.5137 - output_aux_loss: 0.4120\n",
      "Epoch 193/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7319 - output_reg_loss: 0.2799 - output_class_loss: 0.5137 - output_aux_loss: 0.4135\n",
      "Epoch 194/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7282 - output_reg_loss: 0.5227 - output_class_loss: 0.5137 - output_aux_loss: 0.4122\n",
      "Epoch 195/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7429 - output_reg_loss: 0.5175 - output_class_loss: 0.5137 - output_aux_loss: 0.4137\n",
      "Epoch 196/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7504 - output_reg_loss: 0.4283 - output_class_loss: 0.5275 - output_aux_loss: 0.4145\n",
      "Epoch 197/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7287 - output_reg_loss: 0.3679 - output_class_loss: 0.5413 - output_aux_loss: 0.4257\n",
      "Epoch 198/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7243 - output_reg_loss: 0.2977 - output_class_loss: 0.5275 - output_aux_loss: 0.4139\n",
      "Epoch 199/500\n",
      "1411/1411 [==============================] - 0s 232us/sample - loss: 0.7208 - output_reg_loss: 0.4863 - output_class_loss: 0.5137 - output_aux_loss: 0.4122\n",
      "Epoch 200/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7147 - output_reg_loss: 0.4015 - output_class_loss: 0.5275 - output_aux_loss: 0.4169\n",
      "Epoch 201/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7290 - output_reg_loss: 0.2741 - output_class_loss: 0.5275 - output_aux_loss: 0.4124\n",
      "Epoch 202/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7408 - output_reg_loss: 0.4025 - output_class_loss: 0.5137 - output_aux_loss: 0.4127\n",
      "Epoch 203/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7247 - output_reg_loss: 0.3304 - output_class_loss: 0.5275 - output_aux_loss: 0.4167\n",
      "Epoch 204/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7253 - output_reg_loss: 0.3757 - output_class_loss: 0.5275 - output_aux_loss: 0.4134\n",
      "Epoch 205/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7142 - output_reg_loss: 0.3331 - output_class_loss: 0.5275 - output_aux_loss: 0.4128\n",
      "Epoch 206/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7114 - output_reg_loss: 0.5677 - output_class_loss: 0.5137 - output_aux_loss: 0.4107\n",
      "Epoch 207/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7406 - output_reg_loss: 0.3509 - output_class_loss: 0.5413 - output_aux_loss: 0.4270\n",
      "Epoch 208/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7378 - output_reg_loss: 0.3216 - output_class_loss: 0.5275 - output_aux_loss: 0.4158\n",
      "Epoch 209/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7310 - output_reg_loss: 0.4441 - output_class_loss: 0.5137 - output_aux_loss: 0.4120\n",
      "Epoch 210/500\n",
      "1411/1411 [==============================] - 0s 241us/sample - loss: 0.7326 - output_reg_loss: 0.4142 - output_class_loss: 0.5137 - output_aux_loss: 0.4145\n",
      "Epoch 211/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7322 - output_reg_loss: 0.4403 - output_class_loss: 0.5413 - output_aux_loss: 0.4282\n",
      "Epoch 212/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7360 - output_reg_loss: 0.3039 - output_class_loss: 0.5275 - output_aux_loss: 0.4149\n",
      "Epoch 213/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7232 - output_reg_loss: 0.5577 - output_class_loss: 0.5275 - output_aux_loss: 0.4253\n",
      "Epoch 214/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7190 - output_reg_loss: 0.4700 - output_class_loss: 0.5137 - output_aux_loss: 0.4116\n",
      "Epoch 215/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7153 - output_reg_loss: 0.4361 - output_class_loss: 0.5275 - output_aux_loss: 0.4228\n",
      "Epoch 216/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7398 - output_reg_loss: 0.4850 - output_class_loss: 0.5413 - output_aux_loss: 0.4300\n",
      "Epoch 217/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7098 - output_reg_loss: 0.2474 - output_class_loss: 0.5275 - output_aux_loss: 0.4125\n",
      "Epoch 218/500\n",
      "1411/1411 [==============================] - 0s 240us/sample - loss: 0.7186 - output_reg_loss: 0.6934 - output_class_loss: 0.5551 - output_aux_loss: 0.4435\n",
      "Epoch 219/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7024 - output_reg_loss: 0.2442 - output_class_loss: 0.5275 - output_aux_loss: 0.4112\n",
      "Epoch 220/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7219 - output_reg_loss: 0.4411 - output_class_loss: 0.5137 - output_aux_loss: 0.4116\n",
      "Epoch 221/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7178 - output_reg_loss: 0.2514 - output_class_loss: 0.5275 - output_aux_loss: 0.4128\n",
      "Epoch 222/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7040 - output_reg_loss: 0.4027 - output_class_loss: 0.5137 - output_aux_loss: 0.4108\n",
      "Epoch 223/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7286 - output_reg_loss: 0.3227 - output_class_loss: 0.5275 - output_aux_loss: 0.4128\n",
      "Epoch 224/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7516 - output_reg_loss: 0.6279 - output_class_loss: 0.5413 - output_aux_loss: 0.4277\n",
      "Epoch 225/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7336 - output_reg_loss: 0.5761 - output_class_loss: 0.5137 - output_aux_loss: 0.4127\n",
      "Epoch 226/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7374 - output_reg_loss: 0.4212 - output_class_loss: 0.5137 - output_aux_loss: 0.4130\n",
      "Epoch 227/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7151 - output_reg_loss: 0.4026 - output_class_loss: 0.5137 - output_aux_loss: 0.4078\n",
      "Epoch 228/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7507 - output_reg_loss: 0.6070 - output_class_loss: 0.5275 - output_aux_loss: 0.4272\n",
      "Epoch 229/500\n",
      "1411/1411 [==============================] - 0s 230us/sample - loss: 0.7223 - output_reg_loss: 0.2614 - output_class_loss: 0.5275 - output_aux_loss: 0.4136\n",
      "Epoch 230/500\n",
      "1411/1411 [==============================] - 0s 221us/sample - loss: 0.7178 - output_reg_loss: 0.2774 - output_class_loss: 0.5275 - output_aux_loss: 0.4139\n",
      "Epoch 231/500\n",
      "1411/1411 [==============================] - 0s 241us/sample - loss: 0.7398 - output_reg_loss: 0.5439 - output_class_loss: 0.5137 - output_aux_loss: 0.4137\n",
      "Epoch 232/500\n",
      "1411/1411 [==============================] - 0s 216us/sample - loss: 0.7302 - output_reg_loss: 0.3932 - output_class_loss: 0.5275 - output_aux_loss: 0.4240\n",
      "Epoch 233/500\n",
      "1411/1411 [==============================] - 0s 221us/sample - loss: 0.7340 - output_reg_loss: 0.3476 - output_class_loss: 0.5275 - output_aux_loss: 0.4169\n",
      "Epoch 234/500\n",
      "1411/1411 [==============================] - 0s 226us/sample - loss: 0.7170 - output_reg_loss: 0.4430 - output_class_loss: 0.5413 - output_aux_loss: 0.4261\n",
      "Epoch 235/500\n",
      "1411/1411 [==============================] - 0s 220us/sample - loss: 0.7191 - output_reg_loss: 0.2468 - output_class_loss: 0.5275 - output_aux_loss: 0.4130\n",
      "Epoch 236/500\n",
      "1411/1411 [==============================] - 0s 232us/sample - loss: 0.7112 - output_reg_loss: 0.2417 - output_class_loss: 0.5275 - output_aux_loss: 0.4120\n",
      "Epoch 237/500\n",
      "1411/1411 [==============================] - 0s 228us/sample - loss: 0.7318 - output_reg_loss: 0.2656 - output_class_loss: 0.5275 - output_aux_loss: 0.4134\n",
      "Epoch 238/500\n",
      "1411/1411 [==============================] - 0s 232us/sample - loss: 0.7231 - output_reg_loss: 0.4775 - output_class_loss: 0.5137 - output_aux_loss: 0.4103\n",
      "Epoch 239/500\n",
      "1411/1411 [==============================] - 0s 225us/sample - loss: 0.7152 - output_reg_loss: 0.3807 - output_class_loss: 0.5137 - output_aux_loss: 0.4108\n",
      "Epoch 240/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7219 - output_reg_loss: 0.6263 - output_class_loss: 0.5551 - output_aux_loss: 0.4438\n",
      "Epoch 241/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1411/1411 [==============================] - 0s 240us/sample - loss: 0.7244 - output_reg_loss: 0.3092 - output_class_loss: 0.5137 - output_aux_loss: 0.4126\n",
      "Epoch 242/500\n",
      "1411/1411 [==============================] - 0s 231us/sample - loss: 0.7047 - output_reg_loss: 0.2436 - output_class_loss: 0.5137 - output_aux_loss: 0.4111\n",
      "Epoch 243/500\n",
      "1411/1411 [==============================] - 0s 242us/sample - loss: 0.7338 - output_reg_loss: 0.3765 - output_class_loss: 0.5137 - output_aux_loss: 0.4100\n",
      "Epoch 244/500\n",
      "1411/1411 [==============================] - 0s 201us/sample - loss: 0.7094 - output_reg_loss: 0.4039 - output_class_loss: 0.5413 - output_aux_loss: 0.4283\n",
      "Epoch 245/500\n",
      "1411/1411 [==============================] - 0s 208us/sample - loss: 0.7130 - output_reg_loss: 0.5679 - output_class_loss: 0.5137 - output_aux_loss: 0.4127\n",
      "Epoch 246/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7101 - output_reg_loss: 0.2707 - output_class_loss: 0.5137 - output_aux_loss: 0.4118\n",
      "Epoch 247/500\n",
      "1411/1411 [==============================] - 0s 227us/sample - loss: 0.7442 - output_reg_loss: 0.5772 - output_class_loss: 0.5413 - output_aux_loss: 0.4279\n",
      "Epoch 248/500\n",
      "1411/1411 [==============================] - 0s 202us/sample - loss: 0.7046 - output_reg_loss: 0.3164 - output_class_loss: 0.5137 - output_aux_loss: 0.4097\n",
      "Epoch 249/500\n",
      "1411/1411 [==============================] - 0s 221us/sample - loss: 0.7425 - output_reg_loss: 0.4810 - output_class_loss: 0.5137 - output_aux_loss: 0.4146\n",
      "Epoch 250/500\n",
      "1411/1411 [==============================] - 0s 216us/sample - loss: 0.7097 - output_reg_loss: 0.2611 - output_class_loss: 0.5137 - output_aux_loss: 0.4072\n",
      "Epoch 251/500\n",
      "1411/1411 [==============================] - 0s 206us/sample - loss: 0.7212 - output_reg_loss: 0.5430 - output_class_loss: 0.5137 - output_aux_loss: 0.4122\n",
      "Epoch 252/500\n",
      "1411/1411 [==============================] - 0s 225us/sample - loss: 0.7427 - output_reg_loss: 0.3838 - output_class_loss: 0.5275 - output_aux_loss: 0.4221\n",
      "Epoch 253/500\n",
      "1411/1411 [==============================] - 0s 231us/sample - loss: 0.7280 - output_reg_loss: 0.2723 - output_class_loss: 0.5275 - output_aux_loss: 0.4130\n",
      "Epoch 254/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7385 - output_reg_loss: 0.4614 - output_class_loss: 0.5137 - output_aux_loss: 0.4127\n",
      "Epoch 255/500\n",
      "1411/1411 [==============================] - 0s 229us/sample - loss: 0.7167 - output_reg_loss: 0.7994 - output_class_loss: 0.5551 - output_aux_loss: 0.4457\n",
      "Epoch 256/500\n",
      "1411/1411 [==============================] - 0s 230us/sample - loss: 0.7252 - output_reg_loss: 0.3158 - output_class_loss: 0.5275 - output_aux_loss: 0.4126\n",
      "Epoch 257/500\n",
      "1411/1411 [==============================] - 0s 230us/sample - loss: 0.7307 - output_reg_loss: 0.2845 - output_class_loss: 0.5275 - output_aux_loss: 0.4145\n",
      "Epoch 258/500\n",
      "1411/1411 [==============================] - 0s 232us/sample - loss: 0.7284 - output_reg_loss: 0.8444 - output_class_loss: 0.5275 - output_aux_loss: 0.4267\n",
      "Epoch 259/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7097 - output_reg_loss: 0.2785 - output_class_loss: 0.5275 - output_aux_loss: 0.4121\n",
      "Epoch 260/500\n",
      "1411/1411 [==============================] - 0s 231us/sample - loss: 0.7302 - output_reg_loss: 0.2659 - output_class_loss: 0.5275 - output_aux_loss: 0.4131\n",
      "Epoch 261/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7273 - output_reg_loss: 0.5653 - output_class_loss: 0.5275 - output_aux_loss: 0.4228\n",
      "Epoch 262/500\n",
      "1411/1411 [==============================] - 0s 232us/sample - loss: 0.7183 - output_reg_loss: 0.4716 - output_class_loss: 0.5137 - output_aux_loss: 0.4122\n",
      "Epoch 263/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7147 - output_reg_loss: 0.2462 - output_class_loss: 0.5275 - output_aux_loss: 0.4116\n",
      "Epoch 264/500\n",
      "1411/1411 [==============================] - 0s 232us/sample - loss: 0.7608 - output_reg_loss: 0.3423 - output_class_loss: 0.5275 - output_aux_loss: 0.4163\n",
      "Epoch 265/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7256 - output_reg_loss: 0.7803 - output_class_loss: 0.5275 - output_aux_loss: 0.4261\n",
      "Epoch 266/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7237 - output_reg_loss: 0.2999 - output_class_loss: 0.5137 - output_aux_loss: 0.4110\n",
      "Epoch 267/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7208 - output_reg_loss: 0.4603 - output_class_loss: 0.5275 - output_aux_loss: 0.4233\n",
      "Epoch 268/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7180 - output_reg_loss: 0.3712 - output_class_loss: 0.5137 - output_aux_loss: 0.4075\n",
      "Epoch 269/500\n",
      "1411/1411 [==============================] - 0s 241us/sample - loss: 0.7158 - output_reg_loss: 0.2837 - output_class_loss: 0.5137 - output_aux_loss: 0.4130\n",
      "Epoch 270/500\n",
      "1411/1411 [==============================] - 0s 227us/sample - loss: 0.7193 - output_reg_loss: 0.2870 - output_class_loss: 0.5275 - output_aux_loss: 0.4127\n",
      "Epoch 271/500\n",
      "1411/1411 [==============================] - 0s 223us/sample - loss: 0.7487 - output_reg_loss: 0.5876 - output_class_loss: 0.5137 - output_aux_loss: 0.4119\n",
      "Epoch 272/500\n",
      "1411/1411 [==============================] - 0s 224us/sample - loss: 0.7268 - output_reg_loss: 0.2654 - output_class_loss: 0.5275 - output_aux_loss: 0.4131\n",
      "Epoch 273/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7291 - output_reg_loss: 0.4461 - output_class_loss: 0.5137 - output_aux_loss: 0.4133\n",
      "Epoch 274/500\n",
      "1411/1411 [==============================] - 0s 242us/sample - loss: 0.7593 - output_reg_loss: 0.3992 - output_class_loss: 0.5137 - output_aux_loss: 0.4107\n",
      "Epoch 275/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7419 - output_reg_loss: 0.3005 - output_class_loss: 0.5275 - output_aux_loss: 0.4128\n",
      "Epoch 276/500\n",
      "1411/1411 [==============================] - 0s 230us/sample - loss: 0.7118 - output_reg_loss: 0.3105 - output_class_loss: 0.5275 - output_aux_loss: 0.4138\n",
      "Epoch 277/500\n",
      "1411/1411 [==============================] - 0s 220us/sample - loss: 0.7124 - output_reg_loss: 0.3837 - output_class_loss: 0.5413 - output_aux_loss: 0.4258\n",
      "Epoch 278/500\n",
      "1411/1411 [==============================] - 0s 216us/sample - loss: 0.7264 - output_reg_loss: 0.2749 - output_class_loss: 0.5137 - output_aux_loss: 0.4126\n",
      "Epoch 279/500\n",
      "1411/1411 [==============================] - 0s 243us/sample - loss: 0.7195 - output_reg_loss: 0.3406 - output_class_loss: 0.5137 - output_aux_loss: 0.4084\n",
      "Epoch 280/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7275 - output_reg_loss: 0.2726 - output_class_loss: 0.5275 - output_aux_loss: 0.4139\n",
      "Epoch 281/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7319 - output_reg_loss: 0.4553 - output_class_loss: 0.5413 - output_aux_loss: 0.4274\n",
      "Epoch 282/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7425 - output_reg_loss: 0.4487 - output_class_loss: 0.5137 - output_aux_loss: 0.4119\n",
      "Epoch 283/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7130 - output_reg_loss: 0.3646 - output_class_loss: 0.5137 - output_aux_loss: 0.4115\n",
      "Epoch 284/500\n",
      "1411/1411 [==============================] - 0s 220us/sample - loss: 0.7329 - output_reg_loss: 0.3683 - output_class_loss: 0.5137 - output_aux_loss: 0.4101\n",
      "Epoch 285/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7474 - output_reg_loss: 0.4402 - output_class_loss: 0.5413 - output_aux_loss: 0.4274\n",
      "Epoch 286/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7401 - output_reg_loss: 0.5175 - output_class_loss: 0.5137 - output_aux_loss: 0.4125\n",
      "Epoch 287/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7242 - output_reg_loss: 0.5293 - output_class_loss: 0.5137 - output_aux_loss: 0.4112\n",
      "Epoch 288/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7421 - output_reg_loss: 0.5051 - output_class_loss: 0.5137 - output_aux_loss: 0.4096\n",
      "Epoch 289/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1411/1411 [==============================] - 0s 231us/sample - loss: 0.7209 - output_reg_loss: 0.3995 - output_class_loss: 0.5137 - output_aux_loss: 0.4098\n",
      "Epoch 290/500\n",
      "1411/1411 [==============================] - 0s 228us/sample - loss: 0.7469 - output_reg_loss: 0.8011 - output_class_loss: 0.5275 - output_aux_loss: 0.4260\n",
      "Epoch 291/500\n",
      "1411/1411 [==============================] - 0s 221us/sample - loss: 0.7168 - output_reg_loss: 0.4425 - output_class_loss: 0.5137 - output_aux_loss: 0.4113\n",
      "Epoch 292/500\n",
      "1411/1411 [==============================] - 0s 207us/sample - loss: 0.7220 - output_reg_loss: 0.4645 - output_class_loss: 0.5275 - output_aux_loss: 0.4117\n",
      "Epoch 293/500\n",
      "1411/1411 [==============================] - 0s 229us/sample - loss: 0.7318 - output_reg_loss: 0.4417 - output_class_loss: 0.5137 - output_aux_loss: 0.4121\n",
      "Epoch 294/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7557 - output_reg_loss: 0.6129 - output_class_loss: 0.5137 - output_aux_loss: 0.4146\n",
      "Epoch 295/500\n",
      "1411/1411 [==============================] - 0s 228us/sample - loss: 0.7496 - output_reg_loss: 0.3061 - output_class_loss: 0.5275 - output_aux_loss: 0.4151\n",
      "Epoch 296/500\n",
      "1411/1411 [==============================] - 0s 216us/sample - loss: 0.7590 - output_reg_loss: 0.4455 - output_class_loss: 0.5137 - output_aux_loss: 0.4128\n",
      "Epoch 297/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7213 - output_reg_loss: 0.5552 - output_class_loss: 0.5137 - output_aux_loss: 0.4118\n",
      "Epoch 298/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7210 - output_reg_loss: 0.6585 - output_class_loss: 0.5413 - output_aux_loss: 0.4322\n",
      "Epoch 299/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7266 - output_reg_loss: 0.4751 - output_class_loss: 0.5137 - output_aux_loss: 0.4120\n",
      "Epoch 300/500\n",
      "1411/1411 [==============================] - 0s 221us/sample - loss: 0.7179 - output_reg_loss: 0.4745 - output_class_loss: 0.5275 - output_aux_loss: 0.4230\n",
      "Epoch 301/500\n",
      "1411/1411 [==============================] - 0s 231us/sample - loss: 0.7248 - output_reg_loss: 0.8035 - output_class_loss: 0.5551 - output_aux_loss: 0.4386\n",
      "Epoch 302/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7308 - output_reg_loss: 0.4489 - output_class_loss: 0.5275 - output_aux_loss: 0.4243\n",
      "Epoch 303/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7254 - output_reg_loss: 0.4953 - output_class_loss: 0.5413 - output_aux_loss: 0.4290\n",
      "Epoch 304/500\n",
      "1411/1411 [==============================] - 0s 241us/sample - loss: 0.7436 - output_reg_loss: 0.6329 - output_class_loss: 0.5275 - output_aux_loss: 0.4252\n",
      "Epoch 305/500\n",
      "1411/1411 [==============================] - 0s 243us/sample - loss: 0.7120 - output_reg_loss: 0.2983 - output_class_loss: 0.5275 - output_aux_loss: 0.4138\n",
      "Epoch 306/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7308 - output_reg_loss: 0.5503 - output_class_loss: 0.5275 - output_aux_loss: 0.4269\n",
      "Epoch 307/500\n",
      "1411/1411 [==============================] - 0s 241us/sample - loss: 0.7215 - output_reg_loss: 0.4394 - output_class_loss: 0.5137 - output_aux_loss: 0.4120\n",
      "Epoch 308/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7425 - output_reg_loss: 0.2811 - output_class_loss: 0.5275 - output_aux_loss: 0.4128\n",
      "Epoch 309/500\n",
      "1411/1411 [==============================] - 0s 243us/sample - loss: 0.7562 - output_reg_loss: 0.5283 - output_class_loss: 0.5137 - output_aux_loss: 0.4125\n",
      "Epoch 310/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7098 - output_reg_loss: 0.4425 - output_class_loss: 0.5137 - output_aux_loss: 0.4124\n",
      "Epoch 311/500\n",
      "1411/1411 [==============================] - 0s 243us/sample - loss: 0.7134 - output_reg_loss: 0.2829 - output_class_loss: 0.5275 - output_aux_loss: 0.4173\n",
      "Epoch 312/500\n",
      "1411/1411 [==============================] - 0s 241us/sample - loss: 0.7159 - output_reg_loss: 0.2490 - output_class_loss: 0.5275 - output_aux_loss: 0.4127\n",
      "Epoch 313/500\n",
      "1411/1411 [==============================] - 0s 240us/sample - loss: 0.7205 - output_reg_loss: 0.2533 - output_class_loss: 0.5275 - output_aux_loss: 0.4111\n",
      "Epoch 314/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7367 - output_reg_loss: 0.3241 - output_class_loss: 0.5275 - output_aux_loss: 0.4137\n",
      "Epoch 315/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7236 - output_reg_loss: 0.2893 - output_class_loss: 0.5275 - output_aux_loss: 0.4132\n",
      "Epoch 316/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7137 - output_reg_loss: 0.3517 - output_class_loss: 0.5275 - output_aux_loss: 0.4126\n",
      "Epoch 317/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7090 - output_reg_loss: 0.2916 - output_class_loss: 0.5275 - output_aux_loss: 0.4152\n",
      "Epoch 318/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7344 - output_reg_loss: 0.3240 - output_class_loss: 0.5137 - output_aux_loss: 0.4121\n",
      "Epoch 319/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7300 - output_reg_loss: 0.5354 - output_class_loss: 0.5275 - output_aux_loss: 0.4265\n",
      "Epoch 320/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7416 - output_reg_loss: 0.3479 - output_class_loss: 0.5413 - output_aux_loss: 0.4239\n",
      "Epoch 321/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7071 - output_reg_loss: 0.4006 - output_class_loss: 0.5413 - output_aux_loss: 0.4331\n",
      "Epoch 322/500\n",
      "1411/1411 [==============================] - 0s 247us/sample - loss: 0.7324 - output_reg_loss: 0.2753 - output_class_loss: 0.5137 - output_aux_loss: 0.4095\n",
      "Epoch 323/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7705 - output_reg_loss: 0.7713 - output_class_loss: 0.5413 - output_aux_loss: 0.4285\n",
      "Epoch 324/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7152 - output_reg_loss: 0.2552 - output_class_loss: 0.5275 - output_aux_loss: 0.4134\n",
      "Epoch 325/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7220 - output_reg_loss: 0.2512 - output_class_loss: 0.5275 - output_aux_loss: 0.4124\n",
      "Epoch 326/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7258 - output_reg_loss: 0.3121 - output_class_loss: 0.5137 - output_aux_loss: 0.4130\n",
      "Epoch 327/500\n",
      "1411/1411 [==============================] - 0s 231us/sample - loss: 0.7231 - output_reg_loss: 0.3625 - output_class_loss: 0.5275 - output_aux_loss: 0.4159\n",
      "Epoch 328/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7436 - output_reg_loss: 0.9340 - output_class_loss: 0.5551 - output_aux_loss: 0.4478\n",
      "Epoch 329/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7332 - output_reg_loss: 0.3544 - output_class_loss: 0.5275 - output_aux_loss: 0.4160\n",
      "Epoch 330/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7219 - output_reg_loss: 0.2765 - output_class_loss: 0.5275 - output_aux_loss: 0.4130\n",
      "Epoch 331/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7188 - output_reg_loss: 0.2696 - output_class_loss: 0.5275 - output_aux_loss: 0.4132\n",
      "Epoch 332/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7155 - output_reg_loss: 0.3920 - output_class_loss: 0.5275 - output_aux_loss: 0.4131\n",
      "Epoch 333/500\n",
      "1411/1411 [==============================] - 0s 244us/sample - loss: 0.7214 - output_reg_loss: 0.3021 - output_class_loss: 0.5275 - output_aux_loss: 0.4123\n",
      "Epoch 334/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7065 - output_reg_loss: 0.3148 - output_class_loss: 0.5137 - output_aux_loss: 0.4105\n",
      "Epoch 335/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7363 - output_reg_loss: 0.3985 - output_class_loss: 0.5137 - output_aux_loss: 0.4129\n",
      "Epoch 336/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7225 - output_reg_loss: 0.2952 - output_class_loss: 0.5275 - output_aux_loss: 0.4131\n",
      "Epoch 337/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1411/1411 [==============================] - 0s 232us/sample - loss: 0.7365 - output_reg_loss: 0.3196 - output_class_loss: 0.5137 - output_aux_loss: 0.4135\n",
      "Epoch 338/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7738 - output_reg_loss: 0.3819 - output_class_loss: 0.5413 - output_aux_loss: 0.4261\n",
      "Epoch 339/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7202 - output_reg_loss: 0.3687 - output_class_loss: 0.5137 - output_aux_loss: 0.4077\n",
      "Epoch 340/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7584 - output_reg_loss: 0.5283 - output_class_loss: 0.5137 - output_aux_loss: 0.4139\n",
      "Epoch 341/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7289 - output_reg_loss: 0.4462 - output_class_loss: 0.5137 - output_aux_loss: 0.4115\n",
      "Epoch 342/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7351 - output_reg_loss: 0.3896 - output_class_loss: 0.5413 - output_aux_loss: 0.4285\n",
      "Epoch 343/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7323 - output_reg_loss: 0.4327 - output_class_loss: 0.5137 - output_aux_loss: 0.4148\n",
      "Epoch 344/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7261 - output_reg_loss: 0.3289 - output_class_loss: 0.5137 - output_aux_loss: 0.4135\n",
      "Epoch 345/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7301 - output_reg_loss: 0.3727 - output_class_loss: 0.5275 - output_aux_loss: 0.4131\n",
      "Epoch 346/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7218 - output_reg_loss: 0.3465 - output_class_loss: 0.5275 - output_aux_loss: 0.4223\n",
      "Epoch 347/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7122 - output_reg_loss: 0.2950 - output_class_loss: 0.5275 - output_aux_loss: 0.4175\n",
      "Epoch 348/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7402 - output_reg_loss: 0.6824 - output_class_loss: 0.5413 - output_aux_loss: 0.4308\n",
      "Epoch 349/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7044 - output_reg_loss: 0.3267 - output_class_loss: 0.5413 - output_aux_loss: 0.4261\n",
      "Epoch 350/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7196 - output_reg_loss: 0.3095 - output_class_loss: 0.5137 - output_aux_loss: 0.4120\n",
      "Epoch 351/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7487 - output_reg_loss: 0.3952 - output_class_loss: 0.5137 - output_aux_loss: 0.4144\n",
      "Epoch 352/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7219 - output_reg_loss: 0.4753 - output_class_loss: 0.5137 - output_aux_loss: 0.4132\n",
      "Epoch 353/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7248 - output_reg_loss: 0.5056 - output_class_loss: 0.5137 - output_aux_loss: 0.4130\n",
      "Epoch 354/500\n",
      "1411/1411 [==============================] - 0s 232us/sample - loss: 0.7270 - output_reg_loss: 0.4852 - output_class_loss: 0.5137 - output_aux_loss: 0.4132\n",
      "Epoch 355/500\n",
      "1411/1411 [==============================] - 0s 230us/sample - loss: 0.7033 - output_reg_loss: 0.3083 - output_class_loss: 0.5137 - output_aux_loss: 0.4113\n",
      "Epoch 356/500\n",
      "1411/1411 [==============================] - 0s 206us/sample - loss: 0.7212 - output_reg_loss: 0.3201 - output_class_loss: 0.5137 - output_aux_loss: 0.4123\n",
      "Epoch 357/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7222 - output_reg_loss: 0.2755 - output_class_loss: 0.5275 - output_aux_loss: 0.4121\n",
      "Epoch 358/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7226 - output_reg_loss: 0.5911 - output_class_loss: 0.5413 - output_aux_loss: 0.4266\n",
      "Epoch 359/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7375 - output_reg_loss: 0.4481 - output_class_loss: 0.5137 - output_aux_loss: 0.4129\n",
      "Epoch 360/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7310 - output_reg_loss: 0.5609 - output_class_loss: 0.5275 - output_aux_loss: 0.4253\n",
      "Epoch 361/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7225 - output_reg_loss: 0.5519 - output_class_loss: 0.5137 - output_aux_loss: 0.4112\n",
      "Epoch 362/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7196 - output_reg_loss: 0.4749 - output_class_loss: 0.5137 - output_aux_loss: 0.4116\n",
      "Epoch 363/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7174 - output_reg_loss: 0.2543 - output_class_loss: 0.5137 - output_aux_loss: 0.4081\n",
      "Epoch 364/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7341 - output_reg_loss: 0.4573 - output_class_loss: 0.5137 - output_aux_loss: 0.4105\n",
      "Epoch 365/500\n",
      "1411/1411 [==============================] - 0s 206us/sample - loss: 0.7227 - output_reg_loss: 0.2549 - output_class_loss: 0.5275 - output_aux_loss: 0.4132\n",
      "Epoch 366/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7282 - output_reg_loss: 0.2598 - output_class_loss: 0.5275 - output_aux_loss: 0.4129\n",
      "Epoch 367/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7337 - output_reg_loss: 0.5347 - output_class_loss: 0.5413 - output_aux_loss: 0.4279\n",
      "Epoch 368/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7184 - output_reg_loss: 0.2506 - output_class_loss: 0.5275 - output_aux_loss: 0.4127\n",
      "Epoch 369/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7272 - output_reg_loss: 0.3109 - output_class_loss: 0.5137 - output_aux_loss: 0.4078\n",
      "Epoch 370/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7210 - output_reg_loss: 0.2649 - output_class_loss: 0.5275 - output_aux_loss: 0.4124\n",
      "Epoch 371/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7123 - output_reg_loss: 0.2371 - output_class_loss: 0.5275 - output_aux_loss: 0.4116\n",
      "Epoch 372/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7212 - output_reg_loss: 0.2779 - output_class_loss: 0.5275 - output_aux_loss: 0.4135\n",
      "Epoch 373/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7175 - output_reg_loss: 0.2493 - output_class_loss: 0.5275 - output_aux_loss: 0.4126\n",
      "Epoch 374/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7364 - output_reg_loss: 0.5620 - output_class_loss: 0.5137 - output_aux_loss: 0.4134\n",
      "Epoch 375/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7276 - output_reg_loss: 0.4153 - output_class_loss: 0.5137 - output_aux_loss: 0.4118\n",
      "Epoch 376/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7236 - output_reg_loss: 0.5694 - output_class_loss: 0.5137 - output_aux_loss: 0.4118\n",
      "Epoch 377/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7353 - output_reg_loss: 0.3059 - output_class_loss: 0.5137 - output_aux_loss: 0.4131\n",
      "Epoch 378/500\n",
      "1411/1411 [==============================] - 0s 223us/sample - loss: 0.7416 - output_reg_loss: 0.3755 - output_class_loss: 0.5413 - output_aux_loss: 0.4265\n",
      "Epoch 379/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7177 - output_reg_loss: 0.4392 - output_class_loss: 0.5137 - output_aux_loss: 0.4128\n",
      "Epoch 380/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7192 - output_reg_loss: 0.2840 - output_class_loss: 0.5275 - output_aux_loss: 0.4181\n",
      "Epoch 381/500\n",
      "1411/1411 [==============================] - 0s 227us/sample - loss: 0.7111 - output_reg_loss: 0.2657 - output_class_loss: 0.5275 - output_aux_loss: 0.4124\n",
      "Epoch 382/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7319 - output_reg_loss: 0.4198 - output_class_loss: 0.5413 - output_aux_loss: 0.4306\n",
      "Epoch 383/500\n",
      "1411/1411 [==============================] - 0s 227us/sample - loss: 0.7239 - output_reg_loss: 0.4208 - output_class_loss: 0.5137 - output_aux_loss: 0.4105\n",
      "Epoch 384/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7222 - output_reg_loss: 0.5373 - output_class_loss: 0.5137 - output_aux_loss: 0.4118\n",
      "Epoch 385/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1411/1411 [==============================] - 0s 230us/sample - loss: 0.7199 - output_reg_loss: 0.4070 - output_class_loss: 0.5413 - output_aux_loss: 0.4328\n",
      "Epoch 386/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7368 - output_reg_loss: 0.5264 - output_class_loss: 0.5137 - output_aux_loss: 0.4117\n",
      "Epoch 387/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7066 - output_reg_loss: 0.5468 - output_class_loss: 0.5137 - output_aux_loss: 0.4121\n",
      "Epoch 388/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7440 - output_reg_loss: 0.6196 - output_class_loss: 0.5413 - output_aux_loss: 0.4269\n",
      "Epoch 389/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7263 - output_reg_loss: 0.4337 - output_class_loss: 0.5137 - output_aux_loss: 0.4117\n",
      "Epoch 390/500\n",
      "1411/1411 [==============================] - 0s 241us/sample - loss: 0.7387 - output_reg_loss: 0.4547 - output_class_loss: 0.5137 - output_aux_loss: 0.4110\n",
      "Epoch 391/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7177 - output_reg_loss: 0.4877 - output_class_loss: 0.5137 - output_aux_loss: 0.4114\n",
      "Epoch 392/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7610 - output_reg_loss: 0.4920 - output_class_loss: 0.5137 - output_aux_loss: 0.4124\n",
      "Epoch 393/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7489 - output_reg_loss: 0.3207 - output_class_loss: 0.5275 - output_aux_loss: 0.4125\n",
      "Epoch 394/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7243 - output_reg_loss: 0.2759 - output_class_loss: 0.5275 - output_aux_loss: 0.4155\n",
      "Epoch 395/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7386 - output_reg_loss: 0.6334 - output_class_loss: 0.5137 - output_aux_loss: 0.4130\n",
      "Epoch 396/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7148 - output_reg_loss: 0.3336 - output_class_loss: 0.5413 - output_aux_loss: 0.4252\n",
      "Epoch 397/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7116 - output_reg_loss: 0.5282 - output_class_loss: 0.5137 - output_aux_loss: 0.4116\n",
      "Epoch 398/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7383 - output_reg_loss: 0.2754 - output_class_loss: 0.5275 - output_aux_loss: 0.4119\n",
      "Epoch 399/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7298 - output_reg_loss: 0.3492 - output_class_loss: 0.5137 - output_aux_loss: 0.4123\n",
      "Epoch 400/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7176 - output_reg_loss: 0.3428 - output_class_loss: 0.5137 - output_aux_loss: 0.4117\n",
      "Epoch 401/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7258 - output_reg_loss: 0.2861 - output_class_loss: 0.5275 - output_aux_loss: 0.4133\n",
      "Epoch 402/500\n",
      "1411/1411 [==============================] - 0s 232us/sample - loss: 0.7371 - output_reg_loss: 0.5994 - output_class_loss: 0.5413 - output_aux_loss: 0.4281\n",
      "Epoch 403/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7256 - output_reg_loss: 0.3221 - output_class_loss: 0.5137 - output_aux_loss: 0.4114\n",
      "Epoch 404/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7120 - output_reg_loss: 0.2381 - output_class_loss: 0.5275 - output_aux_loss: 0.4124\n",
      "Epoch 405/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7102 - output_reg_loss: 0.3335 - output_class_loss: 0.5275 - output_aux_loss: 0.4191\n",
      "Epoch 406/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7233 - output_reg_loss: 0.5691 - output_class_loss: 0.5413 - output_aux_loss: 0.4269\n",
      "Epoch 407/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7302 - output_reg_loss: 0.4313 - output_class_loss: 0.5137 - output_aux_loss: 0.4111\n",
      "Epoch 408/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7307 - output_reg_loss: 0.2884 - output_class_loss: 0.5137 - output_aux_loss: 0.4124\n",
      "Epoch 409/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7349 - output_reg_loss: 0.5028 - output_class_loss: 0.5137 - output_aux_loss: 0.4136\n",
      "Epoch 410/500\n",
      "1411/1411 [==============================] - 0s 230us/sample - loss: 0.7292 - output_reg_loss: 0.2721 - output_class_loss: 0.5275 - output_aux_loss: 0.4135\n",
      "Epoch 411/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7167 - output_reg_loss: 0.3306 - output_class_loss: 0.5137 - output_aux_loss: 0.4096\n",
      "Epoch 412/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7123 - output_reg_loss: 0.2402 - output_class_loss: 0.5275 - output_aux_loss: 0.4126\n",
      "Epoch 413/500\n",
      "1411/1411 [==============================] - 0s 243us/sample - loss: 0.7362 - output_reg_loss: 0.7365 - output_class_loss: 0.5137 - output_aux_loss: 0.4117\n",
      "Epoch 414/500\n",
      "1411/1411 [==============================] - 0s 241us/sample - loss: 0.7360 - output_reg_loss: 0.2815 - output_class_loss: 0.5275 - output_aux_loss: 0.4138\n",
      "Epoch 415/500\n",
      "1411/1411 [==============================] - 0s 243us/sample - loss: 0.7207 - output_reg_loss: 0.2762 - output_class_loss: 0.5137 - output_aux_loss: 0.4122\n",
      "Epoch 416/500\n",
      "1411/1411 [==============================] - 0s 247us/sample - loss: 0.7151 - output_reg_loss: 0.2546 - output_class_loss: 0.5275 - output_aux_loss: 0.4139\n",
      "Epoch 417/500\n",
      "1411/1411 [==============================] - 0s 248us/sample - loss: 0.7383 - output_reg_loss: 0.2804 - output_class_loss: 0.5275 - output_aux_loss: 0.4132\n",
      "Epoch 418/500\n",
      "1411/1411 [==============================] - 0s 242us/sample - loss: 0.7280 - output_reg_loss: 0.6791 - output_class_loss: 0.5275 - output_aux_loss: 0.4257\n",
      "Epoch 419/500\n",
      "1411/1411 [==============================] - 0s 243us/sample - loss: 0.7255 - output_reg_loss: 0.4423 - output_class_loss: 0.5275 - output_aux_loss: 0.4252\n",
      "Epoch 420/500\n",
      "1411/1411 [==============================] - 0s 245us/sample - loss: 0.7362 - output_reg_loss: 0.5196 - output_class_loss: 0.5275 - output_aux_loss: 0.4270\n",
      "Epoch 421/500\n",
      "1411/1411 [==============================] - 0s 248us/sample - loss: 0.7351 - output_reg_loss: 0.6735 - output_class_loss: 0.5137 - output_aux_loss: 0.4126\n",
      "Epoch 422/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7365 - output_reg_loss: 0.3815 - output_class_loss: 0.5137 - output_aux_loss: 0.4131\n",
      "Epoch 423/500\n",
      "1411/1411 [==============================] - 0s 230us/sample - loss: 0.7458 - output_reg_loss: 0.6886 - output_class_loss: 0.5137 - output_aux_loss: 0.4139\n",
      "Epoch 424/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7164 - output_reg_loss: 0.4288 - output_class_loss: 0.5137 - output_aux_loss: 0.4123\n",
      "Epoch 425/500\n",
      "1411/1411 [==============================] - 0s 226us/sample - loss: 0.7251 - output_reg_loss: 0.2623 - output_class_loss: 0.5275 - output_aux_loss: 0.4131\n",
      "Epoch 426/500\n",
      "1411/1411 [==============================] - 0s 227us/sample - loss: 0.7148 - output_reg_loss: 0.2983 - output_class_loss: 0.5137 - output_aux_loss: 0.4121\n",
      "Epoch 427/500\n",
      "1411/1411 [==============================] - 0s 228us/sample - loss: 0.7442 - output_reg_loss: 0.5792 - output_class_loss: 0.5137 - output_aux_loss: 0.4132\n",
      "Epoch 428/500\n",
      "1411/1411 [==============================] - 0s 231us/sample - loss: 0.7123 - output_reg_loss: 0.2987 - output_class_loss: 0.5275 - output_aux_loss: 0.4129\n",
      "Epoch 429/500\n",
      "1411/1411 [==============================] - 0s 241us/sample - loss: 0.7249 - output_reg_loss: 0.3950 - output_class_loss: 0.5137 - output_aux_loss: 0.4111\n",
      "Epoch 430/500\n",
      "1411/1411 [==============================] - 0s 245us/sample - loss: 0.7464 - output_reg_loss: 0.4958 - output_class_loss: 0.5413 - output_aux_loss: 0.4290\n",
      "Epoch 431/500\n",
      "1411/1411 [==============================] - 0s 240us/sample - loss: 0.7080 - output_reg_loss: 0.2371 - output_class_loss: 0.5137 - output_aux_loss: 0.4122\n",
      "Epoch 432/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7337 - output_reg_loss: 0.3610 - output_class_loss: 0.5275 - output_aux_loss: 0.4221\n",
      "Epoch 433/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7368 - output_reg_loss: 0.5865 - output_class_loss: 0.5137 - output_aux_loss: 0.4132\n",
      "Epoch 434/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7336 - output_reg_loss: 0.4870 - output_class_loss: 0.5137 - output_aux_loss: 0.4125\n",
      "Epoch 435/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7332 - output_reg_loss: 0.4443 - output_class_loss: 0.5137 - output_aux_loss: 0.4138\n",
      "Epoch 436/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7172 - output_reg_loss: 0.4459 - output_class_loss: 0.5137 - output_aux_loss: 0.4122\n",
      "Epoch 437/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7265 - output_reg_loss: 0.2668 - output_class_loss: 0.5275 - output_aux_loss: 0.4131\n",
      "Epoch 438/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7195 - output_reg_loss: 0.5385 - output_class_loss: 0.5275 - output_aux_loss: 0.4252\n",
      "Epoch 439/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7077 - output_reg_loss: 0.3328 - output_class_loss: 0.5275 - output_aux_loss: 0.4122\n",
      "Epoch 440/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7054 - output_reg_loss: 0.2277 - output_class_loss: 0.5275 - output_aux_loss: 0.4125\n",
      "Epoch 441/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7158 - output_reg_loss: 0.3600 - output_class_loss: 0.5275 - output_aux_loss: 0.4126\n",
      "Epoch 442/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7373 - output_reg_loss: 0.5541 - output_class_loss: 0.5137 - output_aux_loss: 0.4134\n",
      "Epoch 443/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7145 - output_reg_loss: 0.3761 - output_class_loss: 0.5137 - output_aux_loss: 0.4119\n",
      "Epoch 444/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7149 - output_reg_loss: 0.5707 - output_class_loss: 0.5137 - output_aux_loss: 0.4118\n",
      "Epoch 445/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7154 - output_reg_loss: 0.5062 - output_class_loss: 0.5137 - output_aux_loss: 0.4122\n",
      "Epoch 446/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7384 - output_reg_loss: 0.5219 - output_class_loss: 0.5413 - output_aux_loss: 0.4268\n",
      "Epoch 447/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7509 - output_reg_loss: 0.3595 - output_class_loss: 0.5137 - output_aux_loss: 0.4135\n",
      "Epoch 448/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7309 - output_reg_loss: 0.2832 - output_class_loss: 0.5137 - output_aux_loss: 0.4124\n",
      "Epoch 449/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7154 - output_reg_loss: 0.4994 - output_class_loss: 0.5137 - output_aux_loss: 0.4121\n",
      "Epoch 450/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7244 - output_reg_loss: 0.3696 - output_class_loss: 0.5275 - output_aux_loss: 0.4178\n",
      "Epoch 451/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7167 - output_reg_loss: 0.2660 - output_class_loss: 0.5275 - output_aux_loss: 0.4140\n",
      "Epoch 452/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7215 - output_reg_loss: 0.3531 - output_class_loss: 0.5137 - output_aux_loss: 0.4135\n",
      "Epoch 453/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7129 - output_reg_loss: 0.2556 - output_class_loss: 0.5275 - output_aux_loss: 0.4147\n",
      "Epoch 454/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7184 - output_reg_loss: 0.3502 - output_class_loss: 0.5275 - output_aux_loss: 0.4133\n",
      "Epoch 455/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7427 - output_reg_loss: 0.2868 - output_class_loss: 0.5275 - output_aux_loss: 0.4127\n",
      "Epoch 456/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7148 - output_reg_loss: 0.2506 - output_class_loss: 0.5275 - output_aux_loss: 0.4130\n",
      "Epoch 457/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7427 - output_reg_loss: 0.4244 - output_class_loss: 0.5137 - output_aux_loss: 0.4140\n",
      "Epoch 458/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7261 - output_reg_loss: 0.4467 - output_class_loss: 0.5275 - output_aux_loss: 0.4250\n",
      "Epoch 459/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7250 - output_reg_loss: 0.4115 - output_class_loss: 0.5137 - output_aux_loss: 0.4083\n",
      "Epoch 460/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7316 - output_reg_loss: 0.3684 - output_class_loss: 0.5275 - output_aux_loss: 0.4199\n",
      "Epoch 461/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7292 - output_reg_loss: 0.4046 - output_class_loss: 0.5137 - output_aux_loss: 0.4114\n",
      "Epoch 462/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7380 - output_reg_loss: 0.3930 - output_class_loss: 0.5137 - output_aux_loss: 0.4119\n",
      "Epoch 463/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7028 - output_reg_loss: 0.2456 - output_class_loss: 0.5275 - output_aux_loss: 0.4130\n",
      "Epoch 464/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7172 - output_reg_loss: 0.3026 - output_class_loss: 0.5275 - output_aux_loss: 0.4122\n",
      "Epoch 465/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7214 - output_reg_loss: 0.2696 - output_class_loss: 0.5275 - output_aux_loss: 0.4129\n",
      "Epoch 466/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7391 - output_reg_loss: 0.4344 - output_class_loss: 0.5137 - output_aux_loss: 0.4126\n",
      "Epoch 467/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7244 - output_reg_loss: 0.3399 - output_class_loss: 0.5137 - output_aux_loss: 0.4118\n",
      "Epoch 468/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7246 - output_reg_loss: 0.2687 - output_class_loss: 0.5275 - output_aux_loss: 0.4129\n",
      "Epoch 469/500\n",
      "1411/1411 [==============================] - 0s 232us/sample - loss: 0.7082 - output_reg_loss: 0.5372 - output_class_loss: 0.5137 - output_aux_loss: 0.4118\n",
      "Epoch 470/500\n",
      "1411/1411 [==============================] - 0s 231us/sample - loss: 0.7104 - output_reg_loss: 0.2934 - output_class_loss: 0.5137 - output_aux_loss: 0.4122\n",
      "Epoch 471/500\n",
      "1411/1411 [==============================] - 0s 232us/sample - loss: 0.7263 - output_reg_loss: 0.3915 - output_class_loss: 0.5137 - output_aux_loss: 0.4079\n",
      "Epoch 472/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7409 - output_reg_loss: 0.3686 - output_class_loss: 0.5137 - output_aux_loss: 0.4154\n",
      "Epoch 473/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7191 - output_reg_loss: 0.4118 - output_class_loss: 0.5137 - output_aux_loss: 0.4121\n",
      "Epoch 474/500\n",
      "1411/1411 [==============================] - 0s 238us/sample - loss: 0.7125 - output_reg_loss: 0.2386 - output_class_loss: 0.5275 - output_aux_loss: 0.4132\n",
      "Epoch 475/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7522 - output_reg_loss: 0.7374 - output_class_loss: 0.5275 - output_aux_loss: 0.4269\n",
      "Epoch 476/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7315 - output_reg_loss: 0.5150 - output_class_loss: 0.5137 - output_aux_loss: 0.4117\n",
      "Epoch 477/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7192 - output_reg_loss: 0.5144 - output_class_loss: 0.5137 - output_aux_loss: 0.4121\n",
      "Epoch 478/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7178 - output_reg_loss: 0.5403 - output_class_loss: 0.5137 - output_aux_loss: 0.4120\n",
      "Epoch 479/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7452 - output_reg_loss: 0.2897 - output_class_loss: 0.5275 - output_aux_loss: 0.4128\n",
      "Epoch 480/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7255 - output_reg_loss: 0.2746 - output_class_loss: 0.5137 - output_aux_loss: 0.4113\n",
      "Epoch 481/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7254 - output_reg_loss: 0.4670 - output_class_loss: 0.5137 - output_aux_loss: 0.4135\n",
      "Epoch 482/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7322 - output_reg_loss: 0.6602 - output_class_loss: 0.5275 - output_aux_loss: 0.4213\n",
      "Epoch 483/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7173 - output_reg_loss: 0.3481 - output_class_loss: 0.5137 - output_aux_loss: 0.4085\n",
      "Epoch 484/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7446 - output_reg_loss: 0.3258 - output_class_loss: 0.5275 - output_aux_loss: 0.4147\n",
      "Epoch 485/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7205 - output_reg_loss: 0.5366 - output_class_loss: 0.5137 - output_aux_loss: 0.4118\n",
      "Epoch 486/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7365 - output_reg_loss: 0.4483 - output_class_loss: 0.5137 - output_aux_loss: 0.4094\n",
      "Epoch 487/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7280 - output_reg_loss: 0.5247 - output_class_loss: 0.5137 - output_aux_loss: 0.4079\n",
      "Epoch 488/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7231 - output_reg_loss: 0.3006 - output_class_loss: 0.5137 - output_aux_loss: 0.4133\n",
      "Epoch 489/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7336 - output_reg_loss: 0.4462 - output_class_loss: 0.5137 - output_aux_loss: 0.4134\n",
      "Epoch 490/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7086 - output_reg_loss: 0.2399 - output_class_loss: 0.5275 - output_aux_loss: 0.4132\n",
      "Epoch 491/500\n",
      "1411/1411 [==============================] - 0s 233us/sample - loss: 0.7415 - output_reg_loss: 0.3322 - output_class_loss: 0.5137 - output_aux_loss: 0.4082\n",
      "Epoch 492/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7222 - output_reg_loss: 0.2935 - output_class_loss: 0.5275 - output_aux_loss: 0.4137\n",
      "Epoch 493/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7325 - output_reg_loss: 0.4610 - output_class_loss: 0.5137 - output_aux_loss: 0.4124\n",
      "Epoch 494/500\n",
      "1411/1411 [==============================] - 0s 232us/sample - loss: 0.7245 - output_reg_loss: 0.5241 - output_class_loss: 0.5137 - output_aux_loss: 0.4110\n",
      "Epoch 495/500\n",
      "1411/1411 [==============================] - 0s 239us/sample - loss: 0.7213 - output_reg_loss: 0.4541 - output_class_loss: 0.5137 - output_aux_loss: 0.4105\n",
      "Epoch 496/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7183 - output_reg_loss: 0.4458 - output_class_loss: 0.5137 - output_aux_loss: 0.4118\n",
      "Epoch 497/500\n",
      "1411/1411 [==============================] - 0s 234us/sample - loss: 0.7164 - output_reg_loss: 0.4382 - output_class_loss: 0.5137 - output_aux_loss: 0.4118\n",
      "Epoch 498/500\n",
      "1411/1411 [==============================] - 0s 235us/sample - loss: 0.7336 - output_reg_loss: 0.4179 - output_class_loss: 0.5275 - output_aux_loss: 0.4257\n",
      "Epoch 499/500\n",
      "1411/1411 [==============================] - 0s 236us/sample - loss: 0.7281 - output_reg_loss: 0.3116 - output_class_loss: 0.5275 - output_aux_loss: 0.4161\n",
      "Epoch 500/500\n",
      "1411/1411 [==============================] - 0s 237us/sample - loss: 0.7106 - output_reg_loss: 0.3845 - output_class_loss: 0.5275 - output_aux_loss: 0.4111\n"
     ]
    }
   ],
   "source": [
    "hist = wide_and_deep.fit([wide_i, deep_i], [targets[:,0], targets[:,1], targets[:,1]], batch_size=64, epochs=500, callbacks=[keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(hist.history).plot(figsize=(16,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_xlim(0, 50)\n",
    "plt.gca().set_ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
