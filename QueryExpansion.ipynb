{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from pplm_utils import *\n",
    "from transformers import AutoConfig, AutoModelWithLMHead, AutoTokenizer, BertTokenizer, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Should birth control pills be available over the counter?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using PPLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argumentation Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accept', 'according', 'accordingly', 'affirm', 'agree', 'argue', 'argument', 'argumentation', 'assert', 'assumption', 'attack', 'attest', 'backing', 'basis', 'because', 'belief', 'believe', 'bias', 'biased', 'challenge', 'cite', 'claim', 'clear', 'con', 'concede', 'conclude', 'conclusion', 'concur', 'connect', 'consequence', 'consequently', 'context', 'controversial', 'convince', 'corroborate', 'corroboration', 'credibility', 'credible', 'criteria', 'criterion', 'debatable', 'debate', 'deduction', 'definition', 'determine', 'disagree', 'discourse', 'disprove', 'ergo', 'evidence', 'example', 'facts', 'fallacy', 'fallible', 'faulty', 'figure', 'general', 'grounds', 'hence', 'honest', 'honesty', 'hypothetical', 'idea', 'imply', 'inconsistent', 'inductive', 'infer', 'irrelevant', 'justify', 'knowledge', 'logical', 'naturally', 'negotiate', 'notion', 'object', 'objective', 'objectively ', 'opinion', 'opponent', 'perspective', 'persuade', 'persuasive', 'point', 'position', 'precisely', 'premise', 'pro', 'probable', 'proof', 'proposal', 'prove', 'rational', 'reason', 'reasonable', 'reasoning', 'rebuttal', 'reiterate', 'relevant', 'rhetoric', 'rhetorical', 'right', 'rumors', 'sequitur', 'since', 'sure', 'surely', 'skeptical', 'skepticsm', 'sources', 'specific', 'stance', 'statistically', 'statistics', 'study', 'subjective ', 'suppose', 'testimonial', 'theory', 'therefore', 'thesis', 'think', 'thought', 'thus', 'trustworthy', 'unconvinced', 'undermine', 'unsubstantiated', 'vague', 'valid', 'warrant', 'wrong']\n"
     ]
    }
   ],
   "source": [
    "with open('arg_bow') as f:\n",
    "    bow = f.read().splitlines()\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3129d26745a443068e61c1c54e85306e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=224.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f3b932945ea49fabf1a778aa61dc6c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "607d7aba90a344fca1c9d9418659965b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c19858923a4f46ad1cb67680f12cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "LM_MODEL_TO_USE = \"gpt2\"\n",
    "config = AutoConfig.from_pretrained(LM_MODEL_TO_USE)\n",
    "config.output_hidden_states = True\n",
    "tokenizer = AutoTokenizer.from_pretrained(LM_MODEL_TO_USE)\n",
    "lm = AutoModelWithLMHead.from_pretrained(LM_MODEL_TO_USE, config=config)\n",
    "lm.eval()    \n",
    "for param in lm.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "query= \"Should Performance Enhancing Drugs Be Accepted in Sports?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", because they are a proven way to improve performance. They have shown that the evidence is clear and convincing: \"The only reason why I believe this study was published as an opinion piece on sports journalism would be if it were true.\" Because of their\n",
      "CPU times: user 36min 29s, sys: 37.1 s, total: 37min 6s\n",
      "Wall time: 3min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_cond_text = tokenizer.encode(\"- What do you think? \" + query + \"\\n- Yes\")\n",
    "unpert_gen_tok_text, pert_gen_tok_texts, grad_norms, loss_per_iter = full_text_generation(model=lm, tokenizer=tokenizer, context=tokenized_cond_text, bag_of_words='arg_bow',\n",
    "                                                                                          length=50, stepsize=0.03, temperature=1.1, \n",
    "                                                                                          top_k=5, num_iterations=15, num_samples=2, grad_length=1000, horizon_length=5,\n",
    "                                                                                          gm_scale=0.9, kl_scale=0.7, repetition_penalty=2, gamma=1.5,\n",
    "                                                                                          no_cuda=True, device=\"cpu\")\n",
    "print(tokenizer.decode(pert_gen_tok_texts[0][0][len(tokenized_cond_text):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". I don't know if it's because of the fact that they're not as popular, but maybe due to their popularity and so on… Maybe there is a reason why people are more interested when athletes say \"because\" or something like this:\n",
      "CPU times: user 36min 24s, sys: 35.8 s, total: 37min\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenized_cond_text = tokenizer.encode(\"- What do you think? \" + query + \"\\n- No\")\n",
    "unpert_gen_tok_text, pert_gen_tok_texts, grad_norms, loss_per_iter = full_text_generation(model=lm, tokenizer=tokenizer, context=tokenized_cond_text, bag_of_words='arg_bow',\n",
    "                                                                                          length=50, stepsize=0.03, temperature=1.1, \n",
    "                                                                                          top_k=5, num_iterations=15, num_samples=2, grad_length=1000, horizon_length=5,\n",
    "                                                                                          gm_scale=0.9, kl_scale=0.7, repetition_penalty=2, gamma=1.5,\n",
    "                                                                                          no_cuda=True, device=\"cpu\")\n",
    "print(tokenizer.decode(pert_gen_tok_texts[0][0][len(tokenized_cond_text):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". I'm not really a fan of it, but if they're going to accept this because there's no evidence that the drugs are harmful then why should we be accepting them for sports reasons as well when all athletes who have been tested on performance enhancing\n",
      "CPU times: user 36min 44s, sys: 37 s, total: 37min 21s\n",
      "Wall time: 3min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenized_cond_text = tokenizer.encode(\"- What do you think? \" + query + \"\\n- Not sure\")\n",
    "unpert_gen_tok_text, pert_gen_tok_texts, grad_norms, loss_per_iter = full_text_generation(model=lm, tokenizer=tokenizer, context=tokenized_cond_text, bag_of_words='arg_bow',\n",
    "                                                                                          length=50, stepsize=0.03, temperature=1.1, \n",
    "                                                                                          top_k=5, num_iterations=15, num_samples=2, grad_length=1000, horizon_length=5,\n",
    "                                                                                          gm_scale=0.9, kl_scale=0.7, repetition_penalty=2, gamma=1.5,\n",
    "                                                                                          no_cuda=True, device=\"cpu\")\n",
    "print(tokenizer.decode(pert_gen_tok_texts[0][0][len(tokenized_cond_text):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". But it's a good idea because if they're not accepted then there is no reason to believe that the drugs are safe and effective, so why should we accept them when people who have been wrong about these things for years now can be right again\n",
      "CPU times: user 37min 22s, sys: 39.6 s, total: 38min 1s\n",
      "Wall time: 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenized_cond_text = tokenizer.encode(\"- What do you think? \" + query + \"\\n- I don't know\")\n",
    "unpert_gen_tok_text, pert_gen_tok_texts, grad_norms, loss_per_iter = full_text_generation(model=lm, tokenizer=tokenizer, context=tokenized_cond_text, bag_of_words='arg_bow',\n",
    "                                                                                          length=50, stepsize=0.03, temperature=1.1, \n",
    "                                                                                          top_k=5, num_iterations=15, num_samples=2, grad_length=1000, horizon_length=5,\n",
    "                                                                                          gm_scale=0.9, kl_scale=0.7, repetition_penalty=2, gamma=1.5,\n",
    "                                                                                          no_cuda=True, device=\"cpu\")\n",
    "print(tokenizer.decode(pert_gen_tok_texts[0][0][len(tokenized_cond_text):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". But it's a good idea to have them, and if they're not accepted then we'll see what happens with the sport of sports medicine.\"<|endoftext|>The UESPWiki – Your source for The Elder Scrolls since 1995\n",
      "\n",
      " (click here)\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(unpert_gen_tok_text[0][len(tokenized_cond_text):]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Transformer decoders with a Language Model head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_MODEL_TO_USE = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(LM_MODEL_TO_USE)\n",
    "lm = AutoModelWithLMHead.from_pretrained(LM_MODEL_TO_USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What do you think?\"+query \n",
    "input_context_pro = [\n",
    "    \"- \"+query+\"\\n- Yes because\",\n",
    "    query+\"The answer is yes.\"\n",
    "]\n",
    "input_context_con = [\n",
    "    \"- \"+query+\"\\n- No because\",\n",
    "    query+\"The answer is no.\"\n",
    "]\n",
    "\n",
    "input_context_neutral = [\n",
    "    \"- \" + query + \"\\n- I don't know\",\n",
    "    \"- \" + query + \"\\n- Not sure\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Greedily hallucinated for query 0:\n",
      "  they are safe and effective. They can be used to treat a wide range of health conditions, including diabetes mellitus (DM), hypertension/hypercholesterolemia / type 2 diabetics (HDIs) etc., as well the most common types of cardiovascular disease like heart attack or stroke [1]. There is no evidence that performance enhancing\n",
      "\n",
      "\n",
      "Greedily hallucinated for query 1:\n",
      "  They should be accepted as a part of the sport, and they shouldn't have to compete against other athletes who are competing at higher levels than them.\"\n",
      "\"There's no question that performance enhancing drugs (PEDs) can help people improve their athletic ability,\" he said during an interview with ESPN FC on Wednesday night after his team won 2\n",
      "\n",
      "\n",
      "Greedily hallucinated for query 2:\n",
      "  I don't believe it should be accepted as a medical condition.I'm not saying that performance enhancing drugs are bad for your health, but if they're given to athletes who need them the most then there's no reason why this shouldn'a never been considered medically acceptable by sports medicine or any other professional bodybuilder/athletic group (\n",
      "\n",
      "\n",
      "Greedily hallucinated for query 3:\n",
      "  In fact, it's not even close to being accepted by the scientific community as a safe and effective treatment for chronic fatigue syndrome (CFS) or any other type of muscle wasting disease that can be caused by exercise-induced hypertrophy.[1]\n",
      "[2][3]: http://www... [4](http:...)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Greedily hallucinated for query 4:\n",
      "  if they should be accepted or not, but it's something that needs to happen. If there is a problem with performance enhancing drugs then we need more research on this topic and better understanding of how these substances work so people can make informed decisions about their use based upon what works best for them at the time. It would also help us\n",
      "\n",
      "\n",
      "Greedily hallucinated for query 5:\n",
      "  if this is a good idea or not, but I don't see any reason why it should be accepted as such.I would like to hear your thoughts on the topic of performance enhancing drugs and how they can help athletes improve their athletic ability by helping them get better at running faster than ever before!Please let me know what questions/comments are\n",
      "\n",
      "CPU times: user 8min 5s, sys: 3.11 s, total: 8min 8s\n",
      "Wall time: 41.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hallucinated_greedy = []\n",
    "\n",
    "for j, input_context in enumerate(chain(*[input_context_pro, input_context_con, input_context_neutral])):\n",
    "    input_ids = torch.tensor(tokenizer.encode(input_context)).unsqueeze(0)  \n",
    "    L = len(input_ids[0])\n",
    "    outputs = lm.generate(max_length=100, input_ids=input_ids, do_sample=False, num_beams=10, top_k=100 , top_p=0.4, num_return_sequences=1, temperature=1.6, repetition_penalty=20)\n",
    "    for i in range(1):\n",
    "        print('')\n",
    "        print(f'Greedily hallucinated for query {j}:\\n {tokenizer.decode(outputs[i][L:], skip_special_tokens=True)}')\n",
    "        print('')\n",
    "        hallucinated_greedy.append(tokenizer.decode(outputs[i][L:], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_return_sequences = 3\n",
    "input_context_pro = [\n",
    "    \"-\"+query+\"\\n- Yes because\",\n",
    "    query+\"The answer is yes.\"\n",
    "]\n",
    "input_context_con = [\n",
    "    \"-\"+query+\"\\n- No because\",\n",
    "    query+\"The answer is no.\"\n",
    "]\n",
    "\n",
    "input_context_neutral = [\n",
    "    \"- \" + query + \"\\n- I don't know\",\n",
    "    \"- \" + query + \"\\n- Not sure\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Hallucinated 1 for query 1:  the majority of people who would consider themselves athletes should not take these drugs. However, there are some good arguments that could be made against this position:1) People have developed different levels and/or body fat for their bodies;2)- It may lead to problems if one or more other factors play an important role (e.-F.)3\n",
      " \n",
      " \n",
      "Hallucinated 2 for query 1:  the benefits of performance enhancers are well known, as a treatment that has been found to be effective and cost minimal. The evidence for this statement was obtained by two separate studies: one conducted at Stanford Medical School with 1 million participants (which had an effect rate close on 2%), while another used data collected over three years from 866 athletes who\n",
      " \n",
      " \n",
      "Hallucinated 3 for query 1:  I don't want my body and its muscles to become damaged by any substances.A new research team from the Department of Public Health at Ohio State University, a public health organization that focuses on infectious diseases including HIV/AIDS is showing signs this month when it comes into contact with young people who have had hepatitis C infection while pregnant or breastfeeding their\n",
      " \n",
      " \n",
      "Hallucinated 1 for query 2:  They're a great option, but we can't wait for the next one and maybe not even get into it.\"Mitch's Guide to Getting Involved With Local Organizations\n",
      "If this sounds familiar—I know of many who have already heard about \"Get Started\" or just started with getting involved! I am often asked why so few local\n",
      " \n",
      " \n",
      "Hallucinated 2 for query 2:  We believe that athletes should be able to compete at the highest level and have fun on a consistent basis, without taking steroids or other performance enhancing medications,\" said Mike Williams-Sargent with Psicocan Pharmaceuticals Inc., who specializes only within sport medicine for his patients as well.[…]\n",
      "In 2007 Dr Richard Ritchie of University College\n",
      " \n",
      " \n",
      "Hallucinated 3 for query 2:  Athleticism will not lead to the development or maintenance of muscle mass, and we believe that there should be an evaluation at this point about whether a drug might work for some individuals but are insufficient as guidelines when it comes into sports performance enhancement programs.\"\n",
      "\n",
      "\n",
      " (source)This has become so popular on social media because athletes like Mikey have come\n",
      " \n",
      " \n",
      "Hallucinated 1 for query 3:  it isn't the best choice. But if they are accepted, what is their worth for your body?\"In a move designed to further bolster public confidence about gun violence at schools and colleges nationwide as well among students from different racial groups, The Washington Examiner will publish an online magazine featuring stories on campus shooting victims' families. On Tuesday afternoon some\n",
      " \n",
      " \n",
      "Hallucinated 2 for query 3:  the data does NOT support that notion\n",
      "\n",
      " (11:18) The Blackout on Toxics, A Reasonable Response and \"How It's Happening\" by Mark Brown : My son recently underwent an antihistamines test. He had been prescribed for two months at home after a recent incident with his father where he hit someone while drunk\n",
      " \n",
      " \n",
      "Hallucinated 3 for query 3:  it is currently being tested.An Ontario man says his wife's car broke into a police van, causing her death and then shooting at officers on the scene before crashing through their windshields while driving down Highway 5 to St John Hospital Center Monday night — killing two paramedics as she was pulled from underneath with stab wounds but not seriously injured or killed\n",
      " \n",
      " \n",
      "Hallucinated 1 for query 4:  But the idea that we shouldn't have to accept it isn´t even close...\n",
      "Posted by Brian on June 12, 2015 at 2:20 PM Posted By Robert Rennie - August 1st 2012 \"No one wants an addiction.\" What should I eat or drink and how much does this mean for my mental health if there are other\n",
      " \n",
      " \n",
      "Hallucinated 2 for query 4:  The current debate surrounding performance enhancing drugs can only go so far to say that they are illegal and the US government has failed us all by not taking their actions very seriously enough, while allowing our athletes (especially women) a chance for free speech on sports grounds with such policies as these being considered unethical.\"In my view,\" said Professor John Fus\n",
      " \n",
      " \n",
      "Hallucinated 3 for query 4:  As noted by Chris, \"If we're going to have a safe and effective sports program based on bodybuilding techniques then the best way that's been done was through physical training.\" So what should athletes be doing instead of getting their bodies pumped up with performance enhancing drugs like Perphenazine (also known as Lofothenic acid), Ac\n",
      " \n",
      "CPU times: user 14min 15s, sys: 12 s, total: 14min 27s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hallucinated_sampling = []\n",
    "\n",
    "for j, input_context in enumerate(chain(*[input_context_pro, input_context_con, input_context_neutral])):\n",
    "    input_ids = torch.tensor(tokenizer.encode(input_context)).unsqueeze(0)  # encode input context\n",
    "    L = len(input_ids[0])\n",
    "    outputs = lm.generate(max_length=100, input_ids=input_ids, do_sample=True, num_beams=10, top_k=100 , top_p=0.4, num_return_sequences=num_return_sequences, temperature=1.6, repetition_penalty=20)\n",
    "    for i in range(num_return_sequences): \n",
    "        print(\" \")\n",
    "        print(f'Hallucinated {i+1} for query {j+1}: {tokenizer.decode(outputs[i][L:], skip_special_tokens=True)}')\n",
    "        print(\" \")\n",
    "        hallucinated_sampling.append(tokenizer.decode(outputs[i][L:], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Transformer encoders with a Masked Language Model head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve a list of stopwords by computing the union of the respective stop word lists of Scikit-learn, Spacy and NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as SKLEARN_STOPWORDS\n",
    "SKLEARN_STOPWORDS = set(SKLEARN_STOPWORDS)\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as SPACY_STOPWORDS\n",
    "\n",
    "import nltk\n",
    "from ipywidgets import Output\n",
    "out = Output()\n",
    "with out:\n",
    "    nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "NLTK_STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "STOP_WORDS = set.union(*[SKLEARN_STOPWORDS, SPACY_STOPWORDS, NLTK_STOPWORDS])\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2859ed33a9f4e32b7a851b2fe9ca464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb4bd3b589640d7a96640a3fe753f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=362.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f271f76792ca4565bec405abf5515aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1344997306.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Should churches be taxed?\"\n",
    "query = \"I can't think of any arguments, can you help me? \"+ query\n",
    "\n",
    "input_context_pro = [\n",
    "    '-'+query+'\\n-Yes, because of [MASK] and the benefits of [MASK] [MASK].',\n",
    "    '-'+query+'\\n-Absolutely, I think [MASK] is good!.',\n",
    "    \"-\"+query+\"\\n-Yes, [MASK] is associated with [MASK] during [MASK].\"\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "input_context_con = [\n",
    "    '-'+query+'\\n-No, because of [MASK] and the risk of [MASK] [MASK].',\n",
    "    '-'+query+'\\n-Absolutely not, I think [MASK] is bad!.',\n",
    "    \"-\"+query+\"\\n-No, [MASK] is associated with [MASK] during [MASK].\"\n",
    "]\n",
    "\n",
    "input_context_neutral = [\n",
    "    query+' What about [MASK] or [MASK]?',\n",
    "    query+\" Don't forget about [MASK]!\"\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.6 s, sys: 890 ms, total: 36.5 s\n",
      "Wall time: 2.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hallucinations = []\n",
    "for input_context in chain(*[input_context_pro, input_context_con, input_context_neutral]):\n",
    "    inp_tens = torch.tensor(tokenizer.encode(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(input_context)))).unsqueeze(0)\n",
    "    mask_indices = np.nonzero(inp_tens.squeeze()==103).squeeze()\n",
    "    preds = model(inp_tens)[0].squeeze()\n",
    "    mask_indices = [mask_indices.tolist()] if type(mask_indices.tolist())!=list else mask_indices.tolist()\n",
    "    top_words = []\n",
    "    for i in mask_indices:\n",
    "        top_words.append(torch.topk(preds[i], k=5))\n",
    "    words = []\n",
    "    for mask_topk in top_words:\n",
    "        for token in mask_topk.indices.tolist():\n",
    "            words.append(tokenizer.decode(token, clean_up_tokenization_spaces=True))\n",
    "        #Interestingly, BERT was returning the ##carriage subword, obviously part of \"miscarriage\" in the \"pregnancy\" context. Further investigation needed to see how to return the full of word. Filtering out subwords for now.\n",
    "        #Filter out subwords\n",
    "        words = [word.replace(\" \",\"\") for word in words if not word.startswith(\"#\")]\n",
    "        words = [word for word in words if not word.endswith(\"#\")]\n",
    "        #Filter out punctuation\n",
    "        words = [word for word in words if not word in punctuation]\n",
    "    words = set(words)\n",
    "    words = list(words.difference(STOP_WORDS))\n",
    "    hallucinations.extend(words)\n",
    "hallucinations = set(hallucinations)\n",
    "hallucinations = list(hallucinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['religion',\n",
       " 'poverty',\n",
       " 'attendance',\n",
       " 'public',\n",
       " 'economics',\n",
       " 'land',\n",
       " 'money',\n",
       " 'prayer',\n",
       " 'death',\n",
       " 'church',\n",
       " 'consumption',\n",
       " 'easter',\n",
       " 'good',\n",
       " 'free',\n",
       " 'tax',\n",
       " 'lent',\n",
       " 'churches',\n",
       " 'property',\n",
       " 'costs',\n",
       " 'mass',\n",
       " 'education',\n",
       " 'exposure',\n",
       " 'financial',\n",
       " 'christmas',\n",
       " 'schools',\n",
       " 'festivals',\n",
       " 'work',\n",
       " 'women',\n",
       " 'taxes',\n",
       " 'religious',\n",
       " 'unemployment',\n",
       " 'bankruptcy',\n",
       " 'legal',\n",
       " 'services']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['religion',\n",
       " 'poverty',\n",
       " 'faith',\n",
       " 'land',\n",
       " 'money',\n",
       " 'prayer',\n",
       " 'death',\n",
       " 'cost',\n",
       " 'church',\n",
       " 'conversion',\n",
       " 'worship',\n",
       " 'free',\n",
       " 'tax',\n",
       " 'lent',\n",
       " 'legal',\n",
       " 'collapse',\n",
       " 'churches',\n",
       " 'property',\n",
       " 'costs',\n",
       " 'mass',\n",
       " 'wartime',\n",
       " 'housing',\n",
       " 'living',\n",
       " 'education',\n",
       " 'financial',\n",
       " 'christmas',\n",
       " 'schools',\n",
       " 'tourism',\n",
       " 'festivals',\n",
       " 'taxes',\n",
       " 'religious',\n",
       " 'attendance',\n",
       " 'corruption',\n",
       " 'services']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Should the Federal Minimum Wage Be Increased?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inflation', 'labor', 'taxes', 'immigration', 'congress']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"-\"+query+\"\\n-Yes, it's not too late because of [MASK] [MASK]\"]\n",
    "hallucinations = []\n",
    "for input_context in chain(*[test]):\n",
    "    inp_tens = torch.tensor(tokenizer.encode(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(input_context)))).unsqueeze(0)\n",
    "    mask_indices = np.nonzero(inp_tens.squeeze()==103).squeeze()\n",
    "    preds = model(inp_tens)[0].squeeze()\n",
    "    mask_indices = [mask_indices.tolist()] if type(mask_indices.tolist())!=list else mask_indices.tolist()\n",
    "    top_words = []\n",
    "    for i in mask_indices:\n",
    "        top_words.append(torch.topk(preds[i], k=10))\n",
    "    words = []\n",
    "    for mask_topk in top_words:\n",
    "        for token in mask_topk.indices.tolist():\n",
    "            words.append(tokenizer.decode(token, clean_up_tokenization_spaces=True))\n",
    "        #Interestingly, BERT was returning the ##carriage subword, obviously part of \"miscarriage\" in the \"pregnancy\" context. Further investigation needed to see how to return the full of word. Filtering out subwords for now.\n",
    "        #Filter out subwords\n",
    "        words = [word.replace(\" \",\"\") for word in words if not word.startswith(\"#\")]\n",
    "        words = [word for word in words if not word.endswith(\"#\")]\n",
    "        #Filter out punctuation\n",
    "        words = [word for word in words if not word in [*punctuation, \"...\"]]\n",
    "    words = set(words)\n",
    "    words = list(words.difference(STOP_WORDS))\n",
    "    hallucinations.extend(words)\n",
    "hallucinations = set(hallucinations)\n",
    "hallucinations = list(hallucinations)\n",
    "hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wars',\n",
       " 'pollution',\n",
       " 'death',\n",
       " 'consumption',\n",
       " 'climate',\n",
       " 'risk',\n",
       " 'water',\n",
       " 'development',\n",
       " 'warming',\n",
       " 'growth',\n",
       " 'summer',\n",
       " 'energy',\n",
       " 'emissions',\n",
       " 'migration',\n",
       " 'winter',\n",
       " 'construction',\n",
       " 'health',\n",
       " 'deaths',\n",
       " 'drought',\n",
       " 'mortality',\n",
       " 'pregnancy',\n",
       " 'wartime']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abortion',\n",
       " 'drugs',\n",
       " 'condoms',\n",
       " 'alcohol',\n",
       " 'pills',\n",
       " 'babies',\n",
       " 'children',\n",
       " 'men',\n",
       " 'women',\n",
       " 'money',\n",
       " 'kids',\n",
       " 'sex',\n",
       " 'insurance']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_context = \"-\"+query+\"\\n-But what about [MASK]?\"\n",
    "inp_tens = torch.tensor(tokenizer.encode(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(input_context)))).unsqueeze(0)\n",
    "mask_indices = np.nonzero(inp_tens.squeeze()==103).squeeze()\n",
    "preds = model(inp_tens)[0].squeeze()\n",
    "mask_indices = [mask_indices.tolist()] if type(mask_indices.tolist())!=list else mask_indices.tolist()\n",
    "top_words = []\n",
    "for i in mask_indices:\n",
    "    top_words.append(torch.topk(preds[i], k=20))\n",
    "words = []\n",
    "tokens = []\n",
    "for mask_topk in top_words:\n",
    "    for token in mask_topk.indices.tolist():\n",
    "        tokens.append(token)\n",
    "        words.append(tokenizer.decode(token, clean_up_tokenization_spaces=True))\n",
    "    words = [word.replace(\" \",\"\") for word in words if not word.startswith(\"#\")]\n",
    "words = set(words)\n",
    "words = list(words.difference(STOP_WORDS))\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doctor',\n",
       " 'condoms',\n",
       " 'pills',\n",
       " 'prescription',\n",
       " 'pill',\n",
       " 'medication',\n",
       " 'baby',\n",
       " 'stuff',\n",
       " 'condom',\n",
       " 'sex',\n",
       " 'medicine']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_context = \"-\"+query+\"\\n-Don't forget about [MASK] [MASK].\"\n",
    "inp_tens = torch.tensor(tokenizer.encode(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(input_context)))).unsqueeze(0)\n",
    "mask_indices = np.nonzero(inp_tens.squeeze()==103).squeeze()\n",
    "preds = model(inp_tens)[0].squeeze()\n",
    "mask_indices = [mask_indices.tolist()] if type(mask_indices.tolist())!=list else mask_indices.tolist()\n",
    "top_words = []\n",
    "for i in mask_indices:\n",
    "    top_words.append(torch.topk(preds[i], k=10))\n",
    "words = []\n",
    "tokens = []\n",
    "for mask_topk in top_words:\n",
    "    for token in mask_topk.indices.tolist():\n",
    "        tokens.append(token)\n",
    "        words.append(tokenizer.decode(token, clean_up_tokenization_spaces=True))\n",
    "    words = [word.replace(\" \",\"\") for word in words if not word.startswith(\"#\")]\n",
    "words = set(words)\n",
    "words = list(words.difference(STOP_WORDS))\n",
    "words =[word for word in words if len(word)>1]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abortion', 'drugs', 'condoms', 'pills', 'babies', 'prostitution', 'sex']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_context = query+\"I don't believe in [MASK].\"\n",
    "inp_tens = torch.tensor(tokenizer.encode(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(input_context)))).unsqueeze(0)\n",
    "mask_indices = np.nonzero(inp_tens.squeeze()==103).squeeze()\n",
    "preds = model(inp_tens)[0].squeeze()\n",
    "mask_indices = [mask_indices.tolist()] if type(mask_indices.tolist())!=list else mask_indices.tolist()\n",
    "top_words = []\n",
    "for i in mask_indices:\n",
    "    top_words.append(torch.topk(preds[i], k=10))\n",
    "words = []\n",
    "tokens = []\n",
    "for mask_topk in top_words:\n",
    "    for token in mask_topk.indices.tolist():\n",
    "        tokens.append(token)\n",
    "        words.append(tokenizer.decode(token, clean_up_tokenization_spaces=True))\n",
    "    words = [word.replace(\" \",\"\") for word in words if not word.startswith(\"#\")]\n",
    "words = set(words)\n",
    "words = list(words.difference(STOP_WORDS))\n",
    "words =[word for word in words if len(word)>1]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string.pu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
