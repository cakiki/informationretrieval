{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from pplm_utils import *\n",
    "from transformers import AutoConfig, AutoModelWithLMHead, AutoTokenizer, BertTokenizer, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Should birth control pills be available over the counter?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using PPLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argumentation Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accept', 'according', 'accordingly', 'affirm', 'agree', 'argue', 'argument', 'argumentation', 'assert', 'assumption', 'attack', 'attest', 'backing', 'basis', 'because', 'belief', 'believe', 'bias', 'biased', 'challenge', 'cite', 'claim', 'clear', 'con', 'concede', 'conclude', 'conclusion', 'concur', 'connect', 'consequence', 'consequently', 'context', 'controversial', 'convince', 'corroborate', 'corroboration', 'credibility', 'credible', 'criteria', 'criterion', 'debatable', 'debate', 'deduction', 'definition', 'determine', 'disagree', 'discourse', 'disprove', 'ergo', 'evidence', 'example', 'facts', 'fallacy', 'fallible', 'faulty', 'figure', 'general', 'grounds', 'hence', 'honest', 'honesty', 'hypothetical', 'idea', 'imply', 'inconsistent', 'inductive', 'infer', 'irrelevant', 'justify', 'knowledge', 'logical', 'naturally', 'negotiate', 'notion', 'object', 'objective', 'objectively ', 'opinion', 'opponent', 'perspective', 'persuade', 'persuasive', 'point', 'position', 'precisely', 'premise', 'pro', 'probable', 'proof', 'proposal', 'prove', 'rational', 'reason', 'reasonable', 'reasoning', 'rebuttal', 'reiterate', 'relevant', 'rhetoric', 'rhetorical', 'right', 'rumors', 'sequitur', 'since', 'sure', 'surely', 'skeptical', 'skepticsm', 'sources', 'specific', 'stance', 'statistically', 'statistics', 'study', 'subjective ', 'suppose', 'testimonial', 'theory', 'therefore', 'thesis', 'think', 'thought', 'thus', 'trustworthy', 'unconvinced', 'undermine', 'unsubstantiated', 'vague', 'valid', 'warrant', 'wrong']\n"
     ]
    }
   ],
   "source": [
    "with open('arg_bow') as f:\n",
    "    bow = f.read().splitlines()\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3129d26745a443068e61c1c54e85306e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=224.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f3b932945ea49fabf1a778aa61dc6c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "607d7aba90a344fca1c9d9418659965b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c19858923a4f46ad1cb67680f12cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "LM_MODEL_TO_USE = \"gpt2\"\n",
    "config = AutoConfig.from_pretrained(LM_MODEL_TO_USE)\n",
    "config.output_hidden_states = True\n",
    "tokenizer = AutoTokenizer.from_pretrained(LM_MODEL_TO_USE)\n",
    "lm = AutoModelWithLMHead.from_pretrained(LM_MODEL_TO_USE, config=config)\n",
    "lm.eval()    \n",
    "for param in lm.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "query= \"Should Performance Enhancing Drugs Be Accepted in Sports?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", because they are a proven way to improve performance. They have shown that the evidence is clear and convincing: \"The only reason why I believe this study was published as an opinion piece on sports journalism would be if it were true.\" Because of their\n",
      "CPU times: user 36min 29s, sys: 37.1 s, total: 37min 6s\n",
      "Wall time: 3min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_cond_text = tokenizer.encode(\"- What do you think? \" + query + \"\\n- Yes\")\n",
    "unpert_gen_tok_text, pert_gen_tok_texts, grad_norms, loss_per_iter = full_text_generation(model=lm, tokenizer=tokenizer, context=tokenized_cond_text, bag_of_words='arg_bow',\n",
    "                                                                                          length=50, stepsize=0.03, temperature=1.1, \n",
    "                                                                                          top_k=5, num_iterations=15, num_samples=2, grad_length=1000, horizon_length=5,\n",
    "                                                                                          gm_scale=0.9, kl_scale=0.7, repetition_penalty=2, gamma=1.5,\n",
    "                                                                                          no_cuda=True, device=\"cpu\")\n",
    "print(tokenizer.decode(pert_gen_tok_texts[0][0][len(tokenized_cond_text):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". I don't know if it's because of the fact that they're not as popular, but maybe due to their popularity and so on… Maybe there is a reason why people are more interested when athletes say \"because\" or something like this:\n",
      "CPU times: user 36min 24s, sys: 35.8 s, total: 37min\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenized_cond_text = tokenizer.encode(\"- What do you think? \" + query + \"\\n- No\")\n",
    "unpert_gen_tok_text, pert_gen_tok_texts, grad_norms, loss_per_iter = full_text_generation(model=lm, tokenizer=tokenizer, context=tokenized_cond_text, bag_of_words='arg_bow',\n",
    "                                                                                          length=50, stepsize=0.03, temperature=1.1, \n",
    "                                                                                          top_k=5, num_iterations=15, num_samples=2, grad_length=1000, horizon_length=5,\n",
    "                                                                                          gm_scale=0.9, kl_scale=0.7, repetition_penalty=2, gamma=1.5,\n",
    "                                                                                          no_cuda=True, device=\"cpu\")\n",
    "print(tokenizer.decode(pert_gen_tok_texts[0][0][len(tokenized_cond_text):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". I'm not really a fan of it, but if they're going to accept this because there's no evidence that the drugs are harmful then why should we be accepting them for sports reasons as well when all athletes who have been tested on performance enhancing\n",
      "CPU times: user 36min 44s, sys: 37 s, total: 37min 21s\n",
      "Wall time: 3min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenized_cond_text = tokenizer.encode(\"- What do you think? \" + query + \"\\n- Not sure\")\n",
    "unpert_gen_tok_text, pert_gen_tok_texts, grad_norms, loss_per_iter = full_text_generation(model=lm, tokenizer=tokenizer, context=tokenized_cond_text, bag_of_words='arg_bow',\n",
    "                                                                                          length=50, stepsize=0.03, temperature=1.1, \n",
    "                                                                                          top_k=5, num_iterations=15, num_samples=2, grad_length=1000, horizon_length=5,\n",
    "                                                                                          gm_scale=0.9, kl_scale=0.7, repetition_penalty=2, gamma=1.5,\n",
    "                                                                                          no_cuda=True, device=\"cpu\")\n",
    "print(tokenizer.decode(pert_gen_tok_texts[0][0][len(tokenized_cond_text):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". But it's a good idea because if they're not accepted then there is no reason to believe that the drugs are safe and effective, so why should we accept them when people who have been wrong about these things for years now can be right again\n",
      "CPU times: user 37min 22s, sys: 39.6 s, total: 38min 1s\n",
      "Wall time: 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenized_cond_text = tokenizer.encode(\"- What do you think? \" + query + \"\\n- I don't know\")\n",
    "unpert_gen_tok_text, pert_gen_tok_texts, grad_norms, loss_per_iter = full_text_generation(model=lm, tokenizer=tokenizer, context=tokenized_cond_text, bag_of_words='arg_bow',\n",
    "                                                                                          length=50, stepsize=0.03, temperature=1.1, \n",
    "                                                                                          top_k=5, num_iterations=15, num_samples=2, grad_length=1000, horizon_length=5,\n",
    "                                                                                          gm_scale=0.9, kl_scale=0.7, repetition_penalty=2, gamma=1.5,\n",
    "                                                                                          no_cuda=True, device=\"cpu\")\n",
    "print(tokenizer.decode(pert_gen_tok_texts[0][0][len(tokenized_cond_text):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". But it's a good idea to have them, and if they're not accepted then we'll see what happens with the sport of sports medicine.\"<|endoftext|>The UESPWiki – Your source for The Elder Scrolls since 1995\n",
      "\n",
      " (click here)\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(unpert_gen_tok_text[0][len(tokenized_cond_text):]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Transformer decoders with a Language Model head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_MODEL_TO_USE = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(LM_MODEL_TO_USE)\n",
    "lm = AutoModelWithLMHead.from_pretrained(LM_MODEL_TO_USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_return_sequences = 5\n",
    "query = \"What do you think?\"+query \n",
    "input_context_pro = [\n",
    "    \"-\"+query+\"\\n- Yes because\",\n",
    "    query+\"The answer is yes.\"\n",
    "]\n",
    "input_context_con = [\n",
    "    \"-\"+query+\"\\n- No because\",\n",
    "    query+\"The answer is no.\"\n",
    "]\n",
    "\n",
    "input_context_neutral = [\n",
    "    \"- What do you think? \" + query + \"\\n- I don't know\",\n",
    "    \"- What do you think? \" + query + \"\\n- Not sure\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hallucinated:  they are safe and effective. However, there is no scientific evidence to support their use as an alternative method of contraception for women who don't want or need them (e:g., those with premenstrual syndrome). There has been some debate about whether such a pill would have any effect on pregnancy outcomes in this population; however research suggests that it may reduce risk factors associated at least partially by inhibiting ovulation during\n",
      "\n",
      "\n",
      "Hallucinated:  According to a new study published in The American Journal of Obstetrics and Gynecology, more than one-third (35%) women who have had an abortion are still using them at some point during pregnancy because they don't want to miss out on their chance for health insurance coverage if it's not covered by Medicaid or other government programs such as Social Security Disability Insurance.\"If you're pregnant with your first child,\" says\n",
      "\n",
      "\n",
      "Hallucinated:  there is no evidence that they are safe or effective in preventing pregnancy. However, some studies have shown a link between use of these drugs and increased risk for breast cancer among women who take them at least once per week during their first trimester (1⇓–3). It should also not come as too much surprise to learn from this study how little research has been done on hormonal contraception since it was approved by US\n",
      "\n",
      "\n",
      "Hallucinated:  According to a new study published in The American Journal of Obstetrics and Gynecology, more than half (48 percent) women who have had an abortion at some point during pregnancy don't know they are pregnant until after their last menstrual period—a time when there's little or nothing left for them before ovulation begins.\"This means that if you're planning on having your first child within six months from conception,\" says\n",
      "\n",
      "CPU times: user 6min 42s, sys: 2.98 s, total: 6min 45s\n",
      "Wall time: 34.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hallucinated_greedy = []\n",
    "\n",
    "for j, input_context in enumerate(chain(*[input_context_pro, input_context_con])):\n",
    "    input_ids = torch.tensor(tokenizer.encode(input_context)).unsqueeze(0)  \n",
    "    L = len(input_ids[0])\n",
    "    outputs = lm.generate(max_length=100, input_ids=input_ids, do_sample=False, num_beams=10, top_k=100 , top_p=0.4, num_return_sequences=1, temperature=1.6, repetition_penalty=20)\n",
    "    for i in range(1):\n",
    "        print('')\n",
    "        print(f'Greedily hallucinated for query {j}: {tokenizer.decode(outputs[i][L:], skip_special_tokens=True)}')\n",
    "        print('')\n",
    "        hallucinated_greedy.append(tokenizer.decode(outputs[i][L:], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_return_sequences = 5\n",
    "input_context_pro = [\n",
    "    \"-\"+query+\"\\n- Yes because\",\n",
    "    query+\"The answer is yes.\"\n",
    "]\n",
    "input_context_con = [\n",
    "    \"-\"+query+\"\\n- No because\",\n",
    "    query+\"The answer is no.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Hallucinated 1 for query 1:  they're an option, I have been in a relationship for years and still feel that way about them but this doesn't mean anything without some kind (but\n",
      " \n",
      " \n",
      "Hallucinated 2 for query 1:  they are very easy, if not impossible... You will have plenty at home and in your office so we don't need any problems with women going out into\n",
      " \n",
      " \n",
      "Hallucinated 3 for query 1:  it can cause infertility, and I've had some doctors say no but they'd prefer for a small dose on its own anyway so that we could keep an\n",
      " \n",
      " \n",
      "Hallucinated 4 for query 1:  they are so popular and I want my children with no side effects at all! They work great in pregnancy, it helps your baby's brain cells become stronger\n",
      " \n",
      " \n",
      "Hallucinated 5 for query 1:  they work so well for my breasts that I just can't go anywhere without one on and off every day - this is why people have tried them (they\n",
      " \n",
      " \n",
      "Hallucinated 1 for query 2:  The only way I can get a contraceptive in that amount and not have one thrown at my door would definitely take up space, so there are no reasons for\n",
      " \n",
      " \n",
      "Hallucinated 2 for query 2:  Birth Control can make your body better, reduce side effects and increase sex drive in women who want it more than those without.\"\n",
      "\n",
      "\n",
      "\"You're talking\n",
      " \n",
      " \n",
      "Hallucinated 3 for query 2:  The pill that we are discussing here could easily make your life more manageable with some form, and not require prescription medications for pregnancy or childbirth.\"This can work\n",
      " \n",
      " \n",
      "Hallucinated 4 for query 2:  The reason we have been discussing these options for a long time was that they didn't provide women with enough information on their own health or safety when choosing whether\n",
      " \n",
      " \n",
      "Hallucinated 5 for query 2: \n",
      "It depends on your age, health condition and level:On Monday night at a Republican rally in Cleveland for his party's 2016 nominee Hillary Clinton he\n",
      " \n",
      " \n",
      "Hallucinated 1 for query 3:  they can cause hormonal problems that would not work on women who are using them as well, or for those with low libido (like men) and want\n",
      " \n",
      " \n",
      "Hallucinated 2 for query 3:  there's a lack on women who don't need them, but I'll take your argument seriously when my time comes and let ya know that is not true\n",
      " \n",
      " \n",
      "Hallucinated 3 for query 3:  I don't know what's better than not being told that if my husband is having unprotected sex with a non condom, it won (that we have an\n",
      " \n",
      " \n",
      "Hallucinated 4 for query 3:  it can cause a lot, and even if there are many things I want (and what is wrong with my baby) in moderation...but as long As\n",
      " \n",
      " \n",
      "Hallucinated 5 for query 3:  it is a medication used for treating some kind or other health condition, and not as prescribed in general medical practices like chiropractic services where there's no\n",
      " \n",
      " \n",
      "Hallucinated 1 for query 4:  As long as women are being offered contraceptive methods in general and not just those they have already given their consent, I can't support a change because there's\n",
      " \n",
      " \n",
      "Hallucinated 2 for query 4:  Birth Control pill use should never have a higher than 6% chance that your baby's going in with diabetes or cancer.\"\n",
      "If I was on this list\n",
      " \n",
      " \n",
      "Hallucinated 3 for query 4:  No, because in a healthy environment people don't become infected with this disease if their family member isn\"s right and he knows they have health problems,\"\n",
      " \n",
      " \n",
      "Hallucinated 4 for query 4:  But we need more evidence and a public debate about what constitutes safe use, whether they should or shouldn't exist,\" he said in his blog post.\"There\n",
      " \n",
      " \n",
      "Hallucinated 5 for query 4:  But there's another argument I've heard that could explain why women get sick or die before they start menstruating because their bodies are in a better state for\n",
      " \n",
      "CPU times: user 10min 41s, sys: 6.94 s, total: 10min 48s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hallucinated_sampling = []\n",
    "\n",
    "for j, input_context in enumerate(chain(*[input_context_pro, input_context_con])):\n",
    "    input_ids = torch.tensor(tokenizer.encode(input_context)).unsqueeze(0)  # encode input context\n",
    "    L = len(input_ids[0])\n",
    "    outputs = lm.generate(max_length=65, input_ids=input_ids, do_sample=True, num_beams=10, top_k=100 , top_p=0.4, num_return_sequences=num_return_sequences, temperature=1.6, repetition_penalty=20)\n",
    "    for i in range(num_return_sequences): \n",
    "        print(\" \")\n",
    "        print(f'Hallucinated {i+1} for query {j+1}: {tokenizer.decode(outputs[i][L:], skip_special_tokens=True)}')\n",
    "        print(\" \")\n",
    "        hallucinated_sampling.append(tokenizer.decode(outputs[i][L:], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   12,    40,   716,  2111,   284,   892,   286,   922,  7159,    13,\n",
       "          1680,   345,  1037,   502,    30,  1867,   466,   345,   892,    30,\n",
       "            40,   716,  2111,   284,   892,   286,   922,  7159,    13,  1680,\n",
       "           345,  1037,   502,    30,  1867,   466,   345,   892,    30,    40,\n",
       "           716,  2111,   284,   892,   286,   922,  7159,    13,  1680,   345,\n",
       "          1037,   502,    30,  1680,   345,   892,   286,   922,  7159,    30,\n",
       "         10358,  4082,  1630, 19521,   307,  1695,   625,   262,  3753,    30,\n",
       "           198,    12,  3363,   780]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.generate(input_ids=input_ids, do_sample=True, top_k=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Transformer encoders with a Masked Language Model head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve a list of stopwords by computing the union of the respective stop word lists of Scikit-learn, Spacy and NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as SKLEARN_STOPWORDS\n",
    "SKLEARN_STOPWORDS = set(SKLEARN_STOPWORDS)\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as SPACY_STOPWORDS\n",
    "\n",
    "import nltk\n",
    "from ipywidgets import Output\n",
    "out = Output()\n",
    "with out:\n",
    "    nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "NLTK_STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "STOP_WORDS = set.union(*[SKLEARN_STOPWORDS, SPACY_STOPWORDS, NLTK_STOPWORDS])\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2859ed33a9f4e32b7a851b2fe9ca464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb4bd3b589640d7a96640a3fe753f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=362.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f271f76792ca4565bec405abf5515aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1344997306.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Should churches be taxed?\"\n",
    "query = \"I can't think of any arguments, can you help me? \"+ query\n",
    "\n",
    "input_context_pro = [\n",
    "    '-'+query+'\\n-Yes, because of [MASK] and the benefits of [MASK] [MASK].',\n",
    "    '-'+query+'\\n-Absolutely, I think [MASK] is good!.',\n",
    "    \"-\"+query+\"\\n-Yes, [MASK] is associated with [MASK] during [MASK].\"\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "input_context_con = [\n",
    "    '-'+query+'\\n-No, because of [MASK] and the risk of [MASK] [MASK].',\n",
    "    '-'+query+'\\n-Absolutely not, I think [MASK] is bad!.',\n",
    "    \"-\"+query+\"\\n-No, [MASK] is associated with [MASK] during [MASK].\"\n",
    "]\n",
    "\n",
    "input_context_neutral = [\n",
    "    query+' What about [MASK] or [MASK]?',\n",
    "    query+\" Don't forget about [MASK]!\"\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.6 s, sys: 890 ms, total: 36.5 s\n",
      "Wall time: 2.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hallucinations = []\n",
    "for input_context in chain(*[input_context_pro, input_context_con, input_context_neutral]):\n",
    "    inp_tens = torch.tensor(tokenizer.encode(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(input_context)))).unsqueeze(0)\n",
    "    mask_indices = np.nonzero(inp_tens.squeeze()==103).squeeze()\n",
    "    preds = model(inp_tens)[0].squeeze()\n",
    "    mask_indices = [mask_indices.tolist()] if type(mask_indices.tolist())!=list else mask_indices.tolist()\n",
    "    top_words = []\n",
    "    for i in mask_indices:\n",
    "        top_words.append(torch.topk(preds[i], k=5))\n",
    "    words = []\n",
    "    for mask_topk in top_words:\n",
    "        for token in mask_topk.indices.tolist():\n",
    "            words.append(tokenizer.decode(token, clean_up_tokenization_spaces=True))\n",
    "        #Interestingly, BERT was returning the ##carriage subword, obviously part of \"miscarriage\" in the \"pregnancy\" context. Further investigation needed to see how to return the full of word. Filtering out subwords for now.\n",
    "        #Filter out subwords\n",
    "        words = [word.replace(\" \",\"\") for word in words if not word.startswith(\"#\")]\n",
    "        words = [word for word in words if not word.endswith(\"#\")]\n",
    "        #Filter out punctuation\n",
    "        words = [word for word in words if not word in punctuation]\n",
    "    words = set(words)\n",
    "    words = list(words.difference(STOP_WORDS))\n",
    "    hallucinations.extend(words)\n",
    "hallucinations = set(hallucinations)\n",
    "hallucinations = list(hallucinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['religion',\n",
       " 'poverty',\n",
       " 'attendance',\n",
       " 'public',\n",
       " 'economics',\n",
       " 'land',\n",
       " 'money',\n",
       " 'prayer',\n",
       " 'death',\n",
       " 'church',\n",
       " 'consumption',\n",
       " 'easter',\n",
       " 'good',\n",
       " 'free',\n",
       " 'tax',\n",
       " 'lent',\n",
       " 'churches',\n",
       " 'property',\n",
       " 'costs',\n",
       " 'mass',\n",
       " 'education',\n",
       " 'exposure',\n",
       " 'financial',\n",
       " 'christmas',\n",
       " 'schools',\n",
       " 'festivals',\n",
       " 'work',\n",
       " 'women',\n",
       " 'taxes',\n",
       " 'religious',\n",
       " 'unemployment',\n",
       " 'bankruptcy',\n",
       " 'legal',\n",
       " 'services']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['religion',\n",
       " 'poverty',\n",
       " 'faith',\n",
       " 'land',\n",
       " 'money',\n",
       " 'prayer',\n",
       " 'death',\n",
       " 'cost',\n",
       " 'church',\n",
       " 'conversion',\n",
       " 'worship',\n",
       " 'free',\n",
       " 'tax',\n",
       " 'lent',\n",
       " 'legal',\n",
       " 'collapse',\n",
       " 'churches',\n",
       " 'property',\n",
       " 'costs',\n",
       " 'mass',\n",
       " 'wartime',\n",
       " 'housing',\n",
       " 'living',\n",
       " 'education',\n",
       " 'financial',\n",
       " 'christmas',\n",
       " 'schools',\n",
       " 'tourism',\n",
       " 'festivals',\n",
       " 'taxes',\n",
       " 'religious',\n",
       " 'attendance',\n",
       " 'corruption',\n",
       " 'services']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Should the Federal Minimum Wage Be Increased?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inflation', 'labor', 'taxes', 'immigration', 'congress']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"-\"+query+\"\\n-Yes, it's not too late because of [MASK] [MASK]\"]\n",
    "hallucinations = []\n",
    "for input_context in chain(*[test]):\n",
    "    inp_tens = torch.tensor(tokenizer.encode(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(input_context)))).unsqueeze(0)\n",
    "    mask_indices = np.nonzero(inp_tens.squeeze()==103).squeeze()\n",
    "    preds = model(inp_tens)[0].squeeze()\n",
    "    mask_indices = [mask_indices.tolist()] if type(mask_indices.tolist())!=list else mask_indices.tolist()\n",
    "    top_words = []\n",
    "    for i in mask_indices:\n",
    "        top_words.append(torch.topk(preds[i], k=10))\n",
    "    words = []\n",
    "    for mask_topk in top_words:\n",
    "        for token in mask_topk.indices.tolist():\n",
    "            words.append(tokenizer.decode(token, clean_up_tokenization_spaces=True))\n",
    "        #Interestingly, BERT was returning the ##carriage subword, obviously part of \"miscarriage\" in the \"pregnancy\" context. Further investigation needed to see how to return the full of word. Filtering out subwords for now.\n",
    "        #Filter out subwords\n",
    "        words = [word.replace(\" \",\"\") for word in words if not word.startswith(\"#\")]\n",
    "        words = [word for word in words if not word.endswith(\"#\")]\n",
    "        #Filter out punctuation\n",
    "        words = [word for word in words if not word in [*punctuation, \"...\"]]\n",
    "    words = set(words)\n",
    "    words = list(words.difference(STOP_WORDS))\n",
    "    hallucinations.extend(words)\n",
    "hallucinations = set(hallucinations)\n",
    "hallucinations = list(hallucinations)\n",
    "hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wars',\n",
       " 'pollution',\n",
       " 'death',\n",
       " 'consumption',\n",
       " 'climate',\n",
       " 'risk',\n",
       " 'water',\n",
       " 'development',\n",
       " 'warming',\n",
       " 'growth',\n",
       " 'summer',\n",
       " 'energy',\n",
       " 'emissions',\n",
       " 'migration',\n",
       " 'winter',\n",
       " 'construction',\n",
       " 'health',\n",
       " 'deaths',\n",
       " 'drought',\n",
       " 'mortality',\n",
       " 'pregnancy',\n",
       " 'wartime']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abortion',\n",
       " 'drugs',\n",
       " 'condoms',\n",
       " 'alcohol',\n",
       " 'pills',\n",
       " 'babies',\n",
       " 'children',\n",
       " 'men',\n",
       " 'women',\n",
       " 'money',\n",
       " 'kids',\n",
       " 'sex',\n",
       " 'insurance']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_context = \"-\"+query+\"\\n-But what about [MASK]?\"\n",
    "inp_tens = torch.tensor(tokenizer.encode(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(input_context)))).unsqueeze(0)\n",
    "mask_indices = np.nonzero(inp_tens.squeeze()==103).squeeze()\n",
    "preds = model(inp_tens)[0].squeeze()\n",
    "mask_indices = [mask_indices.tolist()] if type(mask_indices.tolist())!=list else mask_indices.tolist()\n",
    "top_words = []\n",
    "for i in mask_indices:\n",
    "    top_words.append(torch.topk(preds[i], k=20))\n",
    "words = []\n",
    "tokens = []\n",
    "for mask_topk in top_words:\n",
    "    for token in mask_topk.indices.tolist():\n",
    "        tokens.append(token)\n",
    "        words.append(tokenizer.decode(token, clean_up_tokenization_spaces=True))\n",
    "    words = [word.replace(\" \",\"\") for word in words if not word.startswith(\"#\")]\n",
    "words = set(words)\n",
    "words = list(words.difference(STOP_WORDS))\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doctor',\n",
       " 'condoms',\n",
       " 'pills',\n",
       " 'prescription',\n",
       " 'pill',\n",
       " 'medication',\n",
       " 'baby',\n",
       " 'stuff',\n",
       " 'condom',\n",
       " 'sex',\n",
       " 'medicine']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_context = \"-\"+query+\"\\n-Don't forget about [MASK] [MASK].\"\n",
    "inp_tens = torch.tensor(tokenizer.encode(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(input_context)))).unsqueeze(0)\n",
    "mask_indices = np.nonzero(inp_tens.squeeze()==103).squeeze()\n",
    "preds = model(inp_tens)[0].squeeze()\n",
    "mask_indices = [mask_indices.tolist()] if type(mask_indices.tolist())!=list else mask_indices.tolist()\n",
    "top_words = []\n",
    "for i in mask_indices:\n",
    "    top_words.append(torch.topk(preds[i], k=10))\n",
    "words = []\n",
    "tokens = []\n",
    "for mask_topk in top_words:\n",
    "    for token in mask_topk.indices.tolist():\n",
    "        tokens.append(token)\n",
    "        words.append(tokenizer.decode(token, clean_up_tokenization_spaces=True))\n",
    "    words = [word.replace(\" \",\"\") for word in words if not word.startswith(\"#\")]\n",
    "words = set(words)\n",
    "words = list(words.difference(STOP_WORDS))\n",
    "words =[word for word in words if len(word)>1]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abortion', 'drugs', 'condoms', 'pills', 'babies', 'prostitution', 'sex']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_context = query+\"I don't believe in [MASK].\"\n",
    "inp_tens = torch.tensor(tokenizer.encode(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(input_context)))).unsqueeze(0)\n",
    "mask_indices = np.nonzero(inp_tens.squeeze()==103).squeeze()\n",
    "preds = model(inp_tens)[0].squeeze()\n",
    "mask_indices = [mask_indices.tolist()] if type(mask_indices.tolist())!=list else mask_indices.tolist()\n",
    "top_words = []\n",
    "for i in mask_indices:\n",
    "    top_words.append(torch.topk(preds[i], k=10))\n",
    "words = []\n",
    "tokens = []\n",
    "for mask_topk in top_words:\n",
    "    for token in mask_topk.indices.tolist():\n",
    "        tokens.append(token)\n",
    "        words.append(tokenizer.decode(token, clean_up_tokenization_spaces=True))\n",
    "    words = [word.replace(\" \",\"\") for word in words if not word.startswith(\"#\")]\n",
    "words = set(words)\n",
    "words = list(words.difference(STOP_WORDS))\n",
    "words =[word for word in words if len(word)>1]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string.pu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
