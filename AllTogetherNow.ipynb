{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --disable-pip-version-check -q pandas transformers seaborn tensorflow_hub elasticsearch elasticsearch-dsl annoy faiss-gpu\n",
    "!pip install --disable-pip-version-check -Uq scikit-learn\n",
    "!pip -q install --disable-pip-version-check --no-warn-script-location --user tensorflow-text \n",
    "!pip -q uninstall -y tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch()\n",
    "es.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle('Data/dataset.pkl')\n",
    "display(dataset[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = []\n",
    "for child in root:\n",
    "    d = {'topic':int(child[0].text), 'query':child[1].text}\n",
    "    topics.append(d)\n",
    "topics = pd.DataFrame(topics)\n",
    "display(topics[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = Path(\".\")\n",
    "encoded_dir = current_dir / \"Encoded\"\n",
    "tokenized_dir = current_dir / \"Tokenized\"\n",
    "print([f\"{x.stem}{x.suffix}\" for x in encoded_dir.iterdir()])\n",
    "print(\"\")\n",
    "print(list(encoded_dir.iterdir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "indices = {}\n",
    "for file in encoded_dir.iterdir():\n",
    "    index, tokenized = make_or_load_annoy(embedding_posix=file, n_trees=5, b=2)\n",
    "    indices[file.stem] = {\"index\":index, \"arg_ids\":tokenized}\n",
    "    \n",
    "pq_indices = {}\n",
    "for file in encoded_dir.iterdir():\n",
    "    index, tokenized = make_or_load_pq(embedding_posix=file, b=2)\n",
    "    pq_indices[file.stem] = {\"index\":index, \"arg_ids\":tokenized}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \n",
    "hits_per_index = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
